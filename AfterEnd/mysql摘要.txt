*mysql8在安装后intellij或Navicat都连接不上，报错“ The last packet sent successfully to the server was 0 milliseconds ago.”
 后来用telnet连接3306连接不上，于是在服务器开了防火墙和端口，还是不行
 后来又在阿里云服务器【安全组】里开了端口，还是不行
 后来又报错“message from server: "Host '110.87.116.253' is not allowed to connect to this MySQL server". ”
 于是通过百度用命令update user set host = '%' where user ='root';和flush privileges;设置了允许  即可详见cndn收藏
 如果上一步命令执行错误，可以先将%换成localhost执行成功后，重新进入myql再执行上一步即可。
 有时候执行unpdate命令后还是连接不上3306端口，是因为my.cf里设置了skip-grant-tables造成，删除了重启mysql即可。
 注意：因为安装mysql时没有设置忽略大小写，导致quartz的某些表无法被正确查找到，所以安装mysql时候最好先设置忽略大小写

*常用命令
 service mysqld start|restart|stop  启停命令
 SHOW PROCESSLIST;显示哪些线程正在运行（前100条）。如果想全列出请使用show full processlist;
 show variables like 'datadir'; 查看数据存储目录
 show status like 'Threads%';查看数据库连接情况
 select concat(truncate(sum(data_length)/1024/1024,2),'MB') as data_size,
       concat(truncate(sum(max_data_length)/1024/1024,2),'MB') as max_data_size,
       concat(truncate(sum(data_free)/1024/1024,2),'MB') as data_free,
       concat(truncate(sum(index_length)/1024/1024,2),'MB') as index_size
 from information_schema.tables where TABLE_SCHEMA = 'caisheng'; 查看数据库占用磁盘空间，如：23961.10MB,0.00MB,7.00MB,37.57MB

 SELECT CONCAT(TRUNCATE(SUM(data_length)/1024/1024,2),'MB') AS data_size,
       CONCAT(TRUNCATE(SUM(max_data_length)/1024/1024,2),'MB') AS max_data_size,
       CONCAT(TRUNCATE(SUM(data_free)/1024/1024,2),'MB') AS data_free,
       CONCAT(TRUNCATE(SUM(index_length)/1024/1024,2),'MB') AS index_size
 FROM information_schema.tables WHERE TABLE_NAME = 'resume'; 查看数据库表占用磁盘空间，如：23961.00MB,0.00MB,7.00MB,37.56MB

 



*sharding-jdbc和mycat的区别
 sharding-jdbc和mycat使用不同的理念，sharding-jdbc目前是基于jdbc驱动，无需额外的proxy，因此也无需关注proxy本身的高可用。
 Mycat 是基于 Proxy，它复写了 MySQL 协议，将 Mycat Server 伪装成一个 MySQL 数据库，而 Sharding-JDBC 是基于 JDBC 接口的扩展，是以 jar 包的形式提供轻量级服务的。

*注意：mysql5.x和8.x的jdbc驱动是不一样的，后者在spring中需要增加时区配置

*select for update的作用是在查询的同时 对数据加锁。根据where条件不同，for update产生的锁分为：行锁、间隙锁、表锁。


*mysql常用的sql函数
 字符串连接：select concat (id, name, score) as 别名 from 表名；
                    select concat ('#',id, name, score) as 别名 from 表名；
 格式化：FORMAT函数，第二参数是小数点的位数，有四舍五入的功能。
             SELECT FORMAT(100000,2);--输出100,000.00

*count(*) 和 count(1)和count(col_name) 有什么区别
count(*)=count(1)>count(主键)>count(name)
count(*) 其实统计的就是全表的数据条数，会被sql优化器优化成count(0),如果表中有二级索引的话会优化走二级索引。
count(name) 这个是统计name不为null的记录条数，不会走索引（如果name是主键则有可能优化走二级索引），遍历了所有的记录

*候选键：一种划分键的方式，按照候选键分的话可以分为主键和可选键


*LIKE和REGEXP的区别
 LIKE匹配整个列（like是模糊查询），如果被匹配的文本仅在列值中出现，LIKE并不会找到它，相应的行也不会返回（当然，使用通配符除外）
 REGEXP在列值内进行匹配，如果被匹配的匹配的文本在列值中出现，REGEXP将会找到它，相应的行将被返回，这时一个非常重要的差别（当然，如果适应定位符号^和$，可以实现REGEXP匹配整个列而不是列的子集）
 比如用name like '小红'只能匹配到name==‘小红’的记录
       用name regexp '小红'能匹配到name中所有包含‘小红’’的记录

*MySQL表的5种类型
存储引擎	事务	锁颗粒	主要应用	忌用
MYISAM	不支持	支持并发插入的表级锁	SELECT,INSERT	读写操作频繁
MRG_MYISAM	不支持	支持并发插入的表级锁	分段归档，数据仓库	全局查找过多的场景
Innodb	支持	支持MVCC的行级锁	事务处理	无
Archive	不支持	行级锁	日志记录，只支持insert，select	需要随机，更新，删除
Ndb cluster	支持	行级锁	高可用性	大部分应用

*char_length()和length()函数的区别
 char_length统计字符串的字符长度
 length统计字符串所占字节长度，比如一个emoji符号要占4个字节，但是它的字符长度只有1

*创建FEDERATED类型的表可以连接访问到远程服务器的表。但是在很多查询方面效率比较低，所以比较冷门。
 详见https://www.lanmper.cn/mysql/t8111


*查看最大连接数命令 show variables like '%max_connections%';
  mysql的最大连接数默认是100（mysql5.x版本是151）, 最大可以达到16384。
  不同版本有所差异

=======================分库分表 begin=============================
**阿里建议**
预估数据量：3年内单表数据量大于500w或单数据文件大于2G才考虑分库分表
预估数据趋势：像订单这类持续高速增长的数据今早考虑分库分表，并预留空间。像用户表后期会放缓增长则可以延期考虑分库分表
预估应用场景：频繁变更字段不宜作为分片键，不适合做分库分表。会涉及数据迁移
预估业务复杂度：业务逻辑和分片逻辑绑定会给sql执行带来很多限制，所以如查询逻辑变化非常大，不建议分表分库。

*分库分表的核心是sql语句，即在增删改查过程中，如何根据分片算法对sql语句进行解析或路由。

*分表分库的目的：
      分库：主要解决的是并发量大的问题。因为并发量一旦上来了，那么数据库就可能会成为瓶颈，因为数据库的连接数是有限的，虽然可以调整，但是也不是无限调整的。
               mysql的my.ini或my.cnf配置的 
		max_connections：151代表允许连接数据库的所有用户的连接数总和。上限主要取决服务器资源情况，过大容易内存溢出。不同版本不一样，详见csdn《MySQL 默认最大连接数是多少？》
                                                        Mysql5.5 mysql5.6  mysql5.7：默认的最大连接数都是151，上限为：100000
                                                        Mysql5.0版本：默认的最大连接数为100，上限为16384
                            max_user_connections：3000  代表允许单个用户的连接数最大值（账号的连接数上限），即并发值。默认0 ，上限是应该是max_connections
               注意：实际是分不同实例不同库，而不能是同实例不同库（这样公用的还是同样的连接数）
      分表：阿里开发手册建议单表行数超过 500 万行或者单表容量超过 2GB之后才会有性能问题，在此之前不建议分表
               
      注意：分库分表之后的联合查询或全量查询、跨实例库事务都是比较难的，一般通过搜索引擎做双写。尽量不分库分表
	 实际上确定在3年内是否会达到这个500w或2G级别，如果可以再考虑要根据数据结构、类型和业务进行性能单元测试。可能数据达到1000w才需要分库。
               确定要分库分表，最好做搜索引擎双写，即使没有搜索需求也做。这样后续避免数据清洗。

*多个数据库事务分2种情况：
    多个数据库分布在不同的MySQL实例里。这种情况需要使用到MySQL的分布式事务XA。
    多个数据库在一个MySQL实例里。这个原生MySQL是支持的。你可以在MySQL的一个连接里，开启事务，同时操作多个数据库，失败了做回滚。但是，你使用的编程语言的driver不一定支持。


*演进：
 -传统单库单表出现问题：
  1、数据库连接数限制（一般mysql默认最大连接数100左右，最高可设置1600左右）
  2、表数据量大（单表记录数取决于你的操作系统对单个文件的限制，业界流传500万，超过就要分表分库。可能你入200万速度就很低了，所以... ）
  3、硬件资源（单库单表的qps和tps都会受限制）

 - 传统解决方案：
  读写分离：涉及到数据同步、主从复制
  分库分表：分为垂直分库和水平分库（还有一种垂直拆分表，比如文章表被拆成基础信息表和富文本表）。
      基于代理：在中间代理服务处理。 性能没有jdbc方式高，但是屏蔽了分库细节，开发人员使用简单。还跨语言（支持异构语言系统）
                       Mycat 开源中间件
                       TDSQL 腾讯云的分布式数据库（详见TDSQL MySQL版文档 https://cloud.tencent.com/document/product/557/7700）
      基于JDBC:   属于jdbc直连，在应用层来处理。性能比代理方式高，但是要自己配置分片规则等。只能单一的java语言用Sharedingsphere
                  从yaml配置spring.shardingsphere.datasource里也可以看出：它的数据源是shardingsphere的特定数据源

  双写：在数据增删改查的时候  发给kafka 同步到es，用es去做查询

*分库分表产生的问题：
？分布式主键问题：全局去生成，如雪花算法，有带序号的雪花算法。可以自定义算法
？分布式事务问题：通过XA协议或seata的AT模式去解决
？SQL路由：sql分发到哪个节点执行？原封不动的转发吗？
？结果合并、零散数据合并问题：每个节点只包含部分结果，如何合并？ 如查询收入前十的用户，那么就得从多个分片分别查询前十再汇总合并。

*分库分表解决方案-Mycat
 主要配置4个xml
  schema.xml逻辑库表配置，主要是逻辑库表和实际物理库表的映射关系
  server.xml启动参数配置
  rule.xml拆分规则配置，主要是数据分片规则（连续分片、离散分片、综合类分片）
  wrapper.conf JVM内核调整配置

*分库分表解决方案-ShardingSphere
 详见csdn收藏《ShardingSphere介绍与使用》、bilibli尚硅谷收藏视频（对应笔记https://segmentfault.com/a/1190000038241298）

*分库分表带来的问题：
 联表分页查询（join查询） 搜索引擎双写。将一些要查询的字段放入搜索引擎。
 多库分布式事务
 分布式全局id
 增加开发成本
？Sharedingsphere如何解决上述问题
？正常情况下联合查询不能跨不同mysql，可以联合查询的场景：同库不同表、同mysql实例不同库的表
      注意：*创建FEDERATED类型的表可以连接访问到远程服务器的表。但是在很多查询方面效率比较低，所以比较冷门。 详见https://www.lanmper.cn/mysql/t8111
    mybatis能跨库联合查询吗？!其实可以联合查询的场景也是：同库不同表、同mysql实例不同库的表

*垂直分库和水平分库的优缺点（分库可以突破实例并发和吞吐量，分表可以突破500万限制）
 垂直分库：优点：按业务切分，结构清晰，利于维护。
                 缺点：单表数据量大则读写压力依然大，如单表数据量小则资源浪费。
                           不同业务表不能联表查询（甚至分页查询）
 水平分库：优点：数据分布在不同表或不同库，提高了curd的性能和吞吐量。
                 缺点：扩容时（比如增加一个分片库）会涉及比较复杂的数据迁移。
                          分片事务很难处理，比如要更新一定条件范围的数据，而这个数据范围涉及到多个跨库的分片

*最佳实践
 一般我们进行分库分表时，可以根据业务进行垂直分库，垂直分表，水平分库水平分表
 垂直分库：比如用户订单，用户表尽量落到一个表中，和其它不相关的表分开落到不同库里
 垂直分表：比如将用户表拆分为基本信息表（id、name、password）+附加信息表（nick、age....），这样请求频繁的登录操作就只操作基本信息表
 水平分库和水平分表：主要是根据表的数据量进行，如果前期量小可以在单表上，后期如果量大，要用代码写规则做数据迁移。如果用hash一致算法做的数据落位，那么涉及数据迁移的数据量会比较少。
 注意：1、分库分表第一步是确定用什么列（即sharding column），什么规则来分。如前台用户访问较为频繁的就以userId分，如管理后台访问较多则用adminId。这个是根据我们业务场景来确定的。
          2、水平分表目的是突破单表500万限制，但是在一个业务领域的业务表尽量落到一个库中，避免join查询问题性能。
          3、ES双写场景：
                 场景：如果避免不了分库join，一般进行kafka异步双写ES（同步问题多，性能，数据丢失...），用ES进行查询。但是避免不了延迟问题，只能保证最终一致性。如一些查询条件是不包含sharding column的，不可能为了这些请求量并不高的查询再做冗余分库分表。总之复杂的查询就用此方案。
                 PS：多sharding column不到万不得已的情况下最好不要使用，建议采用单sharding column + es的模式简化架构。
                 大致过程：

          4、有时候我们还可以做一些字段的冗余，以减少关联查询。
          5、

*数据分库分表后的数据迁移：
 垂直分库分表：在更新时间比较少的夜间，或者停服迁移。
 水平分库分表：需要做增量更新，？了解具体的实现方案

停机迁移方案：
    如果系统业务能接受停机迁移，则是一个好方案。 
    注意缩短迁移时间即可

不停机迁移方案：，这里推荐我们常用的一种方案，也就是在线双写的机制。
     1、通过在写原有的数据库的同时也写一份数据到我们的新的库表中。？这个是写程序（分布式事务）还是用canal
       ？增量数据迁移推演过程：
          写原库分支事务出现回滚，则增量迁移分支事务也需要回滚。
          业务库更新：
                新增：a1 如果回滚，最终a1记录不存在
                更新：b0->b1 如果回滚，则最终版本为b0
          迁移库更新：
                新增：a1 没有回滚，则多出一条
                更新：b0->b1 没有回滚，则最终版本b1
          问题：是用shardingAT还是canal，如果迁移库更新是用canal是否能保证数据的一致性。  
                   在这个全局事务中，怎么保证隔离性质，如果用shardingAT则第一阶段就直接释放锁，未隔离，则迁移程序可能读取并同步到迁移库。 所以得用canal
          总结：经过上述推演，则不能用shardingAT，可以用XA。但是性能用过不高。 所以业内解决方案都是canal
     2、同样写一个后台迁移数据的程序，将我们的旧库的数据通过我们的数据库中间件迁移到新的多库表中。？此时要根据sharding的分片策略进行迁移。？那么迁移程序的主键就不能用自动生成
     3、在迁移的过程中，每次插入数据的时候，还需要检测数据的更新情况。比如，如果新的表中没有当前的数据，则直接新增；
         如果新表有数据并没有我们要迁移的数据新的话，我们就更新为当前数据，只能允许新的数据覆盖旧的数据（这里其实推荐使用Canal这样的数据库同步中间件对增量更新做同步）。
     4、经过一轮之后，也就是假如旧表中1000万条旧数据迁移完之后，我们就需要进行校验，校验两边数据是否是一模一样的。
     5、这样反复的跑了几天之后，就数据库和新的数据库肯定是会一模一样的，最后观察下数据正常了，就可以停掉旧库的写入动作了。    ？怎么确定是否完全迁移                  
       ？历史数据迁移推演过程 ：
         取业务库记录，判断迁移库记录：
                                无记录：直接插入
                                有记录：如果这个记录是增量迁移程序全局事务已提交的则直接可以更新到迁移库
                                            如果这个记录是增量迁移程序全局事务未提交的则直接更新到迁移库会出现脏写。所以保证同步程序是全局提交后才能保证隔离，才能保证不脏写。
                                总结：经过上述推演，则不能用shardingAT，可以用XA。但是性能用过不高。 所以业内解决方案都是canal。 
                                         XA或canal都可以避免事务隔离性造成的数据一致性问题，核心在于增量迁移数据和历史迁移数据不交叉。
    总结：不停机数据迁移或同步涉及到几个问题：
             ？如何划分历史数据和增量数据的边界？ ！在开启binlog时，接受到的第一条数据作为历史数据的分界点，在这之前未为历史数据，在这之后为增量数据。
             ？如何保证目标库和源库的数据一致性？
                   首先就是做好历史数据分界点，避免历史迁移程序和增量迁移程序有数据交叉，这样就不会有数据覆盖问题。如果有交叉数据时，历史迁移和增量迁移的先后顺序就可能造成不一致。 
                   其次要注意流程：开binlog->canal监控得到首条记录->执行历史数据迁移任务->canal执行增量数据迁移任务。 此时要在代码中保证整个流程的顺序性。
             ？当历史数据和增量数据迁移完毕，怎么关闭增量程序并启动新的分库分表服务？ 
                   1、首先历史数据迁移任务执行完即可关闭
                   2、其次将原有业务数据服务停掉
                   3、此时原有业务库的增量binlog停止更新，增量迁移任务读完剩余binlog才停止任务执行
                   4、在2点进行同时启动分片业务数据服务。新增的数据会通过新的服务写到分库分表。
             ？binlog有容量和过期时间现在，要保证在出问题前处理数据？ 一般增量数据并不会那么快速增长，即使会我们也可以增加处理线程来处理。
                 容量有多少，过期时间又是多少。
             ？canal、maxwell、go-mysql-transfer的区别优缺点
                 maxwell： 支持历史数据获取，不支持高可用，直接将数据发送到kafka或redis、数据格式json。需要高版本的JDK。支持bootstrap（刷全量数据）有什么用？
                 canal：不支持历史数据获取，支持高可用，支持客户端拉取，数据格式自由（可定制格式）。不支持刷全量数据。
                 为什么鸿俞将canal改成maxwell：因为只是同步到kafka，不需要写客户端处理和历史数据迁移代码，更加简单。
             ？如果canal服务停止中断了怎么办。该问题关键在于重启后是否可以端点续传...
             ？历史数据如何迁移：根据开启binlog后，canal监控到第一条数据的创建时间（如startT），以该时间为条件进行查询，select count() from user where create_time<startT;进行遍历复制到新库
                     
*不停机进行数据清洗：
 和不停机数据迁移差不多原理。
 
 
  

*Mysql同步到ES，数据从Mysql同步到ES主要涉及到几个技术关键点
 1.Binlog机制
 2.Canal中间件
 3.Kakfa中间件

**** Canal begin ******
*相关文档：
 *总体部署逻辑看http://imyhq.com/search/12900.html
 *简单demo详见csdn《java实现通过canal和mysql同步》
 *用Canal同步MySQL到ES方案  https://www.alibabacloud.com/help/zh/elasticsearch/latest/use-canal-to-synchronize-mysql-data-to-alibaba-cloud-elasticsearch

*拓扑：
       角色：Mysql数据库、Canal服务端（下载canal.deployer-xxx.tar.gz包启动）、Canal客户端（可以是canal.adapter-xxx.tar适配器或者引入Canal依赖的java应用等）
       过程：Canal服务端监控mysql数据库binlog，Canal客户端连接Canal服务接收数据进行处理（可以存储或者其它公用）

*如果捕获数据频繁量大，而且处理任务时间较长，则需要搭建kafka做缓存，然后消费（如存ES）。 
 如果普通数据量而且处理任务时间短，其实可以直接处理（如存ES）。 


**** Canal end    ******


**** FlinkCDC begin ******
*流式和离线概念：
 比如mysql数据同步到es过程中（如A表中a记录变化过程为a1->a2-a3）：
  流式：mysql数据一旦变化就会将这种变化同步到es中，那么这a2和a3的变化都会同步到es
  离线：由于离线一般都是定时去取，这时就有可能只取到最终变化结果a3，而a2并未被同步到es过

*示例代码详见csdn《flinkCdc的mysql配置及java测试代码》
*使用Flink standalone模式安装部署，不用搭建相关集群。详见csdn《windows上简单部署flink》《windows上配置flink》《大数据实时处理框架之Flink win10快速部署》

*FlinkCDC在java代码中有个startupOptions配置，是配置怎么开始读取，是全量读取还是从最新的开始读取
 initial配置，就是默认的全量方式。 怎么做到全量：它先做一次全量快照（历史数据，它的op类型是r，即读取的），然后再切换到binlog最新的位置，这是如果有新数据进来就会被接收（op类型可能就是c，即新增）
  
？CheckPointing是什么配置 ！配置多久去检查一次，并留下相应记录点。 当任务执行失败并重启时会根据这个检查记录点重新运行，相当于“断点续传”

？Flink CDC为什么可以不用依赖kafka直接处理数据
  如果用Canal监控Mysql的binlog，为了不因为处理逻辑复杂或者处理时间较长导致消费binlog受影响，一般都先存kafka，然后另外去消费kafka上的数据。 
  但是Flink CDC为什么可以不用依赖kafka直接处理数据呢？ 从内部实现上讲,Flink CDC Connectors内置了一套 Debezium 和 Kafka 组件，这样对于开发者就节省了一步，提高

*用FlinkCDC同步MySQL到ES
 具体文档可看github项目 https://github.com/ververica/flink-cdc-connectors
 两种方式同步ES示例详见：https://gitee.com/qianxkun/lakudouzi-components.git
 有两种方式：
   Table/SQL API方式：
       需要额外安装Flink集群、下载flink-sql-connector-xxx源码并自己编译  jars放到FLINK_HOME/lib/.    比较麻烦
       经测试： 表字段类型是 json , flink 不支持；改为 string 解决
       注意：此demo测试失败
   DataStream API方式：  
       只需要引入相关的依赖到java项目即可。同步ES示例代码详见csdn《Spring Boot+Flink CDC —— MySQL 同步 Elasticsearch (DataStream方式)》
       注意：此demo测试成功


  ？似乎要依赖flink和flinkSQL，但是flinkSQL要下载源码mvn编译（容易报错）

*FlinkCDC1.x和FlinkCDC2.x的区别
 FlinkCDC1.x 只支持单并发，需对读取的库或表加锁，可能导致数据库hang住（Mysql所有的ddl，dml操作都会处于wait read lock阶段）或锁住表的读，DBA一般不给权限。 这种操作尽量在夜深人静时做。 
 FlinkCDC2.x 支持全量读取阶段分布式（即并发，但增量还是单并发）和checkpoint、全量和增量读取过程不锁表仍然保持数据一致性。
 原理详见csdn《FlinkCDC原理详解+复制即用使用教程》


*同步公司数据到ES
          {
          "_cid":"ac84bd6598528",
          "type":"3",
          "_cname":"<a href=\"https://www.597.com/com-ac84bd6598528/\" target=\"_blank\"  class=\"text-link\"><strong>厦门市思明区荞海餐饮店</strong></a><br><span><a class=\"btn btn-mini\" target=\"_blank\" href=\"/companyinfo/companyinfo.html?type=3&act=view&c_id=ac84bd6598528\">查看详情</a></span><br><span>执照状态:<font color=\"green\">已认证</font>(?)</span><br><span>绑定时间:23-04-02 23:32</span>",
          "_source":"私有库",
          "_modTime":"23-04-03 08:31",
          "_regTime":"23-04-02 23:19/<br>23-04-04 13:39",
          "vipStyle":"normalStyle",
          "_nextType":"D类/可跟进",
          "_username":"<a href=\"/companyinfo/companyinfo.html?type=3&act=view&c_id=ac84bd6598528&uid=e7d6827519178#followList\" class=\"text-link\" target=\"_blank\"><strong>AUTO1395010360921</strong></a><br/>",
          "comCityId":"厦门市",
          "operation":"",
          "pageIndex":17,
          "_followTime":"23-04-03 10:08/<br>23-04-17 10:07",
          "adminUsername":"曾思雅",
          "companyTypeStr":"新客户",
          "companyViewData":Object{...},
          "_expireFollowTime":"23-07-01 23:32",
          "companyTongjiData":Object{...},
          "companyJobslistData":Object{...},
          "companyLicenceinfoData":Object{...}
          }
  
？注意测试数据导入ES时，这几个字段数据要核定下_expireModTime comSite createTime note

？mapping配置改进：Null Value、companyTongjiData加入

*检查点：
 FlinkCDC处理数据时，通过检查点配置来间隔地保存当前任务执行状态，当执行失败或重启则可以恢复到之前的状态
 具体原理及配置详见csdn《Flink容错机制（一）》
 详见gupaovip的flinkcdc-mysql2es实践。注意enableExternalizedCheckpoints配置
 ？如何实现“手动重启后断点续传”
--checkpoint.storagePath=file:///G:/flinkCDCCheckpoint
--checkpoint.storagePath=file:///path/to/checkpoints

-s --checkpointDir file:///G:/flinkCDCCheckpoint
-s --checkpointDir file:///path/to/checkpoints


*重启策略：
 是在FlinkCDC处理数据失败时如何重启应用的策略，如固定策略（固定失败后多长时间重启，尝试重启的次数）
 如env.setRestartStrategy(RestartStrategies.fixedDelayRestart(3, 10000));//任务失败后10000ms重启，最多重启3次


========================================================
flink run -d -m 127.0.0.1:8081 -Denv.java.opts="-Dfile.encoding=UTF-8"  -c com.cny.App G:\GitProjects\gupaovip\flinkcdc-mysql2es\flinkcdc-mysql2es-datastream\target\flinkcdc-mysql2es-datastream-0.0.1-SNAPSHOT.jar


再次启动命令：
flink run -input %FLINK_HOME%\README.txt --output %FLINK_HOME%\wordcount.txt -t yarn-per-job -d -Dyarn.application.queue=root.users.flink -Djobmanager.memory.process.size=1024mb -Dtaskmanager.memory.process.size=1024mb -Dtaskmanager.numberOfTaskSlots=1 -Denv.java.opts="-Dfile.encoding=UTF-8" -c “org.apache.flink.examples.java.wordcount.WordCount” “%FLINK_HOME%\examples\batch\WordCount.jar”

-d -Dtaskmanager.numberOfTaskSlots=1

下载flink-1.17.1包到win10上并以standalone模式运行，包里的flink-1.17.1\examples\batch\WordCount.jar和flink-1.17.1\examples\streaming\WordCount.jar有什么区别？ 怎么运行测试它们？

flink run -m standalone-jobmanager:8081 examples/batch/WordCount.jar --input <input_file> --output <output_file>

flink run %FLINK_HOME%\examples\batch\WordCount.jar -input %FLINK_HOME%\README.txt --output %FLINK_HOME%\wordcount.txt

flink run -m standalone-jobmanager:8081 examples/batch/WordCount.jar -input %FLINK_HOME%\README.txt --output %FLINK_HOME%\wordcount.txt
flink run -m standalone-jobmanager:8081 %FLINK_HOME%\examples\batch\WordCount.jar -input %FLINK_HOME%\README.txt --output %FLINK_HOME%\wordcount.txt


运行%FLINK_HOME%\examples\batch\WordCount.jar一段时间后，在Flink Web UI 上显示任务失败，得到错误信息如下，为什么？怎么解决？

flink run -m localhost:8081 -ytm 2024 G:\Software\flink-1.17.1-bin-scala_2.12\flink-1.17.1\examples\batch\WordCount.jar -input G:\Software\flink-1.17.1-bin-scala_2.12\flink-1.17.1\README.txt --output G:\Software\flink-1.17.1-bin-scala_2.12\flink-1.17.1\wordcount.txt

flink run -m localhost:8081 G:\Software\flink-1.17.1-bin-scala_2.12\flink-1.17.1\examples\streaming\WordCount.jar -input G:\Software\flink-1.17.1-bin-scala_2.12\flink-1.17.1\README.txt --output G:\Software\flink-1.17.1-bin-scala_2.12\flink-1.17.1\wordcount.txt -ytm 2024
===============================================================


*实践总结：
  *在Flink1.9.0及以下版本才有windows版本（有相关命令的.bat文件）。csdn的《windows上简单部署flink》并不可行，因为.bat文件应该是1.9.0版本的，并不适用与1.17.1版本。
  *如果在windows上运行在Flink1.9.0独立集群模式，然后跑Flink1.14.4开发flinkcdc-mysql2es项目jar，此时项目中的slf4j会和Flink1.9.0自身的日志框架冲突，前者用的是logback，后者用的是Log4j

**** FlinkCDC end    ******

*JSON类型字段常用sql
 更新：UPDATE company SET json = JSON_SET(json, '$.name', '刀郎') WHERE  '$._cid'='71fc036598800';
          UPDATE company SET json = JSON_SET(json, '$.user.name',  '刀郎') WHERE  '$._cid'='71fc036598800';
 查询：SELECT json-> '$.adminUsername' FROM company  WHERE json-> '$._cid'='71fc036598800';



*ShardingSphere相关核心概念：
 *真实表：如果订单表分为t_order_0、t_order_1、....这些表就叫真实表

 *逻辑表：与真实表相对，t_order则为逻辑表

 *数据节点：数据分片的最小单元。由数据源名称和数据表组成，例：ds_0.t_order_0。

 *绑定表：​ 指分片规则一致的主表和子表。例如：t_order表和t_order_item表，均按照order_id分片，则此两张表互为绑定表关系。绑定表之间的多表关联查询不会出现笛卡尔积关联，关联查询效率将大大提升。
           简单的说就是t_order_item_0和t_order_0是相关联的，它们才有相互关联的数据，而t_order_item_0和t_order_1是不关联的，没有相关数据。所以查询的时候，不会去关联查询t_order_item_0和t_order_1
           要求：1、两个表的分片策略和算法要一致；2、配置相关联

 *广播表：？？？

 *分片键：用于分片的数据库字段，是将数据库(表)水平拆分的关键字段。例：将订单表中的订单主键的尾数取模分片，则订单主键为分片字段。

 *分片算法：目前提供4种分片算法？？和分片策略不同

 *分片策略：包含分片键和分片算法，由于分片算法的独立性，将其独立抽离。真正可用于分片操作的是分片键 + 分片算法，也就是分片策略。目前提供5种分片策略。

*ShardingSphere相关配置：
 spring.shardingsphere.props.sql.show=true  可以打印出执行的sql。 这里分为Logic SQL（逻辑上的sql）和Actual SQL（真实执行的sql）

*分片策略：
  实际上分片策略不仅仅是负责将数据按规则存储到对应分片中，更重要的是在查询的时候快速定位到数据所在分片
  所以在不同的查询sql语句中，shardingsphere需要根据分片规则对sql语句进行改造，让它能够找到对应的数据分片，提升性能。
  详见blogs《sharding-jdbc 分库分表的 4种分片策略，还蛮简单的》

 *Inline策略:  根据单一分片建进行精确分片
  当业务上使用分片键作为查询条件进行精确查询数据时，Shardingsphere会先精确的查找对应的数据分片，然后再去查找。
  注意：要求此时这个分片建的值要能够通过分片的策略算法计算出对应的分片
        在in（1,2,3）查询中，实际上Inline策略判断不出数据是不是在同一个分片，所以会全分片查找，这也可能导致性能下降。
  如：select * from user where userId=123。 则Shardingsphere会先根据之前分片规则去计算userId=123是放置在哪个分片，先找到分片再查询。而并不会到所有分片上去查询。
      具体效果，可以查看输出的LogicSQL和ActualSQL

 *标准策略： 根据单一分片建进行精确或者范围分片
  如果使用Inline策略，此时对分片键进行between查询，则会报错。 如：wrapper.between("userId",123,456);...
  所以就不能用Inline策略，而使用标准策略。 就能支持范围查询了。
  此时，分片策略规则就不能使用Groovy表达式（如t_user$->{0..1}）,而要指定相应的分配策略类，包含精确查询的类和范围查询的类（也会区分分库的算法类和分表的算法类）
  如果是like查询类型，一般在这种大数据是不太使用的（因为涉及复杂查询类都是放到ES中）。 性能不高。所以就不考虑了
  总体原理：执行sql语句（可能是查询或增删改），根据配置的分片策略计算出对应的库及表名称，进行sql重新构造，使得根据分片策略规则到指定的库和表操作。
  包含两种分片算法：精确分片算法和范围分片算法
                    精准分片算法：根据分片键的值计算具体的分库或分表的分片名称（根据配置的是分库的还是分表的策略，原理一致），算法类的doSharding方法返回单一的String类型
                    范围分片算法：根据分片键的范围计算具体的分库或分表的分片名称集合（根据配置的是分库的还是分表的策略，原理一致），算法类的doSharding方法返回多个的String集合类型


 *complex策略： 根据多个分片键进行精确或范围分片
 Inline和标准策略都是单一分片键，而complex策略是多分片键策略
 相比上两种分片策略，complex策略原理是一样的，只是分片键由一变多。

 *Hint策略： 使用自定义的方式进行分片，特点是分片键或者分库的键值可以通过HintManager工具类进行灵活自定义设置，无需在配置文件中写死。
  注意：在调用 SQL 前通过 HintManager 指定分库、分表信息。由于每次添加的规则都放在 ThreadLocal 内，所以要先执行 clear() 清除掉上一次的规则！
  在具体的策略类代码doSharding方法中也能拿到HintManager设置的分片键。

 注意：如select * from user where CAST(userId as char) ='12345' 类似这种sql，shardingsphere是很难找出分片键userId的
       也就是我们涉及分表分库的表的查询不能太复杂，否则shardingsphere很难去理解语义并进行sql的重写。
       再如：select * from db2.t_user;//会直接忽略db2进行SQL重写，如  select * from t_user2;
       再如：select * from t_user union all select * from t_user;//看后面一个t_user则不会重写了
       再如：select max(cid) from t_user group by user_id having userId='123'; //这个也会报错

 总之：分库分表的分片策略的核心在于sql，只有能被shardingsphere识别重写的sql才能做分片策略的可能


*具体扩展学习详见bili《B站最牛的Mysql分库分表教程（2022最新版）》
*新版本的shardingsphere新增分片规则
 Sharding By Mod 可以设置取模的数量n，然后进行分片
 Sharding By Datetime 可以根据时间范围进行分片，相当于根据时间归档

*shardingsphere暴露了很多spi扩展供开发者实现更多的扩展。 如主键生成策略就可以通过其spi规定进行自定义编写

*时间范围分片和取模分片
 时间范围分片：按时间进行归档，但是容易造成数据倾斜（分片上数据有多有少），查找的时候可能要全分片查找，可能造成性能瓶颈
 取模分片：在分片扩展的时候要进行数据迁移。  此问题也会引出hash一致性算法。
 也可以结合两种分片，如订单先按时间范围分片再按取模分片，如10月、11月，10月份订单量少，所以设定取模2，而11月份订单量大设定取模5，这样就可以通过不同月份不同取模来优化数据分片

*基因法多分片查询
 场景：用户表通常我们用userId作为分片键，但是在登录或查询用户时往往是使用userName来查询。 这时候如不能进行分片算法计算，则会全分片去查询所有分片用户表。
 解决：将userName进行hash得到的数字hashCode+userId进行改造，作为分片键。  hashCode可以截取后面部分数字，因为如果分片数量只有8，则这个hashCode只需要大于8的数即可取模
       如果把hashCode看作二进制的数，则相当于只需要取后3位，然后将后3位的数字和userId进行融合，组合成一个新的分片键字段（比如叫fenpianKey）则fenpianKey
       注意：用户名是固定不能更改的，否则会出现问题。 如果用户名更改则将数据按规则迁移到新的物理表（这可能涉及分布式事务，可以用seataAT）
？构造使用场景：
  个人和企业用户浏览记录：平常用用户名查询，所以采用上述基因法多分片查询。 具体操作：利用基因法定制了一个分片键，然后进行数据迁移。
  职位表：
  简历表：

*uuid是字符串主键排序性能低。
 mysql要对主键进行排序，排成一颗B+树。
 我们希望的主键是能单调递增或递减的。才能好排序成B+树


*通常使用Shardingsphere，会结合多数据源进行使用。
 也就是或只有部分分库分表，这部分的业务必须通过Shardingsphere的数据源进行。此时就要在业务的services里通过@DS注解指明Shardingsphere数据源

？？按照jeecg-boot官网文档，将shardingshpere的testdemo集成，在测试添加数据时候一直报栈溢出。 这个问题一直搞了3天
     经过研究在src/main/java/org/jeecg/boot/shardingsphere/config/DataSourceConfiguration.java的shardingDataSource在注入到spring容器里有出现循环引用问题。
     然后一直检查配置，检查DataSourceConfiguration配置是否有shardingsphere版本差异，最终也是没有结果。
     最终推断，问题应该出在yml配置上。
     原本jeecg官网是将jeecg-sharding.yml单独放到nacos，然后通过本地的application.yml里添加“- optional:nacos:jeecg-sharding.yaml”引入。
     于是我将jeecg-sharding.yml内容直接拷贝合并到nacos上的jeecg-dev.yaml里面，结果成功了，问题解决了。

？？虽然解决了上述问题，但为什么官网的方式的配置文件会不生效？
      1、发现jeecg-boot-starter-shardingsphere项目里有application.yml，并且配置了spring.profiles.active: sharding
         答：具体项目在idea执行debug时maven会设置spring.profiles.active=dev，从而覆盖问题所述的配置
      2、intelliJ编译使用的是dev模式编译启动，
      3、在jeecg-system-cloud-start项目的application.yml里配置了- optional:nacos:jeecg-@profile.name@.yaml
         那么profile.name实际是dev还是sharding
         答：最终是dev。实际上如果是optional:nacos:jeecg-xxx。yaml，则spring将xxx字符串解读成环境参数。
            只要项目本地主配置文件application.yml里环境参数加上xxx即可，如spring.profiles.active=dev,xxx

*网友相关数据迁移方案：
 ETL
 停机用存储过程等方案

=======================分库分表 end==============================

============================ mysql begin ============================

*此部分摘要学习bili《黑马程序员 MySQL数据库入门到精通》 文档在网盘java/黑马MySQL数据库

*sql分类
     DDL（Data Definition Language）数据定义语言，用来定义数据库对象(数据库，表，字段)
     DML（Data Manipulation Language）数据操作语言，用来对数据库表中的数据进行增删改
         内外连接（画两个交叉的园）：
            
            内连接（交叉部分）：
                     自连接（交叉部分）：select a.name son，b.name farther from person a, person b where a.prentId=b.id; //子父都在同一张表。注意from person a, person b这种写法也叫隐式内连接
            左连接（左边+交叉部分）：
            左连接（右边边+交叉部分）：
         子查询：
     DQL（Data Query Language） 数据查询语言，用来查询数据库中表的记录
         基本语法： SELECT 字段列表 FROM 表名列表 WHERE 条件列表 GROUP BY 分组字段列表 HAVING 分组后条件列表 ORDER BY 排序字段列表 LIMIT 分页参数
         执行顺序： FROM 表名列表 WHERE 条件列表 GROUP BY 分组字段列表 HAVING 分组后条件列表 SELECT 字段列表 ORDER BY 排序字段列表 LIMIT 分页参数
                         不同于基本语法顺序，执行顺序将“SELECT 字段列表”置后，验证以下sql 发现报错，因为eage这个再select里定义的别名，比where晚执行
                         select e.name ename , e.age eage from emp e where eage > 15 order by age asc;
         
     DCL （Data Control Language）数据控制语言，用来创建数据库用户、控制数据库的访问权限

*函数
   分类：字符串函数、数值函数、日期函数、流程函数

*约束
  分类：非空约束、唯一约束、主键约束、外键约束、默认值约束、检查约束(8.0.16版本之后才有）
  注意：外键约束下，父表数据（如depart父表、employee子表）删除和更新会触发删除/更新行为：
           NO ACTION 检查子表有外键不允许父表删除或更新记录，和RESTRICT一样
           RESTRICT 检查子表有外键不允许父表删除或更新记录，和NO ACTION 一样
           CASCADE 父表删除或更新记录时，级联删除或更新子表数据外键字段
           SET NULL 父表删除或更新记录时，子表相关外键字段设置为null
           SET DEFAULT父表删除或更新记录时，子表相关外键字段设置为默认值，innoDB不支持

*事务
  模拟异常：在两条sql命令语句之间写个汉字或其它非sql语句。  则非sql之前的sql正常执行，之后不执行。
  事务控制：
      查看事务控制方式：select @@autocommit;
      设置事务控制方式：set @@autocommit=0; //1自动提交，0手动提交
      使用方式：
           方式一：使用SET @@autocommit=0;开始，中间业务代码，后面跟COMMIT或ROLLBACK
           方式二：使用START TRANSACTION或BEGIN开始，中间业务代码，后面跟COMMIT;（不需要ROLLBACK，因为能自动回滚）。注意前提是@@autocommit=1
  并发事务产生的问题：
      脏读：B事务读到A事务未提交更新的数据，A事务提交了，则实际上B读的是脏数据。
      不可重复读：在B事务内两次读取数据不一致，因为A事务插入或更新并提交了。（如：两次读取一个表记录总数，在这期间有新的事务插入了记录）
      幻读：B要修改一些数据时，事务期间，A事务又插入了数据，此时B就发现还有未修改的数据，像幻觉。 串行化解决幻读原理：B修改数据事务期间不允许别的事务插入数据
  事务隔离级别：
      级别：读未提交、读已提交、重复读、串行化
      对应关系：关键记住读未提交解决不了问题，读已提交解决了脏读，重复读解决了脏读、不可重复读，串行化解决了所有问题
      查询：默认隔离级别是重复读。select @@transaction_isolation
      设置：
      注意：设置隔离级别是在可能发生问题的的一端。如A事务修改数据，B事务要读取数据，则B事务可能出现脏读。 那么要解决脏读而设置提升隔离级别是在B这边设置，而不是A
      
*存储引擎
   定义：存储数据、建立索引、更新/查询数据等技术的实现方式。存储引擎基于表而不基于库，所以存储引擎也可以成为表类型
   MySQL体系结构：详见网上结构图。包含客户端连接器、连接池、存储引擎....   
   查看表的存储引擎：show create table t_user;
   查看当前数据库支持存储引擎：show engines;
   InnoDB:
      特点：DML操作遵循ACID模型，支持事务；
            行级锁，提高并发访问性能；
            支持外键约束，保证数据完整性和正确性。
      表空间文件：每个xxx表都会对应一个xxx.ibd文件，用于存储表结构、数据和索引。
      逻辑存储结构：
          tablespace 表空间
               segement  段
                    extemt 区：固定大小1M
                        page 页：固定大小16K
                           row 行
    MyISAM
       早期MySQL默认存储引擎
       特点：不支持事务/外键、支持表锁不支持行锁、访问速度快
    Memory
       存储内存，断电丢失数据，一般做临时表或缓存
       特点：内存存储、hash索引
    如何选择引擎：
       主要根据事务、外键、行锁的支持，结合场景需求。  如电商中存储评论或日志等非核心数据可以用MyISAM存储

*索引              
   数据结构原理：
       二叉树/红黑二叉树
       B-tree/B+tree
        问题：InnoDB主键索引的B+tree高度多高？
        答：详见bili视频讲解，16-索引-思考题。   即使存储两千多万数据，B+tree也只需要3层结构
   InnoDB中的索引分类：
       聚集索引：
         定义：将数据存储与索引放到一块，索引结构中的叶子节点保存了行数据。无论如何都会存在聚集索引。有且只有一个。主键就是聚集索引。
         选取规则：如存在主键，主键索引就是聚集索引
                   如不存在主键，使用第一个唯一索引作为聚集索引
                   如没有主见和唯一索引，则InnoDB会自动生成一个rowid作为隐藏的聚集索引。
       二级索引
          定义：将数据存储与索引分开存储，索引结构的叶子节点存储的是关联数据的主键（应该说是聚集索引存储的数据），可以有多个。  
       回表查询：一条数据从二级索引查找到主键再去聚集索引查找具体行数据的过程叫回表查询。
                 如：select * from t_user where name = 'jack';--此sql会先查询name的二级索引再查询聚集索引
    平常说的索引分类：
       单列索引：B+tree上的节点的数据是对应单列值
       联合索引：B+tree上的节点的数据是对应多列值（而且是有序的）
          注意：最左前缀法则：比如name_age_nick联合索引，如查询条件不包含最左边的name字段，则sql将不会查找所有索引。具体详见文档。
                select * from person where age=18 and nick='beibei';--不包含name。可以用explain查看key、key_len
                查询条件尽量使用>=或<=而不使用<或> 前者会走索引，后者不会。
                其它注意事项详见文档
          重点：学习联合索引的B+tree结构，才能理解它的失效法则，以及规避回表查询（比如name_age联合索引，那么该sql不会走回表查询：select name,age from person where name='jack' and age='18'）。            
       前缀索引：一些字段数据量比较大，那么可以截取字段值的一部分作为索引B+tree节点key。从而减少磁盘存储空间，提高性能。
    索引语法：
       注意：可以创建单列索引或联合索引（即多列索引），联合索引关联的几个列的顺序是有讲究的     
             在写sql时可以使用user index(索引名)等“sql提示”关键字来指定mysql用哪种索引。
    SQL性能分析：
       主要是查询的优化，一般索引优化
       状态查询命令：show [session|global] status;  查看MySQL服务器状态信息，包含curd的访问频次信息
                     show [session|global] status like 'Comm_______'; 也可以添加like条件查询
       慢查询日志：它记录了所有执行时间超过预设值的SQL，在/etc/my.cnf中配置
       profile详情：开启该监控功能后，再执行业务SQL，然后
                    show profiles;查看所有SQL耗时。
                    show profile for query query_id;查看具体SQL语句各阶段耗时详情
                    show profile cpu for query query_id;查看具体SQL语句CPU使用情况
       explain执行计划：能查看SQL的执行信息，包含如何连接、连接顺序、索引情况等
                        在要查看的SQL语句之前加上EXPLAIN关键字，然后执行即可查看执行计划的记录（id,select_type,type,possible_ke）。
                            id：执行计划记录多条，根据id判断执行先后顺序，值越大越先执行，值相同则顺序执行。
                            select_type：表示select的类型，SIMPLE代表简单表即不用连接或子查询、PRIMARY主查询即外层查询、UNION、SUBQUERY
                            type：表示连接类型，性能好到差的连接类型为NULL，system，const，eq_ref，ref，range，index，all。注意这几个类型对应一般那种类型查询。如：一般主键查询时它的select_type就是const
                            possible_keys：可能用到的索引
                            key：实际用到的索引
                            key_len：索引的长度
                            ref：
                            rows：
                            filtered：
                            Extra：额外的信息，如在排序sql中会显示排序的方式（如filesort）
                        注意：主要关注type、prossible_keys、key、key_len字段                      
        索引优化：
           主键索引优化：
                 尽量减小长度（二级索引树节点存储了主键，主键太长磁盘IO好性能）
                 尽量顺序插入（因为乱序容易产生页分裂，造成性能消耗。页分裂是InnoDB数据存储的一种内部机制。）如使用UUID则插入都是乱序插入的。
           order by优化：检验标准是在EXPLAIN下的Extra列里进行不出现filesort排序方式
                 尽量通过索引去排序，并且是升序的（因为索引B+tree叶子就是升序链表结构），通过联合索引优化时也是遵循最左前缀法则      
   注意：索引是在存储引擎层的，所以不同引擎的索引结构不一样。
   问题：？如果是表已经有数据，要增加索引，那内部是不是要遍历所有数据去挂到B+tree上？！答案是需要的，整个过程可能是比较耗时的。
         

*SQL优化

*锁

*MySQL管理

*技巧：
  在mysql命令行里，在sql后面加\G（如select * from t_use \G;）可以格式化sql语句

?共享锁、独占锁

？行锁、表锁

？mysql发生死锁情况：
  *用户A 访问表A(锁住了表A),然后又访问表B；另一个用户B 访问表B(锁住了表B)，然后企图访问表A；
   解决：尽量避免同时锁定两个资源，如操作A和B两张表时，总是按先A后B的顺序处理， 必须同时锁定两个资源时，要保证在任何时刻都应该按照相同的顺序来锁定资源。
  *用户A查询一条纪录，然后修改该条纪录；这时用户B修改该条纪录，这时用户A的事务里锁的性质由查询的共享锁企图上升到独占锁，而用户B里的独占锁由于A 有共享锁存在所以必须等A释放掉共享锁，而A由于B的独占锁而无法上升的独占锁也就不可能释放共享锁，
  
============================ mysql end    ============================

？resume写入记录时失败，
  1、用SHOW PROCESSLIST;命令查看，发现有记录waiting for handler commit
    详见http://blog.itpub.net/29990276/viewspace-2827118/   大概是说磁盘满了写不进去。？怎么查看linux查看磁盘占用情况：
  2、用df -hl命令查看磁盘占用情况：发现有的分区已经写满。 ？那么数据库表数据文件再哪里：
     注意概念：
     Filesystem：文件系统
     Size： 分区大小
     Used： 已使用容量
     Avail： 还可以使用的容量
     Use%： 已用百分比
     Mounted on： 挂载点
  3、用show global variables like "%datadir%";命令查看数据目录，进入后发现caisheng.resume的idb数据文件占25G+  ？那么mysql单库或单表占用磁盘空间最大能多少：

  数据库大数据表备份（服务器没有多余的空间放备份文件，所以似乎不能这样备份）：mysqlhotcopy -u root -p db1 db2 … dbn  详见https://www.aieok.com/article/share/356.html

解决方案：
  物理备份至我的云盘（不安全）
  云服务器扩容（看价格）
  买阿里云数据库（看价格）

*数据库备份之路：（尝试了各种命令工具都有问题，最终用Navicat备份还原轻松简单）
 场景：aliyun服务器磁盘空间105G，剩余25G，但是caisheng数据库大小有25G+，需要进行数据库备份还原。  阿里云linux和本地windows的Mysql版本均为8.0.21
 方法一：（用mysql的ibd数据文件备份还原）
             1、本地数据库新建caisheng数据库和resume表，执行alter table resume DISCARD TABLESPACE，停止本地mysql服务（net stop MySQL80）
             2、复制mysql服务器的/var/lib/mysql/caisheng/resume.ibd到本地，执行alter table table_name IMPORT TABLESPACE，重启本地mysql服务（net start MySQL80）
             结果：执行ALTER TABLE table_name IMPORT TABLESPACE; 报错Error Code:1812. Tablespace is missing for table <table_name> 是因为copy的ibd文件没有赋权，需要chown mysql:mysql table_name.ibd --赋权限
                      但是在windows上不知道怎么更改权限？？
 方法二：（用mysqldump备份还原）详见黑马教程
             1、阿里云服务器执行 mysqldump -uroot -p caisheng > resume.sql 生成resume.sql和resume.txt两个文件（结构和数据）
             2、本地mysql执行show  variables like '%secure_file_priv%'; 查出安全目录，将1步文件放在该目录
             3、本地mysql执行source C:\ProgramData\MySQL\MySQL Server 8.0\Uploads\resume.sql导入结构，再执行mysqlimport -uroot -p2143 C:\ProgramData\MySQL\MySQL Server 8.0\Uploads\resume.txt
             结果：报错：ERROR 3140 (22032): Invalid JSON text: "Missing a comma or '}' after an object member." at position 350 in value for column 'resume.json'.
 方法三：（用Navicat的备份还原工具）
             1、Navicat连接阿里云caisheng库、选中caisheng库点击菜单栏备份进行备份（生成到固定目录C:\Users\Administrator\Documents\Navicat\MySQL\Servers\aliyun）生成caisheng目录，内含20230410134517.nb3和caisheng.nbakmysql
             2、将1步caisheng目录拷贝到C:\Users\Administrator\Documents\Navicat\MySQL\Servers\localhost
             3、Navicat连接本地caisheng空库（非空库也行），选中caisheng库点击菜单栏备份菜单，再界面中点‘还原备份’，则会显示2步中拷贝过来的备份，选中指定备份进行还原即可。
             结果：非常好用便捷

