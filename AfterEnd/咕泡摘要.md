# 咕泡资源
*咕泡学习资料链接 https://gper.club/articles/7e7e7f7ffeg51gc7

*咕泡题库，面试前进行训练 https://gper.club/articles/7e7e7f7ff4g5egc6g6a

﻿* 咕泡学院入学时间：2018.11.1
* James老师电话 18107314019
* 大黄蜂账号 845257580陈向阳   密码127185
* 小炮播放器下载地址：https://pan.baidu.com/s/1qXnxYriA7LbvvmurI_51zw 
提取码：tkah
使用教程：https://gper.gupaoedu.com/gper-doc/tencentKT.html
* git之前是存放源代码跟一些资料链接，所以现在都已经全部放到网盘了呢，git现在已经不用了呢
 咕泡百度网盘地址合集：https://gper.club/articles/7e7e7f7ffeg51gc7
 2017期VIP链接：https://dwz.cn/1SLWcJtF　提取码：gqjh （加密处理）
* **架构课程4.0**
 源码分析专题（Tom/James）
 微服务架构专题（小马哥）
 性能优化专题（James/小马哥）
 分布式架构专题（Mic/Jack）
 并发编程专题（Mic）
 电商项目实战（Mic）
 团队协作专题（James）
* **咕泡资源**（这些资源在换工作及新工作解决问题中都是很好的资源）
 qq群：有众多的学员分享交流
 BBS、ASK、Gper生态圈：学员老师都会回答你的问题、分享面试经验。可以积分，积累经验 。Gper有招聘板块
 老师：主要解决个性问题，如职业生涯，工作碰壁，面试问题，沟通技巧...
 微信公众号：课程提醒、学籍信息、作业提交情况、毕业跟踪等
 GitLab：包含课程源码、问题集锦
 云盘：放置录播视频、预习资料、课后作业
 定期给学员做软实力提升、HR技巧分享、英语提升？？这部分内容在哪
 咕泡分布式架构：看架构图，已经是一个成熟的互联网框架。
 内推机会：对于全国名企有一些招聘需求可以get到
* **gitlab使用学习**
      * 链接：http://git.gupaoedu.com 用户名密码 menyin gdlr...  邮箱8425...@qq.com	
          * 咕泡通过gitlab的项目（your projects）来划分不同的版块，主要模块划：问题区vip/qa、作业区vip/static、公告区vip/nice等
         每个区都是以一个项目的形式存在，其中包括以下版块：
         --Overview 概况
           --Details 详情
           --Activity 动态
           --CycleAnalytics 统计
         --Repository 仓库
           --Files 文件
           --Commits 提交记录
           --Branches 分支
           --Tags 版本或里程碑
           --Contributors 贡献者
           --Graph 图像
           --Compare 对比
         --Issues 问题点
           --List 列表
           --Board 版块？
           --Labels 标签？
           --Milestones 里程碑？
         --MergeRequests 合并需求？
         --Wiki 维基？主要是一些附加的知识点文档
         --Snippets 片段？应该是用于部分代码分享，即“Snippet support”功能
         --Members 参与的成员
          * github、gitlab的.md文档，issue都使用Markdown语法，可以下载typora编辑器进行编辑（intellij亦可）。学习https://www.jianshu.com/p/191d1e21f7ed
          * 在qa区中发issue时，右边有个todo面板，可以设置label来标志紧急程度

* 计算咕泡的总课时安排学习计划（和淘淘对比下）
   课程大致分为：常用框架源码解析、分布式、微服务架构、jvm及性能优化、并发编程
    ？先博后专、？思维方式、？先总结规整知识要点整合taotao+jeesite、？将近期学习实践的要点梳理一遍、问题找咕泡讨论一遍


* **咕泡课程学习注意**（整套课程一定要多实践）：
 分布式课程（2-3个月）最好是看直播，有一些问题可以直接提出。结合架构图进行学习
 微服务课程（1个月）会涉及spring源码，因此在此之前要学完spring源码部分
 多线程、并发、性能优化涉及jvm，因此在此之前要学完jvm
 实战项目是穿插在各个部分的课程中

* **问答流程**：vip群聊、gitlab/qa、私聊老师。以后可以简历指导和面试指导

* **翻译小组**，可以学习英文技术文档 http://git.gupaoedu.com/vip/nice/wikis/%E7%BF%BB%E8%AF%91%E5%B0%8F%E7%BB%84

* **咕泡生态圈** https://gper.gupaoedu.com/

* Tom老师和我的技术路线基本一致，喜欢思考，个性也比较像，喜欢艺术，哈哈

* Mic等老师用了一款在线绘图工具，很方便，可绘制流程图、思维导图、原型图、UML、网络拓扑图、组织结构图等。详见 https://www.processon.com/

* 前人经验：https://gper.gupaoedu.com/articleContent?id=26    https://102.alibaba.com/downloadFile.do?file=1530517140411/Codelife.pdf

？《5月下旬学习指导.mp4》22分提到明天下午有英文课程，是指什么课程？

Tom老师，你好，
   想找您咨询下一些问题，我的情况大致如下：

   * java开发七八年，主要还是传统项目，今年更多的是做前端的工作。
   * 对互联网分布式技术有一定了解，能自己用zookeeper、dubbo、nginx等搭建出基础分布式的架构环境。
   * 知识有一定体系，技术涉猎有java、C#、前端，总体知道自己该如何学习进步，但缺乏互联网经验。

？找各个老师交流下：
  * 英文水平不是很好，看英文技术文档都是用翻译软件，提升这方面能力有什么建议，技术文档有没有一些格式和套路。
      因为学习一些技术的时候，通常都是找找视频教程和中文文档，然后有时候要折腾很久。
      james答：花一个月硬啃技术官网：http://spring.io/  https://spring.io/projects/spring-framework
  * 硬件和网络方面的知识也比较欠缺，有什么建议
  * 11月半路出家，从哪部分开始切入好，还是从头开始看录播。我工作相对比较轻松，时间也充足。（老师似乎建议直接跟直播，后面再挑着看录播）
  * 很多技术问题会知道如何解决，也能很快的判断出大致的原因，但要找找资料，这个算基础薄弱吗？需要改进吗？ 
  * 如何去模拟高流量，高并发，让自己能更多学习到实际场景中的一些问题。（老师建议不断思考场景，不断想象，不断折腾，参与到互联网公司环境，建议跳槽）
  * 我在厦门，这里的名企不多。而我就职的公司又属于半传统半互联网的公司，互联网技术经验不够，我想进这些名企，有什么建议。
  * 在一个具体的城市，如何定位自己能力和这个城市这个职业的薪资水平，有哪些点需要注意。
  * 电商实战项目，云服务器要不要提前买下，快到双十一了
  * 全国分舵有线下交流活动，厦门这边好像是没有，能不能组织下。

 * 和Tom聊天如下：
    我：
    1、英文水平不是很好，看英文技术文档都是用翻译软件，提升这方面能力有什么建议，技术文档有没有一些格式和套路。
   因为学习一些技术的时候，通常都是找找视频教程和中文文档，然后有时候要折腾很久。
    2、硬件和网络方面的知识也比较欠缺，有什么建议
    3、11月才加入咕泡，从哪部分开始切入好，还是从头开始看录播。我工作相对比较轻松，时间也充足。
    （入学指导视频中，老师似乎建议直接跟直播，后面再挑着看录播）
    4、很多技术问题会知道如何解决，也能很快的判断出大致的原因，但要找找资料，这个算基础薄弱吗？需要改进吗？ 
    5、如何去模拟高流量，高并发，让自己能更多学习到实际场景中的一些问题。
    （入学指导视频中，老师建议不断思考场景，不断想象，不断折腾，参与到互联网公司环境，建议跳槽）
    6、我在厦门，这里的名企不多。而我就职的公司又属于半传统半互联网的公司，互联网技术经验不够，我想进这些名企，有什么建议。
    7、在一个具体的城市，如何定位自己能力和这个城市这个职业的薪资水平，因为我从事互联网方面的朋友不多，所以比较没人可交流。
    Tom：
    1、英文文档其实很简单，坚持记单词，时间久了就有感觉了。技术类的文档，对口语和书写没有任何要求，只需要能看懂就行。
    2、硬件知识可以去看看运维相关的教程
    3、先看设计模式、源码专题、和分布式专题，如果时间充裕可以先跟直播
    4、提升技术解决效率，需要提升思维能力
    5、利用阿里云或者虚拟机，自己搭建一个比较固定的分布式环境，重在实操
    6、进名企要去一线城市，可以找找所在城市的分公司
    7、了解行业水平可以去各大招聘网站，看招聘需求。现在来了咕泡，要好好利用好这个圈子。

## ----------------------------  2019课程 begin -------------------

* james
2017 1k+学员
2018 3k+学员
* mic说
 3期可能增加 训练营方式，创建一个21天的临时群做任务。
 学习方式：知识链，知识体系。推导式
 提到的东西：ConcurrentHashMap、阻塞队列、
 跳槽频繁差不多一年一次，清楚自己的方向。
 阿里P8 可能不只是技术可能还有30%的产品思维、管理能力等
 面试过程中，如果遇到一个需求问题，首先需要了解好动机、需求、目标（性能、并发等），场景等，最后在做方案细则。
* tom说
 增加创业扶植项目源码

## ----------------------------2019课程 end-------------------

* 版本冲突后

* 测试直接test分支开发的问题、测试test分支再分出dv1分支开发的问题。

* 测试版本回退与当前版本
 三期课程大纲，注意和一二期对比
 课程体系：内功心法.....


？Jenkins如何做到实时提交单独的文件

## --------------------设计模式 begin----------------------------

* 单例模式中的饿汉模式能保证线程安全，即在多线程并发访问该实例都是同一个对象
 而懒汉模式则不能，因为它是延迟创建实例机制，所以多线程同一时刻有可能创建多个实例。

* 懒汉模式用synchronized解决线程安全问题时，在创建实例的时候性能很低。
 懒汉模式用内部类解决线程安全和性能低问题，但会有单例反射攻击问题可以参照LazyThree类处理

* 序列化实现单例，要求被序列化的类添加readResolve方法，以保证反序列化时是同一个对象。相对比较复杂

* 最科学最推荐的单例实现方案是内部类实现法。此法需要放反射构造函数注入，需要用final固定死getInstance方法
 ？在此法中，如何在防反射构造函数攻击时使用到标志变量，此时又该如何防止此标志变量被反射攻击呢。
   tom直接将这个标志变量设置成非静态的即可，即必须有实例才能访问。

* 双重检查锁定（这种方式是比较常用的一种方式） if (instance == null) {synchronized(）{if (instance == null) {xxxx}}} 
 详见CSDN收藏《Java单例模式中双重检查锁的问题》 https://blog.csdn.net/chenchaofuck1/article/details/51702129

* 在动态代理实践中，在intercept拦截方法内部断点，监控到代理生成对象时会调用它的toString方法，
 因此这个拦截方法会再多被执行一遍，而且不会走到你打的断点处，感觉莫名其妙，但其实很合理。

* 动态代理后的代理对象无论怎么转换还是直接用Object接收，其getClass()都是com.sum.proxy.$Proxy0类型，非常重要
 这也是Proxy.isProxyClass()方法的判断依据

* 动态代理，其实是生成一个目标类或接口的代理对象，这个代理对象所有方法（即目标对象对应的方法）里都是调用Invocation实例的invoke方法
 并且把当前代理对象和目标对象的方法及参数传递过去。在代理对象类的invoke方法里，一般就是添加一些附加逻辑代码
 然后在将目标对象的原始方法执行一遍（即将原始方法invoke以下）
 其实这个代理对象的类是动态生成类字节码（字节码重组）然后加载到内存，这个动态类一般都是$ProxyX,X是数字，$ProxyX是继承java.lang.reflect.Proxy

* 明白动态代理原理后，应该知道如果目标对象有私有成员变量，如name，但代理对象是没有name这一变量，但是如果目标对象遵循java get set规范
 则代理对象会有getName和setName方法。所以在spring环境下的bean要反射得到私有成员变量不能通过Field而应通过Method，这就是Tom老师的方式
 **所以一般不管jdk代理还是cglib代理都一般都代理类而不是代理具体的实例，而cglib即使可以代理实例，但也是代理实例的方法，而成员变量是“拿”代理对象的还是原对象要特别注意。


* JDK中有个不成文的规范：只要是带$开头的类就是自动生成的，如$Proxy0

*method.invoke(obj,args)调用时注意，method指向的类型必须是obj实例的类型或父类，否则会报错。 这也是比较符合逻辑的

* 委派模式其实就像一个不干事的中间调度器，Spring中带有Dispatcher、或Handler的一般是用委派模式

* 在java中带Decorator或Wrapper的类都是采用装饰器模式，或者说是包装器模式

*注意适配器模式和装饰者模式的区别：
 适配器模式注重通过扩展旧的类型来使新的数据能适应就类型方法的数据要求
 装饰者模式注重于在一个新的类中将旧的类实例传入，对就类实例的方法进行加工扩展，比如游戏放大招方法增加发光效果。
 java中适配器类型处理的旧类型经常会用@Deprected标记过时类或过时方法

* 观察者模式≈发布订阅模式≈事件模式  
 Spring中的ApplicationListener就是观察者模式

* Spring常用的几种编程思想：AOP、OOP、BOP、IOC、DI  具体看咕泡的截图摘要
 Spring加载步骤：定位，载入，注册，再确定要不要初始化Spring

* 各种设计模式的区别看《咕泡学院_Tom_JavaVIP课程_Spring源码分析(第二版)_第一章.pdf》

* 多线程测试demo中常用countDownLatch，类似loadrunner里的集合点。 可以阻塞主线程，然后都其它线程达到计数器的数后才继续执行主线程。


？复习下 java封装、继承、多态的几种实现方式，如抽象...


？咕泡还介绍了一种在java类里对进行注解以获取sessionfactory的使用mybatis形式，如MybatisConfiguration.java

？注册式实现单例时，使用ConcurrentHashMap还是不能保证单例安全，怎么解决

？实践：
  懒汉模式下保证线程安全，用synchronized，性能问题
  synchronized，这个关键字需要学习
  内部类的初始化过程、java类加载过程原理
  反射入侵是个什么问题
  枚举类
  Vector 

？通过反编译工具ProxyGenerator来获取动态代理生成的代理类的字节码，然后输出到文件中
？策略模式中具体的策略能不能放入Spring的ioc容器，在代码中用ioc容器获取多个具体策略实例
？实践用intellij查看接口的实现类图

## --------------------设计模式 end------------------------------

## --------------------Mybatis begin------------------------------

* lombok  可以通过一些注解使得书写类代码时省略掉 get、set、toString等方法，但实际是有生成的。

* mybatis使用的代码生成器generator生成的会生成一个XxxExample，它会将开发者书写的条件生成sql然后执行。
 对于开发者是好事，但会有一些问题，不推荐使用。

* sqlsession是线程级别或者说是request/response级别的，也就是说这个sqlsession是存活在一次web请求中的。
 sessionfactory是application级别的，是整个web应用启动后创建并存活的。
 ？一个service多个dao是在一个线程里吗？ 

* mybatis的sql语句可以书写到mapper类的注解或者mapper.xml，这两种方式可以兼容吗  
  ！是可以的，但是这种方式里的id不能一样。如mapper.xml有<sql id="getUserById"/> 那用注解的mapper类就不能再有getUserById方法
  一般我们也不会将sql语句写到mapper类的注解里，如果sql复杂则mapper类很混乱，不好维护。

* mybatis插件原理学习：
 * mybatis原理请看CSDN收藏《Mybatis之工作原理》、博客园收藏《【MyBatis源码分析】插件实现原理》 
 * 使用时可看官网文档，并且像mybatis-config.xml可查看其DTD文件
 * 结论：1.mybatis插件中@Intercepts是描述定位了要拦截的类和方法
        2.intercept(Invocation invocation)是提供了一个拦截点供实现，其中invocation包含了当前目标拦截的方法的实例、参数等信息
          invocation.proceed();即执行了当前目标拦截方法（原有的）。在此我们可以做要拦截的处理。
        3.plugin(Object target)中target即要包装的目标实例。在此方法中一般我们用return Plugin.wrap(target,this);直接返回当前
          拦截器作为代理对象。其实也可以自己通过对target的做代理包装，然后返回，此时intercept(Invocation invocation)可直接
          用return invocation.proceed();
 * 整个过程：mybatis用ExamplePlugin1.plugn()包装后的对象作为原始对象的代理对象，然后执行相关方法时其实是用ExamplePlugin1.intercept()执行

* 嵌套查询和嵌套结果
 嵌套查询，指在resultMap里嵌套通过当前查询结果的外键字段再去映射另一个mapper里的sql查询，已达到关联查询的目的
           会产生1+N次查询问题，产生性能问题。 如果要避免无谓的查询，可以用懒加载。
 嵌套结果，指在一个mapper里就把主实体和关联实体的字段通过join方式一次性查询出来，并映射到resultMap上，已达到关联查询的目的

* 在spring web环境下，一个request就是一个线程(但一个线程可能对应多个request，因为tomcat使用线程池)，并且controller、servic、dao都是单例，但此时sqlsession是通过ThreadLocal实例和当前线程绑定的
 注意一个service里可能用到多个dao，但他们应该都是同一个sqlsession。但是每个dao应该都知识有一次连接（即connection）

* mybatis的二级缓存是以实体的命名空间为单元的，如Student 完全限定名为com.cny.Student，则以此为单元。当这个单元的任何内容有增删改才会清除这个单元的缓存
 如：其中有一个getStudenById，那它的缓存key应该大概就是com.cny.Student.getStudenById。
 注意，如果getStudenById结果集关联包含Teacher，则Teacher的也是缓存在com.cny.Student.getStudenById这个key下。 此时如果去增删改com.cny.Teacheer单元的缓存
       则com.cny.Student.getStudenById里的Teacher是不会被更新的，即会有脏数据。

* method.getDeclaringClass()调用方法的getDeclaringClass()是获取方法的声明类型

* jdk1.8后接口中可以用default修饰方法，相当于C#中的虚方法有默认的实现
 这样要扩展接口方法后，之前已实现该接口的类不会受到影响，否则编译会报错。

* mybatis架构几个重要的类或接口
 Sqlsession    代表一次会话
 Configuration  所有配置信息
 Excutor   代表一个执行器，它负责如何调用执行StatementHandler（会传入mappedStatement实例）
 StatementHandler 持有MapperStatement、ParameterHandler、ResultSetHandler引用，最终还是调用mappedStatement执行sql
 ParameterHandler 
 ResultSetHandler
 TypeHandler 会被ParameterHandler、ResultSetHandler引用
 BoundSql
 MapperStatement 真正执行sql的东西
 MapperProxy 对于业务dao接口的代理工具

* * 一般一个抽象类实现一个接口，通常是用到了模板模式。即抽象类对接口规约的方法的实现里包含了一些流程（如a->b->c）。
 此时a、b、c又被抽象类定义为抽象方法供子类实现。相当于子类参与了整个流程的一部分，即模板模式。
 注意：mybatis大量使用这种设计模式。如果这个接口有多个抽象子类，则相当于有多个分类。
 注意：Executor、CachingExecutor、BaseExecutor就属于这种情况

* BaseExecutor#query第1行代码什么意思，课程上没听明白。
* ErrorContext就是利用ThreadLocal变量记录当前线程的相关信息，包括执行到哪、以及报错信息等。等到程序出错时则可以输出这些信息。
* ErrorContext的工作过程， 和Exception一直往上抛后内存溢出问题有什么关系。
  《VIP-20180331-源码分析之3.3源码解读.vep》48分处有讲解到
 寻找答案的过程：
  1.明白它的作用后，我构造一个mybatis使用过程中的错误，即在执行查询方法前，将sqlsession关闭。
  2.此时在ErrorContext的toString方法上打断点，当进入到该断点就可以查看它的调用栈了。

*  sqlsession、excutor、configuration、StatementHandler、ResultsetHandler、MapperProxy的关系。
  * 查看excutor的类层次关系，发现它归为2大类CachingExecutor和BaseExecutor。
   而CachingExecutor是用于装饰BaseExecutor的子类，使之拥有缓存功能。
  * sqlsession持有excutor和configuration实例，然后将相关工作交给他们两去做
   SqlSessionFactory在创建sqlsession之初会先创建configuration，再由configuration生产excutor
   然后将configuration和excutor交给sqlsession，sqlsession尽情的调用这两个去实现功能。
  * MapperProxy.invoke()时 调用sqlsession调用cexutor调用StatementHandler调用ResultsetHandler

*MyBatis事务管理的两种方式：jdbc 和manage（交个第三方去管理，如spring）

*注意：mybatis的dao接口不能重载，因为参数列表对应到mapper.xml文件里的sql语句里的参数，而在执行前是不知道sql语句里有什么参数和参数类型。

？UML图的学习


？spring环境下mybatis的mapper类即dao类是单例，是如何实现的
  这里注意数据库的connection是肯定是多例
  如果说并发很高，一个request就对应一个数据库连接吗 
  ！mysql的最大并发连接数跟硬件配置有关也跟所做操作和服务配置有关：


？BaseExecutor#queryFromDatabase 322行这行代码的意义
占位符，当延迟加载时，会先判断一级缓存中是否存在结果，如果没有结果或者为占位符，则将此延迟对象加入延迟队列，
否则直接从一级缓存中获取结果

？UML图的学习

？梳理调试StatementHandler、ResultSetHandler等过程。


*Mybatis-Plus
 *现在有一种AR模式，Mybatis-Plus也有提供，其实就是将通用的方法都集成到Model实例中，但很多不推荐这样做。
  因为java通常分层架构，不推荐。  而jeesite里面其实也有这样的处理。
 
 *条件构造器在构造相对复杂的条件时，应该就相对不好操作。 

 *计划学习任务：MybatisPlus查询相关API，lombok相关API、
 

## --------------------Mybatis end------------------------------

## --------------------Spring begin------------------------------
*spring的bean相关
    *bean加载方式
        *xml方式定义
        *一般注解方式定义（前提：需先定义一个类(如SpringConfig)并用@ComponentScan注解，IOC容器用new AnnotationConfigApplictionContext(SpringConfig.class)）：
            自己的bean：指定扫描bean的范围，然后用@Component、@Controller等注解类
            第三方bean：@Configuration（也可以用@Component）注解一个类（如DbConfiguration）并用@Bean注解类方法，则方法返回类对象就会被注入到SpringIOC。  
            注意：@Bean注解的方法名就是bean的名字，返回值类型就是bean的类型（如果返回值类型是一个FectoryBean接口的实现，则返回值类型就不是注入bean的类型）。
                  @Configuration和@Component是有区别：功能都差不多一样，前者名称更加专用。另外前者有如下配置：
                  @Configuration(proxyBeanMethods = true) //当proxyBeanMethods = true则applicationContext.get("springConfig").cat()执行n次返回的是同一个Cat对象，反之是多个Cat对象
                  public class SpringConfig{              //并且proxyBeanMethods = true时，IOC里的SpringConfig对象是一个cglib代理的对象，反之则SpringConfig对象原始对象。
                    @Bean                                 //注意：如果cat()方法没有用@Bean则applicationContext.get("springConfig").cat()执行n次返回的也是n个Cat对象。
                    public Cat cat(){return new Cat();}
                  }
                 

        *混合方式：
            场景：老项目采用xml配置了一些bean，现在对老项目要进行一些bean扩充，并且用的是注解方式。怎么将xml里的bean也加载进来呢？
            方案：@ImportResource("aplicationContext.xml")  //这里就会将老项目xml里的bean也加载进来。
                  public class SpringConfig(){....}          
            注意：如果xml导入的bean和配置类里注入的bean冲突了怎么办？ 谁覆盖谁？
        *@Import注解（经常用到）
            如：@Import({Cat.class}) 
                public class SpringConfig{...}
           注意：注入IOC的Cat对象名称是一个全路径类名儿不是"cat"
                 用此方式，Cat类并不需要用@Component等注解，就比较干净，而且解耦。
                 用此方式的bean如果是配置类（不管配置类有没有加@Configuration注解）则配置类里注入的bean也会被导入到IOC容器
                 用此方式注册多个bean时是按书写顺序依次加载注册的。
                 注意此注解也可以用在自定义注解类里，并且可以结合ImportSelector接口、ImportBeanDefinitionRegistrar接口使用
        *IOC容器对象注册：
           applicationContext.registerBean("tom",Cat.class);//如果多次注册则后面代码注册的会覆盖前面注册的。
           applicationContext.register(Cat.class);//这种方式注册的bean的名称是类名小写
           注意applicationContext是AnnotationConfigurationApplicationContext对象，其它IOC容器类型对象不能注册对象。
        *ImportSelector接口注册（动态加载bean，很多框架用到）：
           通过实现接口方法selectImports(AnnotationMetadata metadata)，返回要注册bean的全路径类名数组，spring就会去加载这些bean。
           当然ImportSelector接口实现类要先通过@Import或其它方式注入到springIOC。
           注意：metadata参数是@Import注解的类的元数据信息。通常应用实践是根据这些元数据信息判定是否要注册指定的bean
        *ImportBeanDefinitionRegistrar接口注册（动态加载bean，很多框架用到）：
           通过实现接口方法registerBeanDefinitions(AnnotationMetadata metadata,BeanDefinitionRegistry registry),用registry.registerBeanDefinition()方法注册
           原理基本和ImportSelector接口注册方式是一样的。 只是更加灵活更加动态。
        *BeanDefinitionRegistryPostProcessor接口注册
           该方式也是通过相关的接口方法进行bean的注册
           但它是在其它常规bean注册方式执行注册完后进行的后置注册。
           如：@Import注解注册多个bean是有序的，但如果@Import注册的bean有BeanDefinitionRegistryPostProcessor接口实例，则通过该接口实例注册的bean则是最后注册，有可能覆盖已注册bean           
        注意：springIOC的bean的名称形式有很多种："注解或代码或xml自定义名"、"UserDao"、"com.cny.UserDao"、"com.cny.UserDao#0"、"com.cny.UserDao$xxxcglib#0xxx"、"tools.ip-com.cny.UserDao"等等，其它需要再研究??               

    *bean加载控制
      在众多bean加载方式中，有的是可以动态加载bean有的是不行。所谓的bean加载控制指的就是能不能动态的选择是否加载bean。
      *@Conditional
       该方式需要自己实现指定接口来编写相应的控制逻辑，spring只定义规范没做实现。 但是在springboot中有很多实现，比如@ConditionalOnMissingClass。？如何查看这些注解  ！！intellj里用ctrl+H
       使用：@Conditional可以用大部分加载bean的地方
       注意：ConditionalOnClass和ConditionalOnBean的区别：前者是有类，后者是springIOC里有已注册bean
	     ？如何查看@Conditional的派生注解：到@ConditionalOnClass所在包查看相关注解。！！intellj里用ctrl+H
         ？bean通过@Conditional控制加载的原理     
    *bean依赖属性配置
      即springboot的starter那个属性映射配置类（如CatProperties类）
 注意：如果定义bean时候没有命名，则spring会以"全路径类名#0"的格式给bean命名


*SpringBean的生命周期：
 bean实例化阶段：spring会先取出BeanDefinition进行判断是否singleton，是否延迟加载，是否是FactoryBean，最终将singleton类型的bean进行反射实例化；
                 注意：如过singleton为false则或者延迟加载为true，则不创建实例，而是在getBean()调用时创建
 bean初始化阶段：此阶段对bean实例进行:属性填充->执行Aware接口方法->BeanPostProcessor前置方法->InitializingBean接口方法->init方法->BeanPostProcessor后置方法。实际上都是对bean的加工处理。
                 bean的属性注入有分几种情况：
                                            注入普通属性：如String类型，直接反射创建字符串并通过set()注入
                                            注入单向对象引用属性：如beanA单向依赖beanB，则创建beanA时会先去springIOC找beanB
                                            注入双向对象引用属性：如beanA和beanB相互依赖，则创建它们后还都要重singletonObjects里获取对方，造成死循环。
                                                                  解决方案：三级缓存，即beanA创建但未填充时（半成品）会根据阶段先分别存入三个Map缓存，beanB做依赖填充时先到singletonObjects找，没有则到暂存区找。
                                                                            三个Map分别是singletonFactories（存未被引用过的半成品bean）、earlySingletonObjects（存被引用过的半成品bean）、singletonObjects（存最终完整bean）
                                                                            整体过程：将bean从三级缓存依次移动到一级缓存（即singletonObjects）。其中三级缓存里的bean只要被获取过就代表被引用过，就会移到二级缓存。 
                 注意：该阶段是spring最具技术含量和复杂度的阶段，aop增强功能，注解功能，循环依赖都是在这阶段
                 常用的Aware接口：ServletContextAware、BeanFactoryAware、BeanNameAware、ApplicationContextAware
 bean完成阶段：经过初始化阶段构造了完整的springBean后，最后就是将它存储到singletonObjects里。
 整体流程：
    1、Spring通过xml或注解方式将bean的信息beanDefinition注册到beanDefinitionMap里（xml是直接扫描类添加beanDefinition到beanDefinitionMap，而注解方式则是通过beanDefinitionRegistryPostProcessor后置加入beanDefinition）
    2、在beanDefinitionMap初次填充完后，会执行beanFactoryPostProcessor（beanDefinitionRegistryPostProcessor是其子接口），可以在此阶段对springIOC进行处理，如beanDefinitionMap进行修正或增补
    3、根据beanDefinitionMap里每个beanDefinition进行bean实例化，大致过程：属性填充->执行Aware接口方法->BeanPostProcessor前置方法->InitializingBean接口方法->init方法->BeanPostProcessor后置方法。
    4、在3步中，实例化好未被引用的半成品bean，实例化好被引用的半成品bean，完全实例化成品bean会分别存储在三级，二级，一级Map中，其中一级就是singletonObjects对象。
    注意：实际上springAOP的实现是通过BeanPostProcessor实现的，即AOP实际上是发生在第3点的BeanPostProcessor后置方法执行阶段。spring为AOP注册的AnnotationAwareAspectJAutoProxyCreator实例实际是BeanPostProcessor实现
*Spring注解
 bean的注册注解：
  @Component注解：对比xml的<bean/>标签少掉的属性变成注解(scope = @Scope、lazy = @Lazy、init-method = @PostConstruct、destroy-method = @PreDestroy、abstract = 、autowire = 、factory-bean、factory-method)
  @Component衍生注解：@Repository  在dao层使用
                     @Service     在service层使用
                     @Controller  在controller层使用
                     只是名字带语义，功能和@Component是完全一样的。
 bean属性注入注解：
  自定义bean注入：
    @Value 用于字段或方法（如set方法）或方法参数上，注入普通数据，如String类型数据
    @Autowired 用于字段或方法（如set方法）或方法参数上，根据类型注入引用类型数据,如同类型有多个bean则按名称匹配注入，找不到则报错
    @Qualifier 用于字段或方法（如set方法）或方法参数上，结合@Autowired，根据名称注入。要和@Autowired一起使用，不能单独使用(除非在方法参数上使用)。
    @Resource 用于字段或方法（如set方法）或方法参数上，根据类型或者名称注入（二者可选），默认是依次根据类型和名称注入。它是属于Java的注解，但是Spring也提供相应的解析注入实现
    注意：这些注解用在方法上，其实是根据方法的参数进行匹配的 如 public void myMethod(List<User> userList){...}//此方法会将SpringIOC里User类型的bean注入到userList里
  非自定义bean注入(第三方框架的bean)：
    @Bean 用它注解的方法相当于一个产生bean的工厂方法。方法返回的bean将被注入到springIOC。但是该方法所在类必须是一个SpringBean
          注意：如果@Bean不指定名称，则将以方法名作为该springBean的名称
                如果@Bean修饰的方法里有参数并且是SpringBean，则Spring会根据类型将对应类型的springBean注入。 当然也可以用@Value或@Autowired等属性注解修饰

 xml配置相关替换注解：
   @Configuration 两个作用：标注这是一个配置类（用于替代xml）、它包含@Component的作用
   @ComponentScan 组件扫描，相当于xml里的<context:component-scan/>  可以指定扫描范围
   @PropertiesResource 属性导入，相当于xml里的<context:property-placeholder/> 可以引入xxx.properties文件
   @Import 导入注册bean，相当于xml里的<import/> 将其它类通过该注解实现SpringBean注册
           可以导入三种类：
               普通的配置类：开发人员用的比较多
               实现ImportSelector接口的类：该接口的selectImports()返回的类全限定名字符串数组是用来注册到SpringIOC的
               实现ImportBeanDefinitionRegistrar接口的类
 
 其它注解
   @Primary  用于标注同类型bean优先被使用权（在属性注入时），是Spring3.0引入的。 须与Component或@Bean一起用。
             注意在@Autowired或其它注解中，是依次按类型和名称匹配注入bean，但是如果多个同类型bean中有@Primary优先注入，则@Autowired不再做名称匹配注入
   @Profile 用于切换环境，如test环境（代码中设置环境可以用System.setProperty("spring.profiles.active","test"）
 
 注解注册bean原理：xml是直接扫描类添加beanDefinition到beanDefinitionMap，而注解方式则是通过beanDefinitionRegistryPostProcessor后置加入beanDefinition
                   注解方式里会先将一些预制的xxxPostProcessor类实例添加到beanDefinitionMap里，
                   xxxPostProcessor大致分为beanDefinitionRegistryPostProcessor和beanPostProcessor两类：前者目的是将注解的bean扫描补充到beanDefinitionMap，后者是对bean的属性依赖进行注入
                   所以这些xxxPostProcessor会进行相关beanDefinition的注册，后续再执行bean实例化从而实现注解注册bean


*Spring的xml自定义命名空间
 第三方框架在xml里有特定的自定义标签，需要相应的命名空间，指定对应的解析器。如何自定义命名空间：
 1、新建META-INF/spring.handles文件，它里配置了对应命名空间的解析器类
 2、新建解析器类实现对应的接口。当然不同的标签可以分别在注册各自小的解析器类。
 3、新建META-INF/spring.schemas文件，它里面配置了xml dom标签书写规则
 
*AOP
 XML使用方式：
   切点表达式的配置方式：
      直接配置：<aop:before ... pointcut="execution(void com.cny.service.impl.UserImpl.show())"/>
      单独配置再引入：<aop:before ... pointcut-ref="myPointcut"/> //将上面的pointcut内容抽出来配置在myPointcut里然后引用。

   切点表达式的配置语法
      execution([访问修饰符]返回值类型 包名.类名.方法名(参数)) 
           范文修饰符可以省略不写
           返回值类型、每一级包名、类名、方法名可以使用*表示任意
           包名与类名间用单点.表示该包下的类，用双点..表该包及其子包下的类
           参数列表可以使用两个点..表示任意参数
      其它方式先不用学习
   通知类型
      前置通知：before  目标方法执行之前执行
      后置通知：after-returning  目标方法执行之后执行，目标方法执行报错，则该后置通知不执行
      环绕通知：around  目标方法执行前后执行，目标方法执行报错，则该环绕后通知不执行
      异常通知：after-throwing 目标方法抛出异常时执行
      最终通知：after  无论目标方法是否有异常，最终都会执行
   通知方法被调用时，spring可以为其传入一些必要的参数
      JoinPoint  连接点对象，任何通知类型方法都可用。用连接点对象可获得当前目标对象、目标方法参数等信息
      ProceedingJoinPoint JoinPoint子类对象，主要是在环绕通知中执行proceed(),进而执行目标方法
      Throwable 异常对象，使用在异常通知中，需要在配置文件里配置异常对象名称
   AOP配置的两种方式 
      使用<aop:advisor>配置切面：需要实现Advice接口（实际上使用都是使用Advice的子接口，如MethodBeforeAdvice）。如事务通知就是用这个方式
           在代码中的体现就是advisor（织入类）、advice（切面类）、pointcut（切点类）三个对象。advisor持有advice、pointcut两个引用。
           切面类advice有很多子接口来实现固定的织入逻辑，如前置通知MethodBeforeAdvice
           此部分可以看dynimicDataSource配置类源码的DS原理源码，大概逻辑：
              1、配置类配置一个advisor（实际是DynamicDataSourceAnnotationAdvisor实例）进行AOP，对有@DS注解的方法进行环绕通知，方法执行前后将@DS信息存储和移除到ThreadLocal
              2、配置类通过beanPostProcesser对dataSource实例代理（最后是DynamicRoutingDataSource实例），代理逻辑理：判断ThreadLocal里有DS信息则用DS指定数据源，否则用主数据源。
      使用<aop:aspect>配置切面(常用) 相对灵活
   AOP原理：
      总体过程：自定义aop相关命名空间，然后在相关的处理器里注册BeanPostProcessor接口实例的BeanDefinition，通过BeanPostProcessor来“改造bean”实现AOP功能
              所以AOP实际上是发生在BeanPostProcessor后置方法执行阶段。spring为AOP注册的AnnotationAwareAspectJAutoProxyCreator实例实际是BeanPostProcessor实现
      两种代理：
         JDK动态代理：要求目标类有接口，是默认方式
         Cglib动态代理：要求目标类不能用final修饰。目标类无接口时默认使用该方式。
 
 注解使用方式：
   和XML有相应的对应注解，如：
   @EnableAspectJAutoProxy = <aop:aspectj-autoproxy> 开启aop功能  
   注意：通知注解可以和@Pointcut注解配合使用。详见bilibli黑马spring课程92课9分0秒
         

Spring事务：
  事务使用方式：
    编程式事务控制 xml配置，比较麻烦
    声明式事务控制 直接类或方法上用@Transaction(...)即可。注意和aop一样要再配置类加一个功能开启开关@EnableTransactionManagement（xml对应<tx:anotation-driven/>）
  事务控制相关类：
     平台事务管理器 PlatformTransactionManager  是个接口标准，实现类都具备事务提交，回滚，获得事务对象的功能，不同持久框架有不同实现。
     事务定义 TransactionDefinition  封装事务的隔离级别，传播行为，过期时间等属性信息
     事务状态 TransactionStatus  存储当前事务的状态信息，如事务是否提交、是否回滚、是否有回滚点等。
  事务属性设置（即使用时相关设置）：
     隔离级别（isolation）：解决脏读、不可重复读、幻读
     传播行为（propagation）：解决事务嵌套问题，serviceA调用serviceB,事务用A的还是用B的，还是用同一个。 常用的是默认的REQUIRED，偶尔用SUPPORTS
     超时时间（timeout）：超时则报错
     是否只读（onlyread）：设置方法是否只读。 注意：更新操作的方法不能设置只读

Spring事件：
    Spring提供了以下5种标准的事件：
      ContextRefreshedEvent：IOC容器刷新触发，即所有对象创建完成调用
      ContextStartedEvent：IOC容器开始或重新开始时触发
      ContextStoppedEvent：IOC容器停止时触发 
      ContextClosedEvent：当ApplicationContext被关闭时触发该事件。容器被关闭时，其管理的所有单例Bean都被销毁。
      RequestHandledEvent：Web环境里一个http请求（request）结束触发该事件。如果一个bean实现了ApplicationListener接口，当一个ApplicationEvent 被发布以后，bean会自动被通知。
   
   注意：
      开发者还可以定义自己的事件（如MyEvent extends ApplicationEvent），并自定义触发时机（自己调用）。那么实现ApplicationListener接口的bean也能接受到事件。
      spring事件执行默认都是同步的（即同步事件），变更方法：
	全局变更通过自定义的SimpleApplicationEventMulticaster子类bean来变更为异步事件（注入线程池taskExcutor属性即可，它内部会判断选择同步或异步）；
	局部变更：用@Async("executor")注解事件体方法（如onApplicationEvent），这样在调用该方法则会用线程池异步调用。“executor”为自定义线程池名
      LifecycleProcessor接口：其实就是可以自定义一个实现类放到springIOC，它会覆盖默认的实现类，从而达到对生命周期的一些关键节点进行干预（如start、stop等）。个人感觉也是一种事件机制

SpringWeb整合：
  web三大组件：
     Servlet：服务端小程序，负责请求响应。 单例，默认首次访问创建，创建完执行init(),每次访问都执行service()。缺点一个业务功能就需要配置一个Servlet
     Filter：过滤器，过滤web请求。 单例对象，服务器启动时创建，创建完执行init()，每次访问执行核心过滤方法doFilter()
     Listeniner：监听器，监听域对象的创建销毁及属性变化。不同类型不同监听作用。主要监听三大域：Request、Session、ServletContext（服务启动时创建）
  web架构演进：
     初期用Servlet，每个业务都写一个Servlet。然后里面初始化springIOC对象applicationContext。然后springIOC中获取相关service的bean进行业务操作
       问题：applicationContext每次都创建，我们希望一个应用只创建一次 
             每次访问都能通过单例的applicationContext获取需要的bean 
             applicationContext需要在web层任何位置都能获取到 
       解决：监听ServletContext创建applicationContext并放到ServletContext域里，从ServletContext里获取applicationContext继而可以获得bean
             这些spring-web已经帮我们架构好了。
       常用的类：webApplicationContextUtil（用于获取web的springIOC容器）
       问题：每个请求都对应一个Servlet
             每个Servlet业务操作太繁琐
             Servlet获取springIOC代码不够优雅
       解决：使用springMVC      
   springMVC
       九大组件（视图视图名，映射及适配、主题和本地、flash和file、异常解析：视视映适，主本ff，异常解析）：常用的是HandlerMapping、HandlerAdapter、ViewResolver。这些都是接口，具体实现在spring-webmvc包里DispatcherServlet.properties配置
                 org\springframework\spring-webmvc\5.2.10.RELEASE\spring-webmvc-5.2.10.RELEASE.jar!\org\springframework\web\servlet\DispatcherServlet.properties
                 在DispatcherServlet类均有对应的List存储，如handlerMappings。注意这些策略具体实现类实例及其List并未放入springIOC中。
                 但是springmvc加载时会先去springIOC里找有对应的策略实现类bean（自定义的策略实现，如视图解析器），有则不加载DispatcherServlet.properties的默认实现。
                 前端json到达Controller通过HandlerAdapter去将json转化为对象（如User），所以我们可以在springIOC里添加对应的HandlerAdapter（实际是具体的实现类bean）
       组件流程：详见bili黑马spring课程4分40秒组件流程图
       请求处理：
                 请求映射路径的配置
                 请求数据的接收：
                     注意：http://www.test.com/getTest?p=1&p=2&p=3 要封装到Controller方法入参List<Interger> pList  要加@RequestParam 
                           Controller的入参最好是包装类型（而不用基本类型），如int类型参数没有值会报错  
                           get方式下/getTest?name=jack&age=18&address.num=123&address.city=xiamen 可以映射为user对象并且能映射user.address对象
                           Restfull风格：参数接收使用@PathVariable
                           接收上传文件要求：配置名称固定的springMvc文件上传解析器springBean并导入相关包（默认未开启）；前端是表单method=post、enctype=multipart/form-data、name属性非空；后端用@RequestBody MultipartFile myFileName
                           接收请求头信息：用@RequestHeader("Accept-Encoding") String acceptEncoding、@RequestHeader Map<String,String> map
                           接收Cookie：用@CookieValue(value="JSESSIONID",defaultValue="") String jsessionid
			   接收Request域属性：用@RequestAttribute("username") String username
                           接收Session域属性：用@SessionAttribute("username") String username
                 javaweb常用对象获取
                           接收HttpServletRequest、HttpServletResponse 都是直接在Controller方法入参加入相应参数即可
                 请求静态资源
                           原本Servlet开发如果url路径匹配不到动态资源，则会有个defaultServlet进行匹配，静态资源就是这样被匹配到的
                           springMvc使用后DispatcherServlet替代了defaultServlet，它只匹配动态资源。
                                   解决方式：1、可以配置一个路径映射到defaultServlet即可再次激活defaultServlet
                                             2、使用springMvc提供的静态资源映射配置（如<mvc:resource mapping="/image/*" location="/img/">）
                                             3、直接配置<mvc:default-servlet-hanlder/>
                 注解驱动<mvc:annotation-driven>标签
       
* spring有一个大的设计思想特点，它把很多的功能实现都集中在一些具体的实现类，如ClassPathXMLApplication，然后通过
 许多不同的多层次的接口来划分这些功能，并通过一些多层次的抽象类来规定不同的流程模板。所以在spring中一个实现类有
 可能扮演着多种“角色”

*spring IOC总结：（具体过程可以看spring5源码注释版，在gupao2020年课程有，本地也有下载）
 *springIOC先经过了初始化过程，一系列额外事件、监听、注册初始化和执行过程，实例化并依赖注入过程。这一些列过程可从FileSystemXmlApplicationContext构造开始看进入refresh()
  【初始化过程】发生在FileSystemXmlApplicationContext构造函数执行到"prepareBeanFactory(beanFactory);"之前
  【一系列额外事件、监听、注册初始化和执行过程】发生在"prepareBeanFactory(beanFactory);"到finishBeanFactoryInitialization(beanFactory);之前
  【实例化并依赖注入过程】发生在finishBeanFactoryInitialization(beanFactory);里面
 
 * spring IOC容器初始化大概的过程：定位->加载->注册  
  大致流程可以看自己的demo代码
  具体过程详见博客园收藏 https://www.cnblogs.com/ITtangtang/p/3978349.html#a1

 * spring应用中常用的接口(详见blogs，第一篇很重要 《Spring8：一些常用的Spring Bean扩展接口》《Spring8：一些常用的Spring Bean扩展接口》) 
   ApplicationContextAware 在spring容器的bean有实现该接口，则spring会将ApplicationContext对象注入
   详见gupaovipdemo
 *ConfigurableApplicationContext这个接口是在spring IOC中经常作为最终接收的接口

* spring IOC容器相关的一些类
 带resource的是关于资源的描述类，用于定位
 带BeanDefinition是bean加载后的描述类
 带Reader的是加载相关的类
 带Factory、Context是注册bean信息的相关类

* beanFactory和factoryBean的关系
 factoryBean是一个接口，自定义一个实现它的类，然后将类配置到spring xml里就可以得到一个代理目标对象的bean并放入ioc容器。 （其实如果spring依赖注入的属性bean构造过程较为复杂，则调用一个实现了FactoryBean接口的工厂实现类的getObject方法，即可的到这个属性bean的值并注入）
            例如在spring mabatis整合过程中SqlSessionFactoryBean就是对原生的mybati的ssqlsession的代理
 beanFactory是ioc容器的顶层接口，是生成bean的，包括有些beanFactory也是由其它beanFactory生产出来的bean（它会带有&符号），即factoryBean

 beanFactory这是最原始的ioc容器的抽象接口，它包含了#getBean等原始容器应该有的功能方法。其中getBean方法在当前容器获取不到会到父容器中去获取

*BeanFactory 和 ApplicationContext 区别与联系。详见blogs《BeanFactory 和 ApplicationContext 区别》
 BeanFactory是ApplicationContext的父接口，它提供了最基础了ioc容器的功能方法规约。
 ApplicationContext扩展了BeanFactory接口，额外提供了【 MessageSource, 提供国际化的消息访问】、【资源访问，如URL和文件  】、【事件传播】、【 载入多个（有继承关系）上下文】功能规约
 
**BeanFactory有三个直接子接口：ListableBeanFactory、HierarchicalBeanFactory 和AutowireCapableBeanFactory。最终默认实现类是DefaultListableBeanFactory
  特别注意的是ApplicationContext并未继承AutowireCapableBeanFactory接口，只继承了ListableBeanFactory、HierarchicalBeanFactory 
  DefaultListableBeanFactory实例里有两个map需要关注：
                1、singleObjects用于存储bean实例的map
                2、beanDefinitionMap用于存储beanDefinition实例的map
*在spring生产原生bean时，要用beanDefinition和beanWrapper对原生的bean对象进行对象创建和属性赋值，beanWrapper是一个接口，
 她规定了原生bean的属性访问器和编辑器等操作（BeanWrapperImpl是其实现类），有了它就可以对原生bean进行属性进行填充。
 注意beanWrapper也只是在spring内部使用，开发者并不会使用它进行业务开发。


* spring中lazy-init默认是false，在源码中，它有一个finish...方法进行自调用，其实就是调用getBean方法。

* springmvc中的DispatcherServlet.onRefresh()调用了initStrategies(),这里初始化了springmvc的“9大组件”，这些组件所用的策略
 其实是在spring的xml配置的，如视图解析器组件一般都是配置org.springframework.web.servlet.view.InternalResourceViewResolver
 9大组件的具体实现在DispatcherServlet.properties里有配置（org\springframework\spring-webmvc\5.2.10.RELEASE\spring-webmvc-5.2.10.RELEASE.jar!\org\springframework\web\servlet\DispatcherServlet.properties）

* springmvc的DispatcherServlet.init()经过层层调用初始化了9大组件后（放在成员变量），
 然后在用户请求调用DispatcherServlet.doGet() 时依次调9大组件，最后返回结果给用户

* spring事务中，Datasource是对Connection的包装，Connection的实现其实是通过Socket进行数据库连接
 DataSource中其实是对事务的开启，隔离级别，回滚，提交等操作做了封装和规整。

* * spring可以配置事务在一些异常出现的情况下进行回滚（rollback-for属性），但要求在业务service里不能把可能异常的代码try-catch掉。

* * spring的service层的方法如果有相互的调用要特别注意会有事务传播问题，这个需要开发者注意。

* 实际上数据库的事务的底层原理也是通过操作日志来做数据回滚，如mysql的里有一个binlog就是干这个事情的。

* spring的aop切面配置时，使用xml和annotation方式的区别：annotation可以额外配置匹配目标方法是否包含某个参数名的参数

* ？在spring环境中通常一个Service里包括多个Dao处理，他们公用一个Connection，在一个事务中，此时Connection底层应该有多个socket对应
  不同的Dao操作，而每个socket可理解为一个Sql语句。这些语句在操作是在数据库内存中有个临时区域，等事务提交后才能更新到原始表。
  此时如果有其它事务访问原始表，则可能出现所谓的脏读，不可重复读，幻读的情况。而隔离级别就是规定了在这个事务期间原始表可访问情况。
  

*spring常用的接口或方法：
 ApplicationContextAware：实现该接口的bean在spring容器初始化后会将ApplicationContext对象注入到bean的接口方法中。
                          注意spring的XxxAware类型接口都是资源发现接口，用于发现注入某资源，如：
                          BeanClassLoaderAware:
                          ResourceLoaderAware:
                          BeanFactoryAware:
                          EnvironmentAware:
 InitializingBean：实现该接口的bean，并且配置init-method，系统则是先调用InitializingBean的afterPropertiesSet方法，然后在调用init-method中指定的方法
 bean配置文件属性init-method：用于在bean初始化时指定执行方法，用来替代继承 InitializingBean接口
 BeanPostProcessor：Bean后处理器，一般在bean实例化后，填充到singletonObjects之前执行。每个bean实例化都会执行。 准确的说BeanPostProcessor是拦截了bean的init-method指定的方法前后
        整体执行过程：bean实例化，beanPostProcessor前置方法->InitializingBean接口方法->init-method指定方法->beanPostProcessor后置方法->将bean填充到singletonObjects
        应用场景：在beanPostProcessor前置处理中对bean实例进行包装增强
 ApplicationListener：实现该接口的bean，将接收到spring触发的事件，比如容器关闭事件。   开发者可以通过applicationContext.publishEvent()来发布事件
 LifecycleBeanPostProcessor？再做研究
 BeanFactoryPostProcessor在spring的definitionMap填充完，bean实例化之前执行（当然也是在singletonObjects填充之前）。随着容器初始化只执行一次。该接口可以拿到IOC容器实例进行相关操作。
        注意：BeanDefinitionRegistryPostProcessor是BeanFactoryPostProcessor的子接口用于专门注册BeanDefinition的操作。虽然BeanFatoryPostProcessor也可以，但是入参IOC容器实例要强转类型。
        应用场景：动态注册自己的beanDefinition,比如可以根据自定义注解扫描到特定的类然后注册到beanDefinitionMap里去

？Tom的泛型操作类要研究学习下 javax.core.common.utils.GenericsUtils

？练习：Junit4和spring的集成、并复习Junit的使用

？元旦节后将spring最后这几节课的笔记再复习一遍
  元旦节后找spring相关的面试题做做，到咕泡论坛上找找 https://gper.gupaoedu.com/articles/766
-------------------------------------------------------------
？下午复习下Spring事务的相关配置及事务传播和隔离级别

？<tx:annotation-driven>、<mvc:annotation-driven>和<context:component-scan>功能上的关系

* 学完源码后要找相关的面试题做一做

？在描述DefaultListableBeanFactory到BeanFactory的关系时，他们是继承关系，tom说这是委派模式，但个人感觉不是。 
  委派不应该是调用的关系，而不是继承或实现的关系。 

？spring的aop在实际中有什么应用
？原生bean经过beanWrapper包装有什么用处，是为了aop吗

？RandomAccessFile类的使用学习，网上找了都比较简单

？spring在getBean()得到的是包装后的代理对象，没有原始对象的注解信息，如果开发者要用到原始对象的注解信息怎么办

？多数据源共存的情况下，如何去处理多个数据库的事务，应该属于分布式事务。

## --------------------Spring end------------------------------

## --------------------分布式20190110 begin------------------------------

* 咕泡分布式项目实例 http://git.gupaoedu.com/java-vip/vip-project-space

* * dubbo的官方文档多研究多看，可以窥探到分布式环境下的许多知识点以及编码风格和习惯。

* 领域驱动，个人理解：即按照不同行业业务，将业务里的功能拆分细化，即拆分为不同的领域。如dubbo源码里就分了不同的模块，有admin有rpc等，这应该是就是不同的领域。
 应该说是按照行业领域去建立模型，比如将烟草采购这样一个业务抽象成模型或者说是类，在这个类模拟了这个业务，具体的一些过程操作等都做这样的模拟，做面向对象。
 mic在课程中提到领域案例代码是在service层和dao层添加领域层，这个领域层个人理解就是按照业务划分了细颗粒度的模块并在一些聚合模块进行组装，从而供service层用。

* 分布式环境下，数据的一致性怎么保证。 其实一般会用一种中间状态做处理。 比如下订单业务，一般是要支付完后才算下订单完成。但是由于支付是一个相对耗时的操作，这
 时就会先返回给用户“下订单成功”，然后在订单中的支付状态是支付中，而不是支付完成。这种中间状态是一种软状态。 等到支付完成后会通知更新订单去更新支付状态。

* A/B测试（灰度测试），大概就是内部的测试，软件公司会征集一定范围的用户去试用新的产品功能，以达到测试新功能的目的。

* socket时讲到NIO和BIO时，其实同步和异步一般是对于客户端来说，而阻塞和非阻塞一般是对于服务端来说。
 * 对于BIO进行通信时
    1.客户端和服务端分别需要有发送缓冲区和接收缓冲区，服务端不将接收缓冲区内容读取到内存，接收和发送缓冲区都不会清空，客户端就不能继续发送剩余字节。
    2.在此时如果别的客户端要连接服务端也进行通信就不行，因为已经被上述客户端占用，直到这个客户端处理完，对于所有客户端来说就是阻塞的
 * 对于NIO进行通信时（应该和NodeJs的事件轮询机制是一样的）
    1.客户端和服务端在通信前，会建立一个个通道，每个通道对应了一个客户端和一个服务端。通道里保存了客户端和服务端的一些操作。
    2.在通信时会有一个线程去轮询这些通道，发现那个客户端的发送缓冲区清空了，就去执行对应通道里的动作，网发送缓冲区去写。
    3.由于轮询线程的速度是非常快的，看起来就像是所有客户端都能同时和服务端进行通信，达到异步的效果。 
  形象化BIO、NIO、AIO：客户到银行办理业务。客户相当于一个请求，业务员相当于线程。
    BIO：一客户对应一个业务员，在这个客户请求未办理完之前，业务员是被占用的，所以其他客户不能办理。 也就是同步阻塞
    NIO：银行开了10个通道窗台，客户先填写资料，业务员轮流查看10个通道的客户填写好资料，好了就办理。这时就是同步非阻塞
    AIO：银行还是做了个智能通知APP，客户填写完资料，就会触发事件将信息发送到业务员手上，这时候业务员等着事件就行了，这就是异步非阻塞
    综上所述：BIO是原始的一种处理方式最为低效，NIO其实是一种轮询通道机制，而AIO是基于底层的事件机制

* 常见的序列化工具 Jackson、FastJson、GSon、Hesian（dubbo用的是它的扩展Hesian2）、
 dubbo除了Hesian2以外还提供了很多序列化的实现方案（实现类）
 Protobuf是mic推荐，独立语言、可跨平台交互等诸多优势，但它要实现比较麻烦，需要学习成本。
 序列化方案的选型考虑的点：1.开销，大小和性能 2.计算耗时  3.是否跨平台 4.学习成本

* Protobuf 官方支持C++、JAVA、Python等三种编程语言，但可以找到大量的几乎涵盖所有语言的第三方拓展包。
 javascript前端可以使用protobuf 详见https://blog.csdn.net/arvin_kai/article/details/77532595
 行业已有的实践：Protobuf+Websocket做一些行业应用、Protobuf+Redis做缓存

？测试Controller调用分布式的service实例时想service传递对象参数是通过序列化和反序列化传递的
 ！通过debug 在Controller的service方法调用之前 和之时查看参数对象的内存地址

* ？通过课程了解RPC框架RMI的原理
   个人初步理解RPC远程通信实现Controller里获取Service实例并调用的过程（以HiController、HiServiceImpl、HiService为例）：
   HiServiceImpl实例通过固定的RPC框架的规范进行注册，RPC框架会生成HiServiceImpl的代理（HiServiceImpl_stub），并在宿主进程里保留HiServiceImpl实例
   通过序列化和反序列化途径，HiController可以反序列化得到这个HiServiceImpl代理并用HiService接收。
   在调用HiServiceImpl代理对应的HiService方法时都会通过RPC规范去掉用远程RPC框架的东西，再invoke远程HiServiceImpl里的方法
   以上纯属个人理解，未看过源码，纯属猜测。

* RPC不一定是用tcp协议也有用http协议的，但大多数会用tcp协议用socket，性能会比较好。

？在一般RPC框架中，每一个服务（service）实例都用一个线程池线程去处理，如果这样服务多的话不是非常占用资源？ 
 Socket socket=serverSocket.accept(); //监听服务
 executorService.execute(new ProcessorHandler(socket,service));//通过线程池去处理请求


* zookeeper
 分布式过程中出现的问题：
  * 协议地址维护：一个服务的集群或多个服务都需要有地址，这些地址多了就难以维护，就需要一个服务器
  * 负载均衡，请求一个服务，而这个服务是集群，则需要进行负载均衡，进行合理的转发请求
  * 服务动态上下线感知，一个服务的集群或多个服务，他们上线或宕机都需要被客户端所感知，需要通知到位。
  * 分布式时共享资源调用问题：多线程是线程间共享资源安全问题，而分布式则是进程间的共享资源安全问题。
  * 三态问题：除了事务中的成功与失败状态外的未知状态，可能由于网络通信、延迟等原因造成的。
  * 数据一致性，应用集群中各个节点数据保持一致，保持同步
  * 保证一些一次性远程调用只在一个应用集群节点执行。
  * 应用集群中一个节点挂了，其它节点如何接替它的任务。 
 解决方案：
  * 利用zookeeper的数据存储方式以及特性解决分布式过程中出现的问题（分布式协调服务）
  * 由于作为分布式环境下的协调者，所以要用集群和一些特性来保障zookeeper的高并发高可用。
  * 分布式服务在zookeeper集群上注册，则这些注册数据在这些集群节点间的同步是个问题（增强版2pc来解决）。
 zookeeper特点
  * 树形结构存储，例如一个orderservice存储在一个节点上，而其集群中每个服务器的地址存储在这个节点的子节点
   底层是基于ConcurrentHashMap的一个数据存储，包括以下类型：
    * 事务日志，每个事务请求都会记录日志，一般这些日志会单独挂载在磁盘上而不放在临时目录里
    * 快照日志，其实相当于对数据的一种备份，可以通过它恢复数据。
    * 运行时日志，在运行时产生的一些日志
  * zookeeper中心化， 就是leader-follower模式集群，这时候就出现了读写分离，leader选举等一些问题。
  * zookeeper树形节点特性（每个节点都叫znode）：
   * 同级节点唯一性，和windows的文件夹文件的结构特性一样，同一层目录下的文件夹或文件名不能重复
   * 临时节点特性,一个客户端连接zookeeper服务后创建了一个临时节点（临时节点不能有子节点），在会话结束后，该节点会自动删除
   * 有序节点特性，通过命令可以创建一个节点下的有序子节点，这些子节点会有一些特性，如有序....？后续补充下。
   * 节点要逐层删除，不能删除一个目录，只能逐层删除
   * 持久化节点，和临时节点相对
   * 节点监听，客户端可以订阅节点的相关事件watcher，当节点产生相应的变更时会触发客户端相应的操作。
  * watcher特性
   特点：当数据变化时会产生一个watcher事件，发送至客户端。但客户端只会收到一次通知，如果数据再变化，则客户端不会再
         接受到消息。相当于是JQquery的一次性事件。如要永久事件，则需要循环去注册事件。 
   绑定事件的3个操作：getData、Exists、getChidren
   如何触发事件：凡是事务操作都会触发事件
   事件类型：None(-1)、NodeCreated(1)、NodeDeleted(2)、NodeDataChanged(3)、NodeChildrenChanged(4),注意各个事件触发的时机    
  * zookeeper集群角色
   * 除了一般中心化集群的leader、follower以外还有一个observer
   * leader负责事务请求（zookeeper节点增删改查），投票选leader
   * follower负责非事务请求（查），事务请求会转发到leader去处理，投票选leader
   * observer增强集群性能，增强查，功能基本和follower一样，但不进行事务投票和leader选举投票。
  * 客户端与zookeeper建立连接过程中的几个状态：
    NOT_CONNECTED,CONNECTING,CONNECTED,CLOSE
    当连接成功后为CONNECTED时，如果断开了连接，会变成CONNECTING状态，此时在尝试n次重连后连上就是CONNECTED，否则是CLOSE
 zookeeper节点事务提交过程（增强版2pc协议，二阶提交，即分两次处理）：
    当leader节点收到客户端事务请求（增删改）生成zxid，它会给所有follower发一个要提交事务的携带zxid的消息（proposal），
    follower接受到消息会将这个事务写到本地磁盘并返回一个同意的ack给leader。当超1/2的节点同意时，leader通知
    包括自己在内的所有节点提交事务（即发起commit请求）以及将事务提交成功结果返回给客户端。还有同步给其它节点。 
 zookeeper奔溃恢复（当leader挂了或leader失去过半follower联系即崩溃）（用zab协议解决）
    在上述事务提交过程中，如果有的follower已经收到commit请求而有的没有，此时如果leader挂机，则此时这个事务已经有被某一个
    follower提交了，所以是不能丢失的。 如果在leader还没发起commit请求前就挂了，则这个事务消息要被丢弃。
    zab的设计思想：1.当有的follower接收了commit请求并提交事务而有的没有，此时有提交事务的follower的zxid会最大。
                   2.zxid是在新产生leader后生成的64位数，高32位代表epoch（年号，即新的统治时期），低32位表示消息计数器。
                   3.zxid最大会被选为leader，因为它代表了当前节点的事务是最新的，数据是最新的。
 zookeeper的leader选举：
    影响因素：
     zxid最大会被设置为leader，zxid包含epoch和计数号两部分。这个事务id越大表示数据越新。
     myid越大权重越大
     epoch越大权重越大，每一轮选举epoch都会递增。
    选举过程：
     选举开始时每个zookeeper都会将自己的zxid、myid、epoch三项数据广播给其它zookeeper。
     每个节点收


到其它节点的三项数据，依次检查zxid，myid并进行投票
     统计投票
 zookeeper实际应用场景：
  * 当一个服务集群，如orderservice，会有一个orderservice节点和多个集群点地址子节点（临时节点），当orderservice中一台挂掉，
   其对应的zookeeper临时子节点也会删除，此时会有通知到对应有订阅通知的客户端（orderservice的消费者）。
  * 配置中心，如应用有很多properties文件就可以通过zookeeper管理，当znode产生变更会通知到客户端（properties使用者）
  * 负载均衡，kafka集群可以在zookeeper上注册有序节点，此时节点序号小的为leader，当leader挂了又通过zookeeper又重新选举leader
  * 注册中心，如rpc的注册中心过程：
   * 服务端在zookeeper为serviceX服务创建一个节点，底下临时子节点对应一个服务主机地址，如addrA、addrB...
   * 客户端通过zookeeper获取所有serviceX服务的子节点，并通过zookeeper提供的负载均衡策略选出一个来使用，如选到addrB
   * 服务端和客户端通过zookeeper进行注册、获取、负载均衡，再加上动态代理等技术就可以实现高效的RPC调用
   * 客户端还可以监听serviceX服务的子节点增删，以此来更新本地内存对应serviceX的地址列表addrA、addrB、addrC....
  * 分布式锁，利用事件watcher等特性进行实现。有2种方式(主要看有多少线程来抢锁)：
   羊群效应方式：在zookeeper创建一个锁节点，所有客户端通过zookeeperApi去监听锁节点增删，一旦锁节点删除，所有客户端会再去抢锁（即抢注），抢到者即拿到锁。
   依次监听方式：每个客户端再尝试拿锁时都去抢注创建一个临时有序子节点，所有子节点只监听它前面节点的增删，最小节点则认为是拿到锁，当最小节点释放锁，
                 则第二小节点会监听到并去拿锁，以此类推。即再抢注环节，所有客户端的先后顺序已经排好，这应该就叫做公平锁。而羊群效应则是非公平锁。
   分布式锁假想应用：在销售抢单过程中，通过请求创建zookeeper的临时有序子节点，如果抢到第一子节点的人进行业务处理，即抢到单，将单保存再该人名下。
                     此方案还可将zookeeper请求改为单独的API，前端每次抢单前都去请求API，拿到权限再去请求真正的业务。不安全，但对于内部后台系统问题不大。
 zookeeper实操点：
 集群安装、客户端zkClient.sh常规命令操作、集群下个点的数据一致性（数据同步）、更新数据时的版本号
 watcher测试（用一个客户端连接并用get 节点名 true，这个命令就是开启watcher，然后再开一个客户端进行数据修改）、
 sh zkServer.sh status查看zookeeper状态、查看zookeeper的epoch用命令vim zookeeper/version-2/currentEpoch
 利用javaAPI调用zookeeper增删改查，事件。 
 注意：
  * 当使用get命令去查看zookeeper的节点值时，会有一些当前节点的信息，如cZxid、mZxid等
   cZxid是节点创建时产生的id，mZxid是节点修改时产生的id，pZxid是子节点变更产生的id
   cversion是子节点的版本，dataVersion是节点值发生变更的版本，aclVersion是节点权限变更的版本，这些版本都属乐观锁
   ephemeralOwner当前会话的信息 
   dataLength节点值数据的长度
   numChildren当前节点下子节点的数量 
  * zookeeper每个节点建议只保存少量的数据
  * zookeeper事务请求（增删改）都会转发给leader，而读请求可以放在任意节点
  * 磁盘的读写速度决定了zookeeper的性能。
  * Mic在讲zookeeper的2pc处理事务的过程时，这个事务是指zookeeper数据的增删改事务
  * 看zookeeper的事务日志要用mic课程上讲的一个命令
   03.分布式专题\04.分布式协调服务\录播视频\第二次课\20180606_了解zookeeper的核心原理（下）.vep  在11:12处
  * 特别注意javaAPI调用zookeeper时，sessionTimeout不能过小，否则在操作会出错，可能是中间有断开重连发生
  * zookeeper在扩容时比较麻烦，需要将所有机器停机，做扩展配置再启动。或逐台机器配置重启。
  *ZooKeeper并没有内置负载均衡策略，需要调用者自己实现
  ？zookeeper方面面试题在哪里

*容灾能力：zookeeper集群最多能挂掉几台仍然保持正常工作状态。
 为了可以有超过1/2的节点投票选leader，zookeeper集群一般是2n+1个节点，此时容灾能力就是n
 注意：zookeeper集群，5个节点和6个节点容灾能力是一样的 ，所以多一个节点反而增加网络开销，性能也会下降。

?zookeeper实现分布式锁时如何解决死锁，怎么解决。 
 设置锁节点的过期时间，使得死锁在一定时间能自动“释放”
  
*zookeeper集群的脑裂问题：详见《Zookeeper集群的“脑裂”到底是个什么玩意？》
 描述：集群中的Master或Leader节点往往是通过选举产生的。在网络正常的情况下，可以顺利的选举出Leader（后续以Zookeeper命名为例）。但当两个机房之间的网络通信出现故障时，选举机制就有可能在不同的网络分区中选出两个Leader。当网络恢复时，这两个Leader该如何处理数据同步？又该听谁的？这也就出现了“脑裂”现象。
 解决：采用投票过半的方式避免，并且是部署集群时采用2n+1的方式，减小脑裂的概率
*新旧Leader争夺问题：
 描述：假设某个Leader假死，其余的followers选举出了一个新的Leader。这时，旧的Leader复活并且仍然认为自己是Leader，向其他followers发出写请求也是会被拒绝的。
 解决：因为ZooKeeper维护了一个叫epoch的变量，每当新Leader产生时，会生成一个epoch标号（标识当前属于那个Leader的统治时期），epoch是递增的，followers如果确认了新的Leader存在，知道其epoch，就会拒绝epoch小于现任leader epoch的所有请求。
 
*几种注册中心的对比《全方位对比Zookeeper、Eureka、Nacos、Consul和Etcd》
 *zookeeper为何不适合做注册中心？ 在leader挂了，选举leader 的时间太长，30 ~ 120s, 且选举期间整个 zk 集群都是不可用的。所以说，作为注册中心，可用性的要求要高于一致性！



* dubbo （具体看学习笔记、官网、博客园收藏《dubbo用户指南-总结》）
 * 分布式中遇到的问题（其实就是服务治理问题，而dubbo就是一个服务治理工具）：
  * 服务地址维护
  * 服务被请求时负载均衡
  * 服务请求限流/容错/降级
  * 监控
 * 常用配置（只列出其中几个）：
  * 注册中心配置,dubbo支持的注册中心zookeeper、redis、multicast、simple。支持多种类型注册中心同时使用，这里说的不是集群。
           * dubbo在zookeeper上注册的节点结构大致如下
               -dubbo
              -com.gupao.userService
                -consumers
                  -...
                -configurators
                  -...
                -routers
                  -...
                -providers
                  -...
  * 缓存配置，dubbo的消费端可以配置服务列表的缓存，避免每次都去请求。？这个缓存的调用和维护时机后面讲
  * 协议配置，dubbo支持的多协议：rmi、hessian、webservice、http、thirft、dubbo
    ？hessian是http协议是否说明app等其它客户端也可以直接调用
    网上资料回答是肯定的（Hessian：使用HTTP协议，允许穿透防火墙，使用自己的系列化方式，支持JAVA、C++、.Net等跨语言使用。）
    《dubbo组成原理-http服务消费端如何调用》、《Dubbox的介绍和简单示例》 https://wosyingjun.iteye.com/blog/2320127
    实际上dubbo服务的调用是远程过程调用，就必须有一个代理做发送请求及序列化等工作。而所谓的http协议只是在通信时的协议。
    而并非真正能直接用浏览器进行调用。 如果非要实现这样的功能，可以用dubbo的泛化调用来做一个统一网关，或用当当网的dubbox
    注：如果说dubbo支持浏览器直接http调用的话，就会出现一个问题，在服务集群的情况下，浏览器这边自己做订阅、负载均衡、容错等动作
  * 启动检查配置，dubbo服务的循环引用时启动时会报错，此时可以设置check="false"，启动不检查依赖服务是否启动
      ？dubbo怎么通过zookeeper配置负载均衡的策略的。默认是随机负载策略
  * 服务集群容错配置（cluster这是分布式面试常有）
   * 由来：在分布式环境下serviceA调用serviceB调用serviceC，如果serviceC出错或不可用，则会导致serviceA、serviceB阻塞住。此时就需要一种容错机制
   * 容错机制：failsafe等6种，通过cluster属性配置  ??这里需要补充学习下http://dubbo.apache.org/zh-cn/docs/user/demos/fault-tolerent-strategy.html
      * 详见CSDN收藏《Dubbo 的集群容错模式：Failback Cluster》 https://blog.csdn.net/u011642663/article/details/81949941
      * 这部分内容主要要去看各个容错处理Invoker的doInvoke实现，如FailsafeClusterInvoker#doInvoke
      * 在客户单调用服务端时，（如超时），则客户端报错，但服务端的代码有无执行并不知道或者说是否执行成功并不知道，
       此时就需要服务端按照业务进行相关处理。如addUser()则需要先查询在执行insert。 而客户端对于报错也要进行相应的处理。
       可参考 https://blog.csdn.net/shenhaiwen/article/details/73331193 
      * 客户端调用服务端时，如果服务抛出普通异常（非RpcException），则dubbo会把异常捕捉转移给客户端去抛出，所以服务端就不会报异常。而这种情况
       也算是客户端调用成功了，相当于成功返回了异常。 所以如果cluster="failover" 则不会再重试。 
      * failsafe情况下会把错误吞掉，然后返回给客户端一个null结果（源码里其实是返回一个没有初始化的new RpcResult()）。	
      * 需要注意所有服务端的Throwable或RpcException异常都会在Cluster层转为RpcException并向上抛出，所以Mock这层也是接收到RpcException并处理
   * 配置的优先级别：消费端和服务端都有相同配置的情况下，消费端较高。如都配置timeout，则以消费端为准。详见blogs《dubbo 配置 优先级》
     1.消费端方法配置>服务端方法配置>消费端接口配置>服务端接口配置>消费端全局配置>服务端全局配置
     2.jvm-D参数配置>xml配置>properties配置
   另外一个服务的配置可以具体到这个服务的具体方法中，即可通过<dubbo:method>进行配置
  * 服务集群的降级配置（mock）
   * MockClusterWrapper通过这个包装类去实现降级的拦截
   * 场景：比如一页面有算法推荐职位，当推荐服务出错，则web层就直接返回给页面一些默认的数据或静态的数据。 此时用户看到的并非真实算出来的推荐。
         再如在大促销活动前，将一些非核心功能关闭（并且给用户一些友好提示），以保证核心功能在当前硬件环境下高可用高性能。
         加验证码、12306在不同地区分时段分车次开放购票
   * 目的:为了保证核心服务可用。当在经过容错机制处理错误后可能自己吞掉错误，也可能交给服务降级mock去处理。
   * 类型：自动降级、人工降级。
   * dubbo的mock：降级方案的配置。如服务端Service1实现IService1，然后消费端配置一个mock="ServiceMock"实现了IService1的本地类，当消费端调用
                Service1服务时如果出错，则转而调用ServiceMock的实现，这就达到了所谓的服务降级。
		注意，如果某个服务访问流量超限制，这种情况是无法通过dubbo服务降级处理的
                ？？但是服务多的话不是要一个个配置降级方案，那不很多。一般是一个个配置，但若是一些公共降级其实就相当于统一拦截，可在nginx层面去拦截。

 * SPI机制：插件的一种规范，是dubbo框架的一个重要机制。
     * java SPI机制
	1.配置META-INF/services/接口全路径文件
     	2.按照全路径对应的接口写对应实现类
	3.使用ServiceLoader.load(Person.class);加载实例
     * dubbo SPI机制，是自己的插件规范，每个可扩展的地方都称为"扩展点"（Extension），和spring的ioc容器，依赖注入di异曲同工。 
        * 起步：引入dubbo，然后通过按照dubbo规范通过ExtensionLoader.getExtensionLoader(Serialization.class).getAdaptiveExtension()调用做入口
        * 几个重要的类概念（假设扩展点接口IA，对应实现类有A1、A2）：
	  ExtensionLoader<T>：是一个泛型的类，主要用于加载和实例化A1、A2，如果A1的属性也是扩展点则会用injectExtension()方法做依赖注入
			      其中用到ExtensionFactory的适配器实现类AdaptiveExtensionFactory，它的getExtension(Class<T> type, String name)
			      就是通过名称name获取指定的扩展点实现类，而AdaptiveExtensionFactory内部维护了一个factories集合用于存储扩展点的
			      所有实现类实例。总而言之，扩展点接口有多个实现类，而扩展点的适配器是用于从多个实现类中进行适配或选择其中一个
			      具体实现类的角色，而Wrapper包装类在适配器之前对实现类进行的一层包装。
			      总的过程：对应扩展点的ExtensionLoader加载器初始化时就会去加载对应的Class供以下步骤使用。
					每个要加载的扩展点接口类型都会去实例化一个ExtensionLoader<IA>对象并存储在ExtensionLoader静态字段中，
                                        而IA的实现类如A1、A2都会存储在ExtensionLoader<IA>实例中。 在依赖注入过程中，会通过ExtensionFactory
                                        的实现类去创建所需要的依赖实例，其实还是调用ExtensionLoader中相关的具体扩展点加载器如ExtensionLoader<IB>
                                        所以只有调用getAdaptiveExtension()或getExtension()才会真正去创建所需要的扩展点实例，并执行Aop和DI逻辑。
					以上一系列加载逻辑其实就是用扩展点时再加载Class并生产对象并缓存，而且是单例。因为很多地方都会用到扩展点
                                        所以代码中都是用double check来保证所有生产东西的单例，这点值得学习。
          IA对应一个ExtensionLoader实例,在这个实例会去缓存IA的实现类A1、A2的class
          IA$Adaptive：IA实现类的适配器，用于适配具体的实现类以供开发者调用，比如适配是根据程序运行时的url参数对A1、A2的判断选择其一的过程。
		     在ExtensionLoader实例中可以对AdaptiveExtension的类代码动态生成和编译（类型形如：IA$Adaptive），创建单例并缓存。
		     也可在spi资源文件自定义适配器则用自定义的适配器。IA中如果@Adaptive放在类上则用自定义适配器，放方法则用动态生成编译。
                     在ExtensionLoader相关操作方法:createAdaptiveExtension()、getAdaptiveExtensionClass()、createAdaptiveExtensionClass()
          	     IA、ExtensionLoader、AdaptiveExtension是1:1:1关系。
		     目前理解的是凡是动态生成的适配器类它都是根据实际注册到注册中心的url里的对应参数进行扩展点实现类的选择和处理。		     
       	 	  Wrapper类：在定义IA的实现类中，若有一个带IA ia参数的构造函数的，则dubbo认为他是一个包装类，则所有的非包装类的IA的实现类都会被它包装	        
                     其实Wrapper类实现的就是Aop的功能  
	  Directory类：服务目录，其实就是从注册中心去获取对应的服务目录列表，即List<Invoker>,这里的Invoker应该是每个服务对应一个。会根据注册中心注册服务的变动而变动
	  ExtensionFactory类：用于依赖注入时获取扩展点实现类实例，因为ExtensionLoader<T>实例不过就是加载器，加载的对象自己有缓存同时也有可能放
                              在springIOC容器，但实际上加载器生产的对象也没有放到加载器以外的容器，所以这个功能有点鸡肋或者与设计初衷北里。
	  Invoker类，是消费端生成的一个服务端代理的执行体，屏蔽RPC调用的细节。
                                 消费者调用生产者过程：当消费端调用远程服务时，先在本地的directory列表经过loadblance等一系列筛选选到一个消费端invoker，
                                 消费端invoker去远程连接到生产端并经过层层调用到达生产端invoker，从而调用生产端具体服务实现。
          Invocation类
        * 规约：
             * URL贯穿所有扩展点，自动生成的扩展点适配器的接口IA的方法必有URL参数，以确定真正的底层实现类。
              @Activate也是通过URL参数确定扩展点是否激活（实例化并使用），如一些过滤器类，如果激活即在实现类基础上做过滤包装。
             * 凡是有一个带IA ia参数的构造函数的，则dubbo认为他是一个包装类并会进行相应包装
             * 凡是类中有成员变量也是扩展点并且有相应的set方法，则dubbo会进行对应的依赖注入                 	     
	* 几个注解：
          @SPI("defaultValue") 表示当前被注解的接口类是通过SPI获取实现，即是一个可扩展点。
          @Adaptive 加在接口类上表扩展点接口的实现类的适配器是在SPI的META-INF资源里自定义的适配器。用到扩展点时实际上是用这个适配器类。
		    因为ExtensionLoader代码里默认就是去取它 ，而加在方法是用动态字节码按一定规则生成的适配器（它通过URL参数决定真正的实现类）。
	  @Activate通过自身的注解参数和扩展点的URL参数做对比以确定扩展点是否激活，如一些过滤器类，如果激活即会在实现类基础上做过滤包装。
	* 服务发布过程：dubbo自定义了很多spring的xml标签，并通过ServiceBean(对应的标签为<dubbo:service/>)作为启动入口，进行一系列初始化过程。
		       详见CSDN收藏《Dubbo源码解析之服务发布与注册》 https://blog.csdn.net/laravelshao/article/details/83655652
		       注意：服务发布类调用时序图、Invoker是包含远程方法调用信息和动态代理类的信息类	
		       总之导出服务其实就是创建一个服务的过程，并且以Exporter实例作为载体，在这个载体可以获取方法的执行体Invoker等东西。
		       Invoker里的Invocation封装了执行体相关的一些参数信息。如方法名、参数类型、参数值等		    
        * 服务订阅过程：和发布过程类，<dubbo:reference/>是入口，详见CSDN收藏《Dubbo学习之路（五）：服务消费者发现和订阅服务源码解读》
        	 	 		https://blog.csdn.net/jadebai/article/details/80684870
        * Dubbo泛化引用：其实是在消费者消费服务时可以不需要接口实现，而是提供一个通用的实现调用。，详见《Dubbo泛化引用》
                        利用它可以实现一个通用的远程服务Mock框架。
			利用它还可以作为中转站，让app、浏览器等http间接访问dubbo服务，相当于网关服务。https://www.jianshu.com/p/ff0947529de4
	* 思想启蒙：适配器模式、双检查锁实现单例模式、SPI插件、动态字节码和编译、规范、泛型、Wrapper装饰器、缓存单例、
		   程序初始化流程的性能调优优先级应该放的比较低，但是安全的优先级应该放的比较高！
    *Dubbo线程模型：
       dubbo底层使用Netty进行数据传输，在内部netty的boss线程组和work线程组都是属于IO线程，而dubbo内部又有一个专门的业务线程组（线程池）	
       根据这个线程模型就有iothreads、threads两个配置。配置的ThreadPool=fixed|cached|limited|eager实际内部也是调用ThreadPoolExecutor。这个类懂原理
       对于请求的线程池调度策略通过Dispatcher配置，默认是All，但实际应用中我们的业务服务还是要调用数据库等操作，即会有新的IO操作。因此一般设置message模式
    *Dubbo的官方文档的【示例】、【性能测试报告】和【服务化最佳实践】可以窥探到真实项目中的实践场景。
    *Dubbo里的配置，方法配置会覆盖应用配置，客户端配置覆盖服务端配置。但有一些配置是两边叠加的，如provider 和 service 同时配置的 filter 时，累加所有 filter，而不是覆盖。
 * 实操点：
   dubbo发布服务的demo、dubbo服务用hessian和http协议发布的demo、负载均衡配置、粗略看源码（2.5.0-版本，之后）
   服务的Version、mock（设置timeout=1来构造超时执行降级方案）、负载均衡、SPI、
   通过ExtensionLoader.getExtensionLoader(Protocol.class).getAdaptiveExtension()源码来研究dubbo的SPI应用过程、
   async参数设置是异步调用可以做性能优化详见博客园收藏《Dubbox 基本特性之异步调用》，可以看官网，有CompletableFuture、RpcContext、Java8的default方法三种方式	
   客户端stub参数设置可以对服务进行再次包装过滤，可以做一些容错或过滤应用
   参数验证、
   Router路由规则可以在dubbo-admin平台上设置。
   课程都学习完后去看mytotal和爱定家dubbo代码
   dubbo服务容器启动方式测试
 * 注意：
   * 分布式服务一般会将服务接口类作为一个单独的jar发布以供消费端使用。
   
   * dubbo底层是用Netty进行通信
   
   * dubbo下的服务可以不用打war和依赖Tomcat等web容器，可直接打jar包然后通过dubbo特定代码启动
    注意dubbo支持了spring、jetty、log4j的container容器，用于启动服务的应用。默认spring容器
   
   * dubbo的RandomLoadBalance算法是权重+随机的算法
   
   * dubbo中Directory、Router、LoadBalace、Invoker、Cluster（以及Cluster Invoker）的关系其实是服务集群流程的各个节点。
    详见官网说明http://dubbo.apache.org/zh-cn/docs/source_code_guide/cluster.html
   
   * 简书收藏《dubbo一些你不一定知道但是很好用的功能》有RpcContext传递隐式参数等一些功能介绍
   
   * 注意<dubbo:service>的executes、actives、threads、connections设置，他们的区别和关系
   
   * dubbo使用com.alibaba.dubbo.container.Main.main启动时必须注意默认固定加载classpath/spring配置文件,如要更改位置则可加启动参数或加dubbo.properties（dubbo.spring.config=classpath*:*.xml）
      只要最后生成jar里配置文件在classpath/spring里（maven打包插件指定targetPath）或者运行时指定了配置文件的位置都可启动
   * dubbo默认的序列化方式是heasesion而不是dubbo序列化，主要是为了dubbo2.0兼容dubbo1.0的应用，实际上dubbo序列化会比heasion性能提高50%
   * dubbo的Exporter用于导出服务、Exchange用于将请求响应信息封装成request/response
   * dubbo如何实现灰度发布：比如在新旧版本接口实例配置时设置不同的version，在消费端配置version="*"，这样再利用轮询负载均衡就可以达到新旧接口均可以达到50%的流量。
 * 问题：
    ？？重新学习dubbo的使用再去看官网，有必要再做调试研究 
    ！已重新研究源码和官网
    ？容错和降级同时配置时是怎么样一种表现，还有在事务性服务链链是什么表现，这些应该是比较重要的内容
      mock实现只有在抛出RpcException才能被执行，所以当某个cluster服务集群的容错方式最后没有抛出RPCException就不会执行mock。 如failsafe就把错误吞掉。
    ！此问题在可看dubbo官网的源码说明可略知一二，在源码导读-集群/服务调用过程两部分可以知道它的表现形式。
      详见http://dubbo.apache.org/zh-cn/docs/source_code_guide/cluster.html和http://dubbo.apache.org/zh-cn/docs/source_code_guide/service-invoking-process.html
      dubbo官网说服务目录是 Dubbo 集群容错的一部分，也是比较基础的部分，所以大家应尽量搞懂。    
      只mock只有在容错机制抛出PPCException情况下才能接受处理，？这个要验证下
    ？如果有很多个服务消费，那岂不是要配置和编写很多个mock	是的
    ？双重检查锁定 if (instance == null) {synchronized(）{if (instance == null) {xxxx}}}  单例模式里有，不过似乎会有问题： https://www.jianshu.com/p/8b580d20dd58
    ？再去将dubbo学习的18点内容复习下，老师提的内容要点。
    ？淘淘项目服务端pom里排除了netty，那在默认protocol=dubbo协议情况下  duboo协议底层又是通过什么通信？ 
      因为zookeeper也有依赖netty所以，dubbo和zookeeper一起用的时候会有netty版本冲突，所以排除了dubbo中的netty
    ？dubbo课程像没有讲到线程模型，等多线程编程学完再重新回到dubbo学习下。
    ？<dubbo:service>的executes、actives、threads、connections、accepts设置，他们的区别和关系
    ？Router路由规则要学习下
 * 常见应用问题及解决方案：
  * 利用filter参数配置解决具体服务的拦截功能，比如调用次数或时间的统计。？？filter的使用和原理还要稍微看看。
  * mock做降级
  * async让客户端做异步调用，做性能优化。需要结合RpcContext.getContext().getFuture();
  * executes、actives、threads、iothreads、connections做线程和请求数性能优化
    actives是指单个消费端能对每个生产端服务每个方法的并发调用数。在消费端配置。
    executes是指服务端提供者每生产端服务每方法最大可并行执行请求数。在服务端配置。
    connections是指消费端和生产端建立的连接数，一般是长连接。在消费端配置。一个生产端服务端可能只能允许10个消费端去连接
    accepts是指服务提供者最大可接受连接数，一般是长连接。在服务端配置。它是指单个生产端的，而connections是指单个消费端对单个生产端的
    threads 生产端服务端业务线程池大小。处理业务代码的线程
    iothreads 生产端服务端io线程池大小。处理dubbo通信过程中需要的io读写，序列化反序列化等工作的线程。 当消费端异步调用时，如果用类似resultFuture.thenApply(()->{//消费端处理代码})，
	     则消费端处理代码用的是iothreads线程池里的线程。如果消费端处理代码包含耗时操作或阻塞，则会占用消费端的io线程池，影响性能。 所以可以用resultFuture.thenApplyAsync()或不要做耗时操作。
  * 多注册中心的意义，如果在国内外两个环境部署一套消费者和服务者，地理位置造成网络很远，此时就可以用两个注册中心将两个环境隔离开。 
      但是有一些公共的服务，又是需要国内外共同使用的，此时就可以将公共服务注册到两个注册中心上去。
      如果用group去区分国内外环境其实是有问题的，因为注册中心无论放在国内或国外对于另一个环境都是远距离传输，速度显然不行。
  *dubbo线程模型的Dispatcher配置策略默认是all，实际上比较好的处理方式是I/O线程和业务线程分离，所以采取message是比较好得配置。并且如果采用all如果使用的dubo版本比较低很有可能会触发dubbo的bug。


* MQ  
 **消息队列的对比：
  有broker的：即有中间存储服务器的，就是所谓的中间件
   RocketMQ是ActiveMQ的升级版。吞吐量大
   Kafka速度是最快的，但是可能丢包，可以用于传输相对不重要的数据。 传输速度快原理：创建一次连接，多个数据打成一个包进行传输。吞吐量大
   RibbitMQ轻量级MQ，上限取决于机器内存，可靠性比较强。
  没有broker的：无中间件存储服务器的，就是作为项目依赖被生产者消费者来引用和使用。
   ZoneMQ
 * 分布式队列消息的应用
  * 应用功能的解耦，如用户注册功能会附带发送邮件，新人礼包等操作
  * 流量消峰，如秒杀活动，会先把所有请求都写到MQ消息队列中，具体处理秒杀的业务服务再去订阅这个消息
  * 异步化，如有些耗时业务不直接处理，等资源空闲时在处理
  * 业务可扩展性，如增加一个用户注册相关的附带操作业务，可以直接订阅用户注册的消息即可实现。
  * 实现数据一致性，即尽最大努力去通知消息，保证事务一致性。

* MQ相关概念
 JMS java message service  是一套java消息队列的规范API
 AMQP
 MQTT
 MOM 面向消息的中间件

* 2种模型
 P2P模型 点对点。单个消费者接收到，消息只能被一个消费者消费。
 Pub/Sub模型 发布订阅。多个消费者可以接收到

* 注意：MessageConsumer.receive()是阻塞的，即只有接收到消息后才会往下执行
       也就是说消费者可以使用阻塞的receive或者非阻塞的监听方式去获取到消息

* 持久化机制，保证消息可靠性，这具体要研究下用法？
 可以设置ActiveMq持久化到磁盘或者数据库上，这时可能需要mq服务器有一些性能资源的开销。



*消息发送的方式（可通过mq连接的url参数设置，也可通过代码设置）
 同步发送，会有性能开销，因为阻塞，但安全性高。 非持久化并且非事务的消息默认采用同步发送。
 异步发送，和同步相反，非持久化消息默认采用异步发送。
 **开启事务的消息都是异步发送

* Broker 相当于mq的中控中心，负责消息保存订阅、客户单连接等。

* * MQ消息的应答方式（ACK_MODE）和应答类型（ACK_TYPE） 详见https://www.jianshu.com/p/c2bd409cadf2
 注意以下代码 客户端循环非事务消费10条消息，如果在第9条消息执行acknowledge()签收，则前面8条也会被签收，则只剩最后一条没被签收。
 因为receive()会将接收到的消息放到待签收的缓存中，一旦有执行acknowledge()则连带前面的消息都会签收。这应该就是所谓的session级别

     ```java
      for(int i=0;i<10;i++) {
                TextMessage textMessage = (TextMessage) consumer.receive();
                System.out.println(textMessage.getText());
                if(i==8) {
                    textMessage.acknowledge();
                }
            }
     ```
     
     
* 非持久化存储是存在内存 

* 消息发送的过程原理（看流程图会比较清楚）
  pruducerWindow应该是要存异步发送的消息缓存空间，所以它要保证空间足够用才能进行异步发送。
  这个缓存空间由activeMq配置 systemUsage节点相关参数进行设置
  pruducerWindow有点像线程池的队列长度

* 5种持久化机制
 kahadb  默认，事务日志方式
 jdbc 就是数据库存储，支持Oracle、MySQL...  ()
 Memory 内存，不配置持久化的时候就是内存方式
 LeavelDB  性能高于kahadb的方式，官方不推荐，原因不详。可以实现主从....
 JDBC with ActiveMQ journal 由于jdbc性能不算很很好，而这种方式是采用日志文件缓存然后同步到数据库。
 注意：ActiveMQ只能全局设置持久化方式。 发送和接收消息时只能单独设置消息是否持久化，而不能单独设置消息的持久化方式。


*topic类型，客户端订阅是要在发送端发送之前，如果客户端等发送完在上线连接到MQ并订阅，这时候是没法接收到之前发送端发送的消息。
 如果想要让客户端在发送端发送消息后，再订阅则只能通过持久化订阅。整个逻辑：客户端端先持久化订阅->客户端离线->发送端发送消息->客户端上线接到消息。
 持久化订阅具体的实现是通过设置一个clientID，即conn.setClientID("PersistentTopicMsg");
 注意：持久化订阅必须要求发送端发送方式为持久化模式

* 持久化订阅，即客户端一次性注册一条持久化订阅然后关闭客户端，此时服务端发送一条消息到MQ，当在打开客户端去获取持久化订阅的消息是能获取得到的
 要求在服务端和消费端都做相应的持久化设置

*JMS规范中的消息类型包括TextMessage、MapMessage、ObjectMessage、BytesMessage、和StreamMessage等五种

* 消息消费流程（看流程图比较清楚）
 2种消费方式，特别注意：同一session下不能同时使用这两种方式
 阻塞方式 received
 监听方式 MessageListenner

* 客户端在发送或消费消息时，在ack确认之前会放在一个列表中。

* preFetchSize 一个设置参数。消费端在消费消息时候其实会预先获取preFetchSize条消息，然后一条条消费，相当于是提前批量获取，以减少交互。
 如果有2个客户端同时开启，有4000条消息可消费，而2个客户端都设置preFetchSize>=4000,此时必定有一个客户端获取不到消息。


* optimizeAcknowledge 开启优化ACK，相当于批量提交，批量应答的。注意和preFatchSize配合使用。
 可以减少消费消息阻塞和网络通信开销，会出现消息重复消费！！！

* 消息重发机制（重新接收）： 6次重发后就发一个posion_type标志此消息有毒，然后这个消息就丢到死信队列（ActiveMQ.DLQ）。
 可以设置重试间隔时间，一般是设置间隔时间递增。
 死信队列也是消息队列，也可以被消费，可以配置它的策略。可以针对所有队列也可以针对某个队列设置策略。

* broker网络连接（高可用高性能解决方案），多个broker通过网络链接在一起（不算是数据同步）。通过networkConnector配置实现 
 它是一个单向通信，如两个activieMq a和b，a配置了网络链接而b没有，则客户端链接a可以消费到b上的消息，而客户端链接b却消费不到a的消息
 所以要达到a和b都能消费到各自的消息就必须在ab两个服务都配置网络链接。
 ？消息无法回流，是单项流动，无法再次回流。可以参数设置回流策略，replyWhenNoConsumers="true"
 如果activimq节点需要很多呢？ 

* activeMq的集群，利用zookeeper的有序节点实现leader选举。
 和持久化策略相关联。
 官方默认是kahaDB，所以官方推荐在集群中使用kahaDB文件共享方式来达到集群中数据的一致。kahaDB会有锁的机制保证读写唯一。
 如果是jdbc方式，则jdbc会在对应数据库有一张lock表用于提供锁，保证集群的读写唯一。


* ActiveMq适用于并发量小

* ActiveMq优缺点
 缺点：吞吐量低，无分片（数据量大就有问题）
 优点：TPS要求上低的话，开发易上手

？用户的请求的request和response对象可以直接存MQ，然后订阅处理吗？ 

* 实操点：
 各种jdbc方式的持久化配置使用，消息重发、broker网络链接。

* URL驱动  其实就是通过URL及其参数和协议来做接口的不同实例化，相当于做多态

* 装饰器模式可以使得功能按领域划分，便于维护和扩展


？学员问,高并发下如何保证消息不被重复消费,Mic回答说不能保证，这是怎么说。
？spring集成的activeMq消息监听接收方法里消息处理完后是自动确认应答吗？

？BlockingQueue的学习，应该在多线程部分会涉及吧。在dubbo容错方案ForkingClusterInvoker设置并行请求时源码涉及。

******************* KafKa begin **************************
*kafka集群内网测试环境
 版本：kafka_2.11-2.2.1-cdh6.3.2表scal语言版本2.11，kafka版本2.2.1（查看/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/kafka_2.11-2.2.1-cdh6.3.2.jar即可知道版本）
      
 安装目录：/opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554
（username:root   pwd:meimima） 
kafka
192.168.8.27:9092 cdh-5
192.168.8.30:9092 cdh-7
192.168.8.31:9092 cdh-8
 zookeeper
192.168.8.29:2181
192.168.8.24:2181
192.168.8.25:2181

*详细资料看网盘黑马《资料-企业级消息队列kafka》配套资料
 高性能高吞吐原因：简书《2、kafka为何能实现每秒几十万的吞吐量》
 基本实战看：csdn《SpringBoot集成kafka全面实战》

*KatfKa：基本原理看咕泡文档，相关面试题：https://blog.csdn.net/wanghaiping1993/article/details/125346010

*Broker不保存订阅者的状态，由订阅者自己保存。
无状态导致消息的删除成为难题（可能删除的消息正在被订阅），Kafka采用基于时间的SLA（服务保证），消息保存一定时间（通常7天）后会删除。

*Broker： 缓存代理，Kafka集群中的一台或多台服务器统称broker.
 Broker没有副本机制，一旦broker宕机，该broker的消息将都不可用。

*KafKa的集群拓扑，和redis的cluster模式集群相像
 集群存在多个broker，每个broker有多个服务器节点（这些节点有leader，有flower，由zookeeper选举），每个broker的数据都是互不相干的（总数据的一部分）
 每个broker里面的数据又被划分为多个分区（即partition），而我们的一个主题（即tipic）可以保存在多个分区或单个分区。

*rebalance：就是说如果消费组里的消费者数量有变化或消费的分区数有变化,kafka会重新分配消费者消费分区的关系。

*kafka，是不是每个group组拥有各自的offset？
  一个group组就是一个订阅者，每个组拥有自己的offset，每个group组的消费者，通过手动提交，来保证数据不会被重复消费或者丢失。我这样理解的对吗？ 

*kafka-eagle功能：查看积压小区、分区副本情况、broker使用率等

？消费者消费消息时监听消息（“推”）和主动拉取消息（拉）两种方式可以混用吗
   kafka采用的是拉取消息，这样可以根据消费者的消费能力进行消费。 而代码中的监听事件其实也是在设定了拉取速度之后的触发的事件，而不是broker推送的事件。

？kafka集群节点数量多少合适，经验值如下公式：
   kafka_broker_nums = 2*(峰值生产速度()*2/100) + 1        //假如峰值生产速度为50MB/s(通常是20+MB/s比较正常)。kafka_broker_nums = 2*(50*2/100)+1 = 3台

？分区数量数量多少合适，经验：在单机kafka上创建但partion的topic，进行生产和消费吞吐量测试（Tp和Tc，单位MB/s）,目标吞吐量为Tt，则分区数=Tt/min(Tp,Tc)。 如：Tp=20MB/s，Tc=50MB/s，Tt=100MB/s
   则partions=100/min(20,50)=100/20=5
 
? 消息分区分配策略：可以自定义策略，一般默认策略，机制如下：
    ① 若发送消息时指定了分区（即自定义分区策略），则直接将消息append到指定分区；
    ② 若发送消息时未指定 patition，但指定了 key（kafka允许为每条消息设置一个key），则对key值进行hash计算，根据计算结果路由到指定分区，这种情况下可以保证同一个 Key 的所有消息都进入到相同的分区；
    ③  patition 和 key 都未指定，则使用kafka默认的分区策略，轮询选出一个 patition；

？kafka什么情况下会丢失数据
  1、生产者生产消息时，当设置ack模式为0的时，leader未写入数据就挂了；在ack模式为1的时候，leader写入数据后，但是副本未同步，此时leader挂了，则数据也是会丢失
  2、消费者消费消息时，提交了offset但是没有正确处理消息，出现异常未回滚offset，也会导致“消息丢失假象”。kafka消息在过期后就会删除。
   
*概念(基本概念看csdn《Kafka基本概念》)
  rebalance：一个主题的分区分配消费组里的多个消费者的过程。 通过partition.assignment.strategy参数设置。一个组的消费者或订阅主题或主题分区的数量发生变化都会触发rebalance
  offset：主题+消费者+offset形成一组唯一标识存储在zookeeper里，用于记录每个或每组消费者的消费情况。早期版本存储在zookeeper，后面存储kafka的一个专门topic上

*基本使用：
       生产者配置：
            enable.idempotence=true 一致性设置（kafka 0.11.0.0+），通过消息的sequence号防重复生产（生产后会记一个sequenceId，后续写入要大于这个值才能写入）（出错等情况可能出现重试，重复发送生产），保证幂等性。
            producer.acks=1 其中0代表不等leader存就直接返回，1代表leader写入但slave还未同步就返回，-1代表leader写入且slave同步后返回。  三者响应速度和消息丢失率依次递减
            spring.kafka.producer.batch-size=16384 批量提交的大小
            producer.properties.linger.ms=0 延时提交，即批量提交的时间间隔。此配置为0表示每接收到一条消息就提交给kafka,这时候batch-size其实就没用了
            producer.buffer-memory = 33554432 生产缓冲区大小？？
            producer.properties.partitioner.class=com.felix.kafka.producer.CustomizePartitioner自定义分区器
       消费者配置：           
            consumer.properties.group.id=defaultConsumerGroup 默认的消费组ID
            consumer.enable-auto-commit=true 是否自动提交offset
            consumer.auto.commit.interval.ms=1000 提交offset延时(接收到消息后多久提交offset) ，相当于批量应答
            consumer.auto-offset-reset=latest 当kafka中没有初始offset或offset超出范围时将自动重置offset的策略:earliest:重置为分区中最小的offset;latest:重置为分区中最新的offset(消费分区中新产生的数据);none:只要有一个分区不存在已提交的offset,就抛出异常;
            consumer.properties.session.timeout.ms=120000 消费会话超时时间(超过这个时间consumer没有发送心跳,就会触发rebalance操作)
            listener.missing-topics-fatal=false 消费端监听的topic不存在时，项目启动会报错(关掉)
            listener.type=batch 设置批量消费
            consumer.max-poll-records=50 批量消费每次最多消费多少条消息
            consumer.fetch-min-size=1000 服务器应以字节为单位返回获取请求的最小数据量，默认值为1。和consumer.fetch-max-wait共同决定了消费的速度
            consumer.fetch-max-wait=500 如果没有足够的数据立即满足“fetch.min.bytes”给出的要求，服务器在回答获取请求之前将阻塞的最长时间（以毫秒为单位）,默认值为500

*kafka发送消息，可以发送key-value或value形式的消息

*kafkaTemplate.send()发送消息时，kafka会帮我们自动完成topic的创建工作，但这种情况下创建的topic默认只有一个分区，分区也没有副本。
 可以通过KafkaInitialConfiguration进行具体topic的分区和副本配置

*kafka为了保证消息消费顺序topic的每个分区只能被消费者组中一个实例消费。如果你的topic分区数为36，则可以尝试调整消费者实例数为36，

*如果在同个springBean里设置了2个同组@KafkaListener监听方法，会发现2个方法执行的线程都是一样的。 所以这样设置两个监听并不会提高效率，因为同线程则2个方法是同步执行。 
 但如果不同个springBean里设置了2个同组@KafkaListener监听方法，会发现2个方法执行的线程是不一样的。 所以这样可以切换线程执行，可能可以提高效率。 至于能不能提高效率则是要看切换线程“值不值得”
 kafka消费者是拉取一次执行一次@KafkaListener监听方法，如果监听方法阻塞，则拉取也会暂缓

*配置事务的id，开启了事务会默认开启幂等性 props.put("transactional.id", "first-transactional");

*kafka服务配置的server.propertis里配置log.retention.hours=24  则表示topic消息可保留24小时

*自Kafka 0.9.0.0版本开始，Kafka已经将偏移量（offset）的管理从Zookeeper转移到内部主题（Internal Topic）__consumer_offsets中。
 在Kafka 2.8.0及更高版本中，Zookeeper中存储的元数据信息已经被彻底移除，Kafka完全采用了自己的元数据存储方式。

*kafkaTool里的菜单栏tools-zookeeper browser，查看/cluster/controller可以查看controller节点

？为什么公司用kafka2.2，而不用更高的版本（可以完全脱离zk），这可能是为了和scala2.11适配

？将原本的单分区topic更改为多分区（通过KafkaInitialConfiguration更改），然后添加了100条helloword数据，然后在kafkaTool查看时发现，数据没有分配到其它新增分区，而是在原本分区上。！应该是100条样本数太少了，测试个1w条就可以了。 

？启动生产者生产100条数据到kafka，后面再启动消费者消费数据，发现消费不了启动前生产者添加的100条数据
  ！原因很简单，consumer.auto-offset-reset设置了当kafka没有初始offset或超出范围时重置offset的策略，测试项目中设置为latest是“最新”，即消费分区在消费者启动后产生的数据会被消费。

？kafka消费者已经停止了，用kafkaTool查看zookeeper上的消费者节点还是active=yes
  1、Zookeeper可能还没有检测到消费者已经停止。这可能是因为Zookeeper的心跳间隔比较长，或者因为网络延迟等原因导致Zookeeper没有及时检测到消费者的停止。
  2、Zookeeper可能已经检测到了消费者的停止，但是它仍然保留了消费者节点的信息。这可能是因为Zookeeper节点的过期时间比较长，或者因为其他节点仍然在使用该消费者节点的信息。
      ？如果是上述两种原因，那么有没有相关的配置可以设置。

？内网带宽有无限制，限制多少，一般是根据厂商的服务器产品相关。但一般都比较大，不会成为瓶颈。
  比如：现公司用的华为云“通用计算增强型C6s”的最大内网带宽是30Gbps

？为什么在zookeeper查看/consumers并不能查看到kafka消费这的信息
   ！kafka在某些版本后已经将offset等信息自己管理，zookeeper上存储的信息变少了，也就是半脱离zookeeper。  在kafka高级些的版本已经完全脱离了zookeeper

？kafka生产者写入brocker消息为什么采用轮询策略而不适用随机策略，轮询性能表现更好，所以作为默认为轮询策略。
  ！个人认为主要是kafka的吞吐量是比较高的消息中间件，如果用随机算法开销会比较大，而轮询则比较简单。 

******************* KafKa end ****************************


* Redis 
 * 学习网站redisdoc.com
 * 几种数据类型结构及常见应用场景csdn《redis八种基本数据类型及其应用(全)》
 * 结合淘淘和咕泡的文档和中文官网进行学习实践。
 * 5种数据类型中的list，提到了“双向链表”：每个数据在内存中存储位置是不连续，但每个数据节点都存储了上一个和下一个节点的指针。
    双向链表在插入和删除复杂度低，但是内存开销大。“压缩列表”：和双向列表相反，内存中是连续，内存空间小，插入删除复杂度高。
    redis3.2前都是用上2种一种，redis3.2+就是quicklist，是上2种的综合。
    注意：String类型以外的类型在添加元素后（如lpush users aa），再用set users 123，则users这个会变成String类型。 也就是String类型的set命令能强制转换类型。 而且他数据类型的设置命令会报错。 

 * 守护进程的方式运行：守护进程一般在系统启动时开始运行，除非强行终止，否则直到系统关机都保持运行。
    常见的守护进程包括系统日志进程syslogd、 web服务器httpd、邮件服务器sendmail和数据库服务器mysqld等。

 * fork一个子进程：相当于复制一个子进程，和github的fork项目仓库差不多。 

 * 注意Jedis三种使用方式：单机、分片、集群。另外还提供哨兵功能和连接池功能。 详见知乎《Redis集群的 3 种方式，各自优缺点分析！》
    Jedis连接池包括2种：普通单机连接池、哨兵连接池、分片模式下连接池。都通过jedisPool.getResource();获取一个Jedis对象进行操作数据
    集群cluster模式下是自带连接池的（配置详见blog《spring集成 JedisCluster 连接 redis3.0 集群》）。JedisCluster实例即可操作数据
    分片其实也算是一种分布式手段


 * redis的数据库是0-15,且不支持自定义命名，以dbX的方式命名（db0~db15）；
   应以命名空间的方式理解Redis数据库db，多个应用程序不应使用同一个Redis的不同库，而应一个应用程序对应一个Redis实例，不同的数据库可用于存储不同环境的数据。
  注意：Redis集群下只有db0，不支持多db。

 * 2种持久化方式
    rdb快照，在一些自定义或系统自身的条件下会执行快照，此时可能会阻塞主线程造成其它客户端不能访问redis
                  配置维度：指定时间，达到指定键数量
    aof文件，没次操作都写入操作日志文件到磁盘，性能不会有大的影响。但是文件会一直增大，
           特别是当有一些冗余操作如执行"set foo 1"再执行"set foo 2"，但redis会有优化方案：重写aof文件。

 * 内存回收策略，详见blog《redis-淘汰策略》。淘汰策略是在达到最大内存限制后进行的处理策略，默认是不删除策略（noeviction）
   注意：lru和lfu的区别：lru是指最久没使用的数据淘汰，lfu是使用次数最少的数据淘汰。

 * Lua脚本相当于一段sql语句集或存储过程，可以让redis一起执行多个命令语句，从而减少多个单语句在网络传输中的消耗。执行lua脚本实例如下：
    如 EVAL   "return {KEYS[1],KEYS[2],ARGV[1],ARGV[2]}"     2         key1      key2     first      second
     [命令] [脚本内容]                                [参数个数]  [参数名1] [参数名2]  [参数值1]  [参数值2]

 * lua脚本可以由redis客户端发送到redis服务端执行并保存，其它客户端可以直接复用。  

 * redis是单线程，这是就只能用到CPU的一核心，如果要充分利用服务器CPU的多核，可以在同一台服务器上部署redis集群。

 * redis是通过NIO实现异步，即多路复用。

 * Redis存在最终一致性，原子性问题。 例如：age=1两个客户端同时访问Redis 执行age++;最后age可能等于2或3
    在单体redis中，可以通过MSET命令保证多个命令同时成功或失败，保证最终一致性。但是在集群下这个命令无法保证一致性。
 解决方案：使用lua脚本，例如上面的age++;命令，把这个命令编写在lua里面，两个客户端AB都执行过lua而不是直接执行命令。
           此时A执行lua时是不受B的影响的，并且等到A执行完后，B执行的也是同样的lua，因为Redis可以执行过的lua保存起来。
 问题：如果lua脚本复杂，执行时间很长，则其它客户端连接会被阻塞掉并返回错误。用script kill去终止lua脚本的执行

 *如果redis已经有一个key是string类型（用set方法设置的），但是此时用别的类型方法操作，如hget或hset则会报错。

 *jedis中用byte[]的key存值  用string的key取值，因为redis内部应该也是用byte[]进行存储
  但是在redis-cli命令行中使用hget命令却不能像java代码中jedis用byte[]为key的值。

 *注意在JedisCluster集群模式下是不能用模糊查询的，只能是单机模式下

 *目前spring-data-redis已发布的主干版本都不能很好的支持Redis Cluster的新特性。为了解决此问题spring-data-redis开源项目组单独拉了一个315分支，但截止到目前尚未发布
  315分支gitHub下载路径如下：https://github.com/spring-projects/spring-data-redis
  315分支源码下载路径：http://maven.springframework.org/snapshot/org/springframework/data/spring-data-redis/1.7.0.DATAREDIS-315-SNAPSHOT/
  后来经过测试，1.7.0+版本均可以支持Cluster特性
  注意：Spring Data操作Redis时，发现key值出现 \xac\xed\x00\x05t\x00\tb ，原因是序列化的时候采用默认的序列化器，难怪jeesite里jedis的key序列化都要区分下Object和String
        可以自定义序列化器，详见gupao-demo。由此可见redis中的存储实际上都是通过byte[]存储的，即二进制存储

 *缓存穿透：缓存和数据库里没有key或有key无value，用户发送大量请求，使得数据库压力增大。解决：请求鉴权、存储key-null（注意设置过期时间不超过5分钟，因为不知道什么时候会插入该数据并且更新缓存）、布隆过滤器
  缓存击穿：某一热点数据缓存失效导致大量请求直达数据库。 解决：设置热点数据过期时间加长或不断更新过期时间、分布式锁减少数据库压力
  缓存雪崩：大量缓存同一时间失效或过期。造成大量请求涌到数据库。 解决：分布式缓存、设置过期时间时要随机、热点数据永不过期。


 ？？scan和keys命令的对比
 ？？为什么Object result = redisTemplate.execute(new SessionCallback<String>{...});返回的不是String而是Object
    ！！特别注意使用redisTemplate时，用RedisTemplate<Object,Object>接收（这样可以用ObjectSerializer），才可以使用泛型才可以返回上述的String类型


 ？？以下几个方法的区别 参考csdn《RedisTemplate使用PipeLine的总结》
    @Nullable
    <T> T execute(RedisCallback<T> var1);

    @Nullable
    <T> T execute(SessionCallback<T> var1);
    
    List<Object> executePipelined(RedisCallback<?> var1);
    
    List<Object> executePipelined(RedisCallback<?> var1, RedisSerializer<?> var2);
    
    List<Object> executePipelined(SessionCallback<?> var1);
    
    List<Object> executePipelined(SessionCallback<?> var1, RedisSerializer<?> var2);
  以上方法总结：
     1.execute分RedisCallback、SessionCallback两种方式
     2.上述2者只是操作的方式和对象不同，但是都可以实现普通、管道、事务方面的需求。
     3.管道模式相当是在一次redis的请求-响应中批量处理多个命令，有点类似lua脚本。当然这些也都是在一次Connection中完成
     4.事务的实现有两种：使用executePipelined(RedisCallback rc) 详见https://yq.aliyun.com/articles/648282
                        使用execute(SessionCallback sc) 详见https://blog.csdn.net/qq_39455116/article/details/90749257
     5.execute的多有操作都是在一次Connection中完成，这也就是它和redisTemplate.opsForValue()等操作方式的区别。
     6.单机下支持事务、管道模式，RedisCLuster集群是不支持

 *redis事务参考csdn《java 使用RedisTemplate实现Redis事务》，blogs《SpringDataRedis事务 专题》，csdn《redis一些关于SessionCallback和事务要注意的地方》
  redisTeplate操作redis事务要在一次连接中，并且使用一定要用SessionCallback，如redisTemplate.execute(SessionCallback sc)
  redisTemplate是RedisCluster集群下是不支持事务和管道模式的。
  redis的事务和DB的事务是有本质的区别的，redis事务是没有回滚的。也就是redis事务更像是批量原子命令，要么都执行要不都不执行。保证事务中指令的顺序性，不被线程所打乱。
  实际上就是通过watch一个key，在事务代码里去改变这个key，则只有其中第一个更改key的线程拥有这个事务的执行权，其它线程的进入事务后都会被取消执行。
  **如果在EXEC指令被提交之前，Redis-server即检测到提交的某个指令存在语法错误，那么此事务将会被提前标记为DISCARD，此后事务提交也将直接被驳回；
    但是如果在EXEC提交后，在实施数据变更时（Redis将不会预检测数据类型，比如你对一个“非数字”类型的key执行INCR操作），某个操作导致了ERROR，那么redis仍然不会回滚此前已经执行成功的操作，而且也不会中断ERROR之后的其他操作继续执行。
    对于开发者而言，你务必关注事务执行后返回的结果（结果将是一个集合，按照操作提交的顺序排列，对于执行失败的操作，结果将是一个ERROR）。
  具体gupaovip-demo

 *redisTemplate执行lua脚本实现分布式锁，详见gupaovip-demo

 *注意管道模式和事务的区别（详见csdn《Redis编程实践【pipeline和事务】》）：
  *管道模式是将多个命令缓存在client的outputstream，因此相当于批量提交，实现多个命令使用一次网络请求响应
  *事务应该是在redis服务端进行加锁，保证事务持有redis服务的执行权，执行过程中保持排他性。 因此他需要在同个session中，但是可能是多次的网络请求响应。

*布隆过滤器在redis上的基本使用流程
 在reidis服务上安装布隆过滤器插件
 编写add.lua和exist.lua两个lua脚本文件，分别代表添加元素和判断元素是否存在的脚本
 在java代码中定义add和exist两个方法，分别执行上述两个lua脚本
 在程序初始化时候，调用add方法添加元素（比如网站所有的userid）
 当请求来的时候通过exist方法判断元素是否存在 

*布隆过滤器在java代码里的基本使用流程
 通过guava的布隆过滤器类创建一个布隆过滤器
 将要被查找的数据在程序启动时添加到布隆过滤器（比如网站所有的userid）
 当请求来的时候通过布隆过滤器的方法判断元素是否存在

*redis cluster集群部署和集群节点增删（及数据迁移）实战详见bilibili《分布式一致性hash、redis 集群的重要应用丨分布式一致性hash原理 丨redis 集群原理以及搭建....》
*redis集群的hash一致性问题
 比如在3个redis节点的集群中，原本key为cny的值是通过hash后取模（除以3取余），确定存储在哪一个redis节点。
 但是当如果redis集群节点数量增减（比如增加1个节点），则原来各个节点存储的数据如果还是存储在原来的节点。
 那么按照新的取模算法（除数变成4）去找cny这个key则会找不到，也就是可以失效了。 hash不一致了，即“hash一致性问题”
 而如何解决：
  1、将原本的hash取模算法变更
  2、假设将所有真实的节点（比如3个）均匀分布放在一个圆环上，相当于3个大节点。
  3、然后将hash取模的除数变大（实际是2的32次方，redis是2的14次方），也就是相当于有2的32次方个虚拟的节点，将这些虚拟节点分布到这个圆环上。
  4、当我们要存key时，先进行hash2的32次方取模确定是哪个虚拟节点
  5、虚拟节点归哪个真实节点（大节点）管辖，就看虚拟节点在圆环顺时针方向上第一个真实节点是谁。从何建立key->虚拟节点->真实节点的映射
  6、利用这样的映射规则来确定具体在哪个真实节点，这样就能保证增减节点时候映射规则的相对固定。
  7、但是当增减真实节点后就会涉及节点数据迁移问题。顺时针上老的节点就要把部分的数据迁移给新插入的节点。
  8、数据均衡分配问题：因为hash取模的除数如果太小就会出现不均衡，为了让数据均匀分布，那么就提高除数，相当于让样本虚拟节点足够多。
  引入redis Cluster集群中使用到hash一致性原理。
  redis Cluster集群拓扑：集群由多个主节点和多个从节点组成，主节点各自存储不同的数据分片，从节点存储主节点的副本。 从节点只做备份，主节点读写。
  最终一致性：主节点接收客户端写数据立即返回，然后异步的传输给从节点，实现最终一致性。这样出现主节点写完数据还没传输给从节点时，主节点宕机了，造成此次写的数据丢失。 
  高可用：主从节点保证了高可用
  高性能：多个数据分片节点形成的集群保证了高性能
  去中心化：任意一个redis节点都能连接，但是如果数据不在本节点，则本节点会根据hash算法分配返回一个从定向给客户端去让客户端重新连接到对应主节点，而非从节点（主要是因为从节点只做备份，主从复制是最终一致性，可能出现小的不一致）
  再平衡（rebalance）：当集群中增减节点时，就会涉及数据再分片。仅 Redis Enterprise 支持自动重新分片。这包括重新分片、分片迁移和设置自动平衡触发器而不影响您的应用程序。如果您运行的是 Redis Community 版本，则需要手动执行维护操作。

* Nginx
 * nginx.conf的server_name和location配置规则需要补充学习。 
    server_name和location的匹配是相互独立的，如果www.s1/location1匹配到server1但是找不到location1的匹配则会报错，而不会去server2里看有没有location1
    server_name匹配优先级：完全匹配>通配符在前>通配符在后>正则>listen配置项后有default或default_server的>前面的都没匹配到则找到listen端口的第一个server
    location匹配优先级：  
 * Nginx安装第三方扩展模块需要重新编译，在第三方扩展模块添加后要进行编译时，原来编译的相关的参数也要加上去，不能省略。
    为了不覆盖原有安装后的相关配置（如：nginx.confg），可以将编译后objs/nginx目录拷贝到原本安装sbin目录（如：/usr/local/nginx/sbin）

 * C语言的应用，在linux下 用make命令是编译，make install命令是安装的意思。

 * ./nginx -V 查看nginx版本及相关信息，如扩展模块信息。在添加新的扩展模块时，可通过此命令查看当前现有的一些扩展模块。

 ？学习要点：
  ？要学习常见的Nginx扩展模块：状态统计http_stub_status_module、限流ngx_http_limit_req_module
  ？proxy_pass模块下的各种常见参数配置，如proxy_set_header Host $host;proxy_set_header X-Real-IP $remote_addr;等等
    proxy_set_header相关设置可以让目标服务器从nginx那边获取到真正客户机的一些请求信息，而不是获取nginx的请求信息
  ？负载均衡中ip_hash策略的应用场景，详见csdn收藏 https://blog.csdn.net/xqhys/article/details/81788358
    其实可以举例917使用又拍云，我们做了一层服务器缓存，此时就要求根据ip或url进行hash，让客户端相对固定的访问统一个真实服务器。
  ？io 模型，epoll、select....是什么鬼

 * nginx.conf里面也可以用include 来包含其它的配置文件，从而达到分类治理的效果。

 * 用nginx或tomcat做静态资源服务器时，静态资源的header里会添加ETage和Last-Modified两个信息以供浏览器决定如何做缓存，如：
    ETag: "5b0ce6b0-570b"
    Last-Modified: Tue, 29 May 2018 05:35:44 GMT
    但实践中一般会指定明确的缓存策略，如设置expires为1d。 597的静态资源是设置expires为30天

 * nginx中的gzip压缩是可逆的，无损压缩，但是会消耗一定的CPU资源，这个如何去权衡。
    图片、音频、视频用gzip压缩的后大小基本不变，只能做有损压缩，如降低分辨率和质量。或者可以用第三方的服务应用。

 * nginx进程模型：一个master进程加多个worker进程组成，worker进程是从master进程中fork出来的。
    通过ps ef|grep nginx 可以看到nginx默认开启了master和worker两个进程
    工作进程数通过worker_processes设置，一般建议设置为linux的CPU核心数
    worker_connections=1024说明一个worker进程可以处理的连接数，即并发数，理论上如果有3个worker进程，则总并发可达1024* 3

 * fork进程是UNIX关于进程管理的一个术语，本质是新开一个进程，但是不从磁盘加载代码，而是从内存现有进程复制一份。

 * 如果nginx的并发/吞吐量不够用了怎么办
  * 简单方式：在nginx做集群，然后dns做轮询
  * 昂贵方式：nginx做集群，然后F5做负载均衡
  * 复杂方式：dns做地域性的解析，指向当地的机房。


* NIO 先看博客园收藏《Java NIO：NIO概述》，在看咕泡课程笔记，再看博客园收藏《Netty序章之BIO NIO AIO演变》
 * 同步/异步，阻塞/非阻塞概念可参考简书收藏《深度解读Tomcat中的NIO模型》
 * 其中司机-售票员-乘客 可以很好的解释NIO和BIO的区别。BIO有点像每站必须停的公交，而NIO有点像中长途巴士，根据乘客要停的地方在停。
 * BIO模型下，如下代码ServerSocket需循环接收到客户端Socket实例，然后new Thread()去处理。这时候对于客户端是阻塞的，
    while (true) {
     Socket socket = serverSocket.accept();
     new Thread(new ServerHandler(socket)).start();
    }
 * NIO模型下，客户端请求服务端时并留下事件，而服务端用一个线程去轮询这些事件，当数据准备好了就触发对应的事件。 
    这就是同步非阻塞，同步体现在事件轮询，非阻塞体现在客户端不必等待服务端。

 *在Java NIO中，是通过selector.select()去查询每个通道是否有到达事件，如果没有事件，则一直阻塞在那里，因此这种方式会导致用户线程的阻塞。
　也许有朋友会说，我可以采用 多线程+ 阻塞IO 达到类似的效果，但是由于在多线程 + 阻塞IO 中，每个socket对应一个线程，这样会造成很大的资源占用，并且尤其是对于长连接来说，线程的资源一直不会释放，如果后面陆续有很多连接的话，就会造成性能上的瓶颈。
  不过要注意的是，多路复用IO模型是通过轮询的方式来检测是否有事件到达，并且对到达的事件逐一进行响应。因此对于多路复用IO模型来说，一旦事件响应体很大，那么就会导致后续的事件迟迟得不到处理，并且会影响新的事件轮询。

 * BIO是面向流的，而NIO是面向Buff的。

 * 堆外内存：即不被jvm管理的内存空间。堆内内存则相反。

 * 系统调用，我们的java应用要调用到操作系统内核的api时候就叫系统调用。

 * 操作系统的内核是管理我们的内存，操作CPU、管理文件系统等主要资源的程序。
    而操作系统就是由内核和外围的一些程序组成的。
 * 内核态，只能由操作系统内核来调用的资源，如文件系统。
 * 用户态，和内核态相反。

 * 系统调用的时候，一旦应用程序调用到内核的api的时候，就会处于阻塞状态。

 * BIO 同步阻塞
 * NIO 同步非阻塞

 * 阻塞是对于客户端，同步对于服务端。 这里的客户端和服务端，可以理解为应用程序和操作系统内核。

 * NIO的chanel是双向的，而BIO的流是单向的。

 * NIO的buff简单理解成为一个数组。

* NIO理解可以参考博客园收藏《支撑Java NIO 与 NodeJS的底层技术》

* 堆内内存 是由jvm管理的内存  堆外内存是不被jvm管理而是由操作系统管理的内存

* 个人理解同步与异步，阻塞与非阻塞
 * 对于服务端来讲是同步与异步，也就是说服务端如果"停滞"了则为同步，否则异步
    对于客户端来讲是阻塞与非阻塞，也就是客户端如果"停滞"了则为阻塞，否则非阻塞
    注意，对于底层来讲java进程和系统io内核api来说，java进程为客户端，而系统内核为服务端。
        此时对于java进程和系统内核交互时，分为系统内核有数据准备阶段和数据赋值两个阶段。
        在数据准备阶段，java进程请求io数据时如果能立即返回则为非阻塞，反之为阻塞。
        在数据赋值阶段，系统内核如果是立即处理，则为同步，否则为异步。
        这个过程可以结合大白老师的nio_demo进行理解。
  * 宏观的看：有客户端，服务端，系统内核3方，客户端和服务端其实都有一个os系统内核。这两个系统内核通过io交互然后把数据通过事件推给客户端和服务端。

 * BIO是面向字节的，就是只能一个字节一个字节操作
    NIO是面向buff的，就是可以块块数据进行操作

 * java是不允许直接操作地测内存相关的东西，但是有一个unsafe操作类可以让我们操作。 程序员一般不用。但是一些Nio框架会用到。

 * Nio的buff相关概念（详见csdn收藏《JAVA NIO缓冲区(Buffer)------ByteBuffer常用方法详解》）：
    capacity 整个buff的容量
    position 读或写操作时的起始指针位置
    limit 读或写操作时的限制长度
    flip()当写操作时要转为读操作时，通过flip()方法将limit设置为position的值，然后将position指针调整到buff首位即0的位置，从而达到可以读取已写数据
    rewind() 似乎和flip类似  具体百度下或直接看方法源码即可清楚 
    marke


 * Nio的selector也有点像rpc一样，其实是在服务端和客户端的一个代理，用于屏蔽细节。
    对于客户端和服务端把相应的事件handler注册到它的selector上，而服务端的事件由操作系统去触发，然后顺理成章的触发客户端的事件。
    简单的比喻：clientA、clientB找server下订单，server去找系统内核os工厂真正制造数据产品dataA和dataB。
    server有一个线程轮询的问dataA和dataB好了没？ 如dataA好了，server就打电话给clientA说好了，把dataA通过事件传递给他。
    注意：一个selector实例既可同时注册客户端和服务端的channel的相关事件。它其实是一个事件容器，当注册的事件的数据准备好了，操作系统会将对应的状态
       设置为true（如：selectionKey.isWritable()为true），而开发人员只要轮询selector的selectionKey的状态即可根据状态进行相应的读写等操作。


* 注意socketChannel.write(writeBuffer);并不一定会将writeBuffer里的内容一次性写入到socketChannel中，

* Arrays.copyOf(byte[] original, int newLength)可以拷贝原数组的指定长度的元素

* Netty4.x版本是比较成熟稳定的版本，使用的是NIO，而Netty5.x用的却是AIO，但是由于操作系统支持及性能表现没比4.x好，所以主流都是用Netty4.x
  为什么Netty使用NIO而不是AIO？
  原因：在Linux系统上，AIO的底层实现仍使用EPOLL，与NIO相同，因此在性能上没有明显的优势；Windows的AIO底层实现良好，但是Netty开发人员并没有把Windows作为主要使用平台考虑。

* Netty学习 找不到大白的相关笔记，可学习网上
 博客园收藏《netty入门（一）》 https://www.cnblogs.com/sky-chen/p/10497166.html 这里面有对大白代码的剖析
 教程系列《Netty入门教程——认识Netty》https://www.jianshu.com/p/b9f3f6a16911  （图片显示不出来，执行$('.image-view img').each(function(){$(this).attr('src',$(this).attr('data-original-src'))});）
 博客园收藏《Netty框架入门》 代码部分可不看

* Netty的几个组件
 EventLoopGroup 事件循环器组，它可包含一些线程。实际上等价于一个线程池。 他可以传递给Bootstrap或ServerBootstrap作为主事件循环器组和工作事件循环器
 EventLoop 事件循环器，一个线程可对应多个EventLoop。一个 EventLoop 在它的生命周期内只和一个 Thread 绑定；
 Bootstrap/ServerBootstrap 客户端服务端的帮助启动类
 Channel 和Nio的channel对应，有做了一些封装。一个 Channel 在它的生命周期内只注册于一个 EventLoop；
 Handler 用于非业务和业务的一些逻辑处理，相当于事件的方法体。
 ChannelFuture是一个Future接口对象，在channelFuture.channel().closeFuture()代码实际返回的实例还会是一个promise对象。

* 网上说Netty需要一段时间才能预热，但是它能够处理比NodeJS每秒多40％的请求。 只是代码量要比NodeJS多很多。

* serverBootstrap.childHandler()和handler()的区别，是面试中常考的一个问题。
 handler是服务端channel接收连接及初始化等相关的事件业务处理逻辑，是与bossEventLoopGroup相关的处理产生的事件。
 childHandler是处理客户端连接生命周期中的一系列事件处理，也就是workEventLoopGroup相关处理产生的事件。
 理解：在创建nett服务ServerBootstrap时会传入两个EventLoopGroup类型参数bossEventLoopGroup和workEventLoopGroup。如上所述：
          bossEventLoopGroup处理的是服务端通道接收连接及相关初始化工作，不需要处理开发者写的业务代码，所以在大白的lion项目设置它的ioRatio=100,。
          workEventLoopGroup处理的是客户端连接生命周期期间的一系列开发写的业务代码，以及业务代码中的相关io读写操作。所以大白的lion项目设置它的ioRatio=70
 应用：netty的3种reactor线程模型就是通过bossEventLoopGroup和workEventLoopGroup的不同调节实现的
          单线程模型：reactor模型的接收和处理都是同一个线程，bossEventLoopGroup和workEventLoopGroup是相同，且指定线程数为1
          多线程模型：reactor模型的接收用一个线程，处理用多个线程。 即bossEventLoopGroup指定单线程，而workEventLoopGroup则多线程
          多线程主从模型：reactor模型的接收和处理都用多个线程，即bossEventLoopGroup和workEventLoopGroup分别指定线程数大于1的线程数。
          注意：*bossEventLoopGroup和workEventLoopGroup都是EventLoopGroup类型，都可以设置ioRatio。
                   *服务器端的 ServerSocketChannel 只绑定到了 bossGroup 中的一个线程, 因此在调用 Java NIO 的 Selector.select处理客户端的连接请求时, 实际上是在一个线程中的,
                    所以对只有一个服务的应用来说, bossGroup 设置多个线程是没有什么作用的, 反而还会造成资源浪费.

* 一般Tomcat默认还是Bio的io模型，可配置Nio 
 使用NIO方式处理并发性能好的前提是 每个请求耗时不能高，但是这样对现有的request response处理要有额外处理。 
 如果不能达到这个要求，用 NIO反而会是整体性能下降。
 现在一般的处理流程： 请求进来，查数据库，执行业务逻辑，渲染，然后返回。整体耗时很长。所以……

* Nio_Demo中serverSocketChannel.configureBlocking(false);实际上就是让serverSocketChannel.accept()方法非阻塞，即同步非阻塞模式。
 如果设置为true则serverSocketChannel.accept()方法阻塞，此时如果serverSocketChannel.regist()内部会判断blocking为true则抛异常。
 即设置为true实际上就相当于BIO的模式，并且serverSocketChannel不能注册到selector上
 注意：serverSocketChannel是可以不注册到selector上的。 个人理解selector是一个轮询载体，也是系统调用过程中所产生事件的接收体

* Nio通信的整体过程：


* netty源码中有些方法是带有0的(如channelRead0)，一般是真正干活的，而不干活的是如channelRead

* netty可以实现3中Reactor模型：单线程模型、多线程模型、主从多线程模型。详见咕泡文档《09-Netty 源码分析之EventLoop.pdf》

* handler实现类上的@Sharable注解主要是为了这个handler可以被多个channel安全地共享。
 因为handler里是业务逻辑代码（如业务逻辑A），而多个客户端channel他们可能在EventLoopGroup里的不同线程，他们要共同访问A，所以A代码要保证线程安全。

* Netty可在任何系统上运行，但对于不同的系统会有不同的折中，Linux系统中的epoll具有高可扩展的I/O的事件通知，Linux上的JDK的NIO则是基于epoll，
当使用epoll取代NIO时，可以使用Netty中的EpollEventLoopGroup取代NioEventLoopGroup，使用EpollServerSocketChannel.class取代NioServerSocketChannel.class。
https://www.cnblogs.com/leesf456/p/6895145.html

* 沾包问题：详见CSDN收藏《Netty4实战 - TCP粘包&拆包解决方案（这个文章解决了自己想解决的问题）》

* 在快速重连的图解中，HandlerShakeHandler、FastConnectHandler是netty自带的组件

* * 研究下ChannelFuture和Future接口   juc里线程池操作有使用到Future

*关于Netty服务和普通web服务并发相关问题：
 0、学习Netty并发相关可以和tio框架做对比。官网有相关测试报告参考https://www.tiocloud.com/doc/tio/61
 1、4核心16G内存单机Netty服务能处理上百万的连接吗？
     答：可以，这个是不错的配置，实际上并发处理百万连接，并非长链接。 此时主要瓶颈在于IO读写和带宽。
 2、4核心16G内存单机Netty服务能建立上百万的长连接吗？
     答：对于这个配置的Netty服务来说，建立上百万个长连接是非常困难的，因为每个连接都需要占用一定的内存资源，长时间运行也可能导致内存泄漏等问题。
           同时在大量连接的读写也会耗费IO及带宽资源。
 3、一个netty的连接大概需要占用多少内存？
     答：连接占用内存主要由连接的状态、缓冲区大小、协议。通常一个Netty连接占用内存几十到几百字节之间。实际测试为准。
           连接状态：连接建立时会耗费一些内存资源、关闭时会释放
           缓冲区大小：Netty中的读写操作是基于缓冲区的，连接的读写缓冲区大小对内存占用也有影响。如果应用程序使用较大的读写缓冲区，连接所占用的内存也会相应增加。
           协议：Netty支持多种协议，例如HTTP、WebSocket等等。不同协议的连接所占用的内存也不同，例如HTTP连接需要占用一定的内存资源来处理HTTP头等信息。
                    一个典型的HTTP请求标头带cookie等信息大约1-2 KB，不带额外信息大概200B，而对于具有许多cookie、标头或其他元数据的大型响应，响应标头的大小可能从几KB到几百KB不等。
                    在大白推送系统中私有协议的头只要13B，对比http协议的的占用都减小了15~150倍以上。而websocket协议的头在2~14字节之间，根据实际数据长度规则变化。
                    
 4、大白的推送系统达到百万需要什么配置？
      
 5、单服务器单端口的Netty服务有没有可能建立超过65535个连接？
     不能，因为单端口有65535个句柄限制（因为每个连接都得有标识才能相互找得到）。可以通过以下方式扩容：
     多端口：通过在同一台服务器上使用多个端口。那么是不是Netty的客户端和服务端监听多个端口即可，还是要一台服务器部署多个Netty服务？
     多服务器节点：将Netty服务部署到多个服务器节点，并负载均衡。
     
 5、如何模拟百万并发请求做压测？ 
      可以用jmeter做模拟     
      首先单服务器单端口的Netty服务是不可能建立超过65535个连接的（句柄限制）。解决方式那么是不是可以让Netty客户端和服务端监听多个端口？ 

 6、websocket请求、netty-channel请求、http请求有什么区别？

 7、性能测试中的并发量和QPS有什么区别？
     并发量指在某个时间段内同时处理的请求数量。在Web应用中，客户端向服务器发送请求，服务器处理请求并返回结果，这些请求和响应的交互会占用一定的资源，
     比如CPU、内存、网络带宽等。因此，一个服务器在同一时间内所处理的请求数量越多，就意味着它需要承担更高的并发量。通常，我们使用并发用户数或者并发请求数来衡量系统的并发能力。
     而QPS则是指在单位时间内系统所能够处理的请求数量

 9、一个普通服务器的带宽应该是多大？
       不同规模网站带宽大小：
       带宽2M 适用于小型企业网站、OA办公平台、H5页面等
       带宽3M 适用于中、小企业网站、初级网络应用、CRM、OA办公平台、H5页面等
       带宽3M 适用于中、小企业网站、中级网络应用 日IP达到1000左右
       带宽5M 适用于中大型企业网站 中、小型商城网站 静态网站 初级游戏网站
       带宽5M 适用于中大型网站应用 社交平台 大型商城网站 下载站 视频网站等
       带宽10M 大型企业网站 集团业务 政企业务 对数据安全要求较高的用户群体 同时针        
       
 10、通常说的“同时在线访问人数”指什么？ 
      同时在线访问人数通常指15分钟内访问页面数或pv，如平均页面大小1000KB，3秒完全打开，带宽10M，15分钟理想状态下可以打开的页面数公式：10*1024÷8÷1000=1.28 即每秒打开1.28个页面，15分钟大概打开1152个页面
      根据以上公式，我们根据不同类型的网站，在同等带宽下，大致估算出：
        ①、如果是图片或者文字类的网站，1M带宽就相当于200人左右同时在线。那么10m宽带的云服务器，可以访问2000人左右。
        ②、假如是视频网站或下载类型的网站，那么就要看并发连接数目。带宽是10M，每个人的页面为30KB的话，并发同时操作，就是2400人同时在线。
        ③、若是正常的中小企业站，1000人同时在线，占用的带宽大概是2M-5M之间。那10m宽带的云服务器，可以访问人数在2000-5000之间。
      我们买的服务器的带宽就是访问的吐数据出来的速度，这个速度的话一般是不会太快的，但是我们服务器的下行速度是贼快的，基本无限制可以达到Gbps的大小。

  11、线上查看TPS（每秒事务处理量）可以使用如下工具：
     JMeter：JMeter是一款开源的压力测试工具，可以模拟多种协议下的负载测试，并可以实时监控系统的TPS。
     VisualVM：VisualVM是一款Java应用程序监控和调优工具，它可以监控Java应用程序的运行情况，包括TPS、内存、线程、GC等信息。
     Prometheus：Prometheus是一款开源的监控和告警系统，可以监控Java应用程序的运行状态，包括TPS、QPS、响应时间等信息，并支持自定义告警规则。
     Grafana：Grafana是一款开源的数据可视化工具，可以将Java应用程序的TPS等数据可视化展示，方便开发人员进行监控和分析。
     总之，在Java线上环境中，可以通过以上工具对TPS等关键性能指标进行监控和分析，及时发现和解决问题，保障系统的高可用性和稳定性。


* CompletableFuture此接口需要学习下，详见https://www.jianshu.com/p/6bac52527ca4
  CompletableFuture有两个主要静态方法runAsync()和supplyAsync()，他们返回值都是CompletableFuture，一个是运行任务是有返回值一个是没有的。
  CompletableFuture其它实例方法都是提供了以上两个静态方法所代表的运行任务的的相关其它任务的执行载体。
  各个实例方法主要从有无返回值、是否复用当前任务线程、当前任务异常是否执行下一个任务、多个任务合并、多任务谁更快返回则用谁等维度规约方法。
  CompletableFuture一些方法的比较：
      -总结：CompletableFuture用线程池及阻塞等技术，将一些任务体串联或并联起来，形成链式编程。
      -基础方法：runAsync、supplyAsync 两个方法分别代表运行无返回值和有返回值的内容（注意：这两个方法是静态方法，其它方法都是实例方法，任务通常都是从这两个方法开始）
      -Async结尾：当前任务和上个任务使用相同的线程池，此时线程可能是同一个也可能不是同一个。如果该方法还传递指定了线程池参数，则当前任务使用指定线程池。
                         注意：通常指定线程池，才能让核心的线程池不被业务代码占用，业务代码用业务线程池执行，这样核心线程池不容易成为系统瓶颈。
      -不以Async结尾：如果上一个任务执行完毕返回，则当前任务用上一个任务的线程执行，否则当前任务用和上个任务线程池的线程执行
      -when开头的方法：只有whenComplete方法带when。whenComplete接收上个任务返回值，自己不返回结果值。另外会接收上个任务的异常
      -then开头的方法：
      -带accept的方法：只接收上一个任务结果，执行当前任务后并不返回值，即只消费
      -带apply的方法：和带accept的方法相比就是既接收上一个任务结果，执行完当前任务又会返回值，即又消费又返回。
      -带run的方法：不接收上一个任务结果，也不返回当前任务执行结果；
      -带Either的方法：Either意思是“或”，也就是两个任务并行取其中最快的结果，并执行当前任务。
      -n元依赖：runAsync、supplyAsync两个静态方法为零元依赖，then或when开头通常都是一元依赖（thenCombine除外），带Either的方法为二元依赖，allOf和anyOf为多元依赖
 CompletableFuture的另一些方法：
      complete(value)  用于通知CompletableFuture的实例对应的任务线程直接完成任务。从而触发任务完成后续的事件
      isCompletedEceptionally()方法可以判断CompletableFuture是否是异常完成。
      completeExceptionally(cause); 和cancel()同样的效果
      isDone()   如果当前的CompletableFuture实例已经已经完成（正常完成、异常、取消任务都是完成）则返回true，否则false
 注意：*线程池循环引用会导致死锁：嵌套使用CompletableFuture时，如果子父层尽量不用相同线程池，容易导致线程池循环引用会导致死锁
          *线程池循环引用会导致死锁：像dubbo客户端RPC异步调用时使用的是IO线程（如cfUser=userService.getById(12)）,此时如果用同步回调（如cfUser.thenApply(()->{xxx...})）则回调代码里用的是IO线程执行
                                                  如果同步回调方法里有阻塞或等待或耗时操作，则整个IO线程会被占用。  因此尽量不用同步方法或者用不耗时的同步方法
 原理：详见bilibli收藏视频和美团技术文章 https://tech.meituan.com/2022/05/12/principles-and-practices-of-completablefuture.html  
          概念：
                依赖数量：可以分为以下几类：零依赖、一元依赖、二元依赖和多元依赖。比如任务cf3的执行依赖于cf1和cf2的的执行，则这叫二元依赖
                stack：CompletableFuture的字段（Completion类型），用于存储当前CF完成后需要触发的依赖动作，去触发依赖它的CF的计算，依赖动作可以有多个，以栈（Treiber stack）的形式存储，stack表示栈顶元素。
                           其实stack就是一个链表结构
                Completion：stack相当与当前依赖动作，而整个调用链可能有很多依赖动作，它们都存储在Completion子类中（Completion本身是观察者的基类），
                                    根据元数可分为一元依赖基类UniCompletion、二元依赖BiCompletion
                result：result用于存储当前CF的结果
          概述：CompletableFuture实现两个接口，Future表示异步计算的结果，CompletionStage用于表示异步执行过程中的一个步骤（Stage）。
                   以一元依赖为例（如：cf2=cf1.thenApply(fn2);）大概流程是这样：
                   1、cf1.thenApply(fn2);调用时，将fn2压栈存储，此时会new一个CompletableFuture对象和fn2绑定一起压栈，返回CompletableFuture对象赋给cf2
                   2、当cf1对应任务执行完后，弹出fn2进行执行，当fn2执行完毕会根据1步的绑定关系找到cf2，并执行cf2身上栈的调用链继续调用
                   
          补充：CompletableFuture和前端的Promise类似(以下伪代码)：
                   两者区别：前者还可以有多元依赖，后者只能零元或一元依赖
	       //Promise用法：
                      myFunc(){
                        return new Promise((resolve, reject) => { if(ture){ resolve(123) }else{ reject('出错了') }});
                      }
	      //CompletableFuture用法：
                      public CompletableFuture<String> myFunc(){
   	          CompletableFuture<String> resultFuture = new CompletableFuture<String>(); 
	          Thread.sleep(5000);//模拟耗时调用
                        if(result){ resultFuture.complete(t); }else{ resultFuture.completeExceptionally("出错了"); }		                 
                      }
                   
         CompletableFuture类实现了Future接口和CompletionStage接口（CompletableFuture类实现了Future接口和CompletionStage接口）
         在CompletableFuture中有一个静态代码块，在CompletableFuture类初始化之前就进行调用，代码块里的内容就是通过Unsafe类去获取CompletableFuture的result、stack和next属性的“偏移量”，
         这个偏移量主要用于Unsafe的CAS操作时进行位移量的比较。

 
* RecursiveTask需要学习下
* * juc常用的api都需要学习下

   ### -------大白老师代码研读 begin-------
*lion项目总体逻辑：
 角色：以骑手（终端），商家（推送发起端），lion服务
 每个lion服务节点包含：ConnectionServer连接服务（WebsocketServer也是连接服务），GatewayServer网关服务，PushCenter推送实现类
 执行过程：
     1、骑手和lion的ConnectionServer建立长链接（通过心跳检测），并将当前的GatewayServer服务的ip+端口存redis+骑手id（即远程路由）、connection对象存lion服务进程的concurrentHashMap（即本地路由）
     2、商家推送消息时首先根据骑手Id到redis查找远程路由，根据路由信息找到具体lion服务节点的网关，将消息发送到网关。
     3、GatewayServer网关接收到商家推送的消息，交由PushCenter推送实现类，PushCenter会根据推送消息里的骑手id找本地路由里的connection，找到则推送，找不到则返回从定向消息给商家。
     4、商家根据3步响应，成功则过，不成功报错，如果接收到是重定向消息则重新从第2步开始重新推送。
 注意：因为Netty保持百万长连接的瓶颈主要在于内存占用，所以协议、缓冲区大小、连接状态都是影响因素。 lion项目使用了私有协议，并定义了自己的编解码器。
          私有协议只能用于Netty客户端和Netty服务端之间，所以ConnectionServer、GatewayServer等都是用ServerChannelHandler，对应私有协议编解码器PacketDecoder
          但是如果客户端（骑手）用的是web，那么只能用socket，那么就要用socket协议，所以除了ConnectionServer外还有WebsocketServer作为连接服务，它用的是WebSocketChannelHandler，对应websock的编解码器。
 并发核心点：单链接占用内存、传输协议（数据报文大小）、客户端65535端口限制
           单链接占用内存：按正常对象测试可能在1~3KB左右，算1KB
           单消息占用内存：按13B的报文头+889B报文（person类测试）大概也是1KB
           按照以上数据推算，不考虑缓冲区等其它消耗1M内存就500个并发请求，1G内存就能50w个并发请求。

* 有3个sessionId
 xxxMessage的sessionId，只有set方法    如HandshakeOkMessage
 ReusableSession的sessionId，是sessioncontext.deviceId的MD5加密生成的  在握手过程中将其付给xxxMessage的sessionId
 BaseMessage的getSessionId() 获取的是packet.sessionId,是一个增量int值
 Packet的sessionId，是一个增量int值


？大白老师留的3个问题：
 1.netty服务端默认启动多少个线程，什么时候启动
   ！对于默认启动的是物理cpu个数* 2个线程（源码中有），因为现代计算机一般都是双核以上。
   大概原理：
             在并发环境下，服务考虑io密集型或cpu密集型，是因为在处理时要平衡io和cpu处理的关系（如netty里有个ioRatio参数）。netty默认io和cpu处理是1:1的关系，即服务器一半线程用于接收请求（io部分），
             另一半线程用于处理任务（即我们的业务代码执行，也就是cpu部分）。 那么就是如果1核心则开启2个线程，2核心则开启4个线程，即cpu核心数*2。
   详解csdn《为什么Netty线程池默认大小为CPU核数的2倍》

 2.Netty是如何解决jdk空轮询的bug
   ！老师讲的很含糊。具体解析可以看blog《NIO的epoll空轮询bug》
     大概就是因为在selecter选择器遍历的时候调用selecter.select()方法时应该阻塞的，但是却因为java底层问题被唤醒了。导致整个遍历进行空轮询
     netty的解决方式大概是：对空轮询进行监控时间和次数，当达到一定程度则进行selecter重建，来避免空轮询。
     
 3.netty如何保证异步串行化（无锁串行化，大概应该是一个EventLoop处理一个通道的事情保证了不进行线程切换）

？ServerChannelHandler#channelRead问什么能将msg转化为Packet，是不是客户端是直接对象序列化 Packet packet = (Packet) msg;
？项目中是如何解决分包或者粘包问题的
  ！用编解码器 
？ServerBoot(Server server, ServiceNode node) 这里的ServiceNode node具体作用和使用。大白只让node做注册中心注册使用，是不是应该让server去依赖node
？GlobalChannelTrafficShapingHandler详见简书收藏《Netty 那些事儿 ——— Netty实现“流量整形”原理分析及实战》
  ！用于netty环境下的固定全局流量整形
？com.google.common.eventbus.EventBus的作用和使用，它在整个系统中充当的角色是什么
  ！是一个第三方的库，用于单机内存型事件派发，有点委派着模式/发布订阅模式/观察者模式
？注意各个服务组件（如路由服务、网关服务）他们是分属不同的进程，因为他们各自启动一个服务进程。
  ！应该说他们都是属于同一个进程，但是监听了不同端口的服务。
？app等前端是否能够直接查询zookeeper，然后自己做负载均衡？ 
  ！不能，从lion项目整体架构看，骑手app是直接连接到netty服务端。但是在连接之前会先去请求一下负载均衡服务（这个服务并不转发请求，而是返回一个可用的netty服务）。
    而商家app在推送消息时，是先通过hppt请求pushClient服务器，pushClient去redis请求远程路由获得具体netty服务地址后再与其连接。
    此时要注意Adriod app可以使用lion提供的pushClient SDK而iosApp就要另外写SDK了。 
    注意SDK里并没有集成负载均衡功能。
？this.holderFactory = heartbeatCheck ? HeartbeatCheckTask::new : SimpleConnectionHolder::new;这里SimpleConnectionHolder没有无参构造函数为什么还能用new
  这是jdk8的语法，但是感觉有点奇怪，这样不算直接可以访问私有构造函数了？ 
？为什么很多一些对象Xxx需要用XxxHolder进行包装。一般xxxHolder有什么作用，为什么要做一层包装。一般是做一些简单的逻辑包装
  做对象的持有以便做一些小包装功能，如监控
？this.timer = new HashedWheelTimer(...时间轮概念 详见《使用netty HashedWheelTimer构建简单延迟队列》https://www.cnblogs.com/eryuan/p/7955677.html
  ？时间轮的总槽数ticksPerWheel参数似乎没有作用
？学习jdk8的新语法
  ！详见腾讯课堂《大白话学懂Java8视频教程》
？心跳逻辑，似乎没有什么特殊的逻辑和作用
  ！如果heartbeatCheck配置为true，则代码中用了一个定时器去检查连接的状态，并且输出了对应连接的状态信息
？NettyConnection的“读超时”isReadTimeout()是个什么意思
  一旦netty通道建立即对应着一个connection对象，而这时候在一定时间内没有读操作，可以进行一些操作，如关闭连接。
  这些连接上根据读写的状态而进行的一些操作放在连接管理器上处理，如ServerConnectionManager
？ChannelFuture、ChannelFutureListener的使用   
  ChannelFuture是ctx.channel().writeAndFlush()返回的对象类型，而ChannelFutureListener是 ChannelFuture#addListener的参数类型
？ChannelHandlerContext ctx; ctx.writeAndFlush和ctx.channel().writeAndFlush的区别和联系
  !详见CSDN收藏《Netty中ctx.writeAndFlush与ctx.channel().writeAndFlush的区别》
？InboundHandler顺序执行，OutboundHandler逆序执行的执行顺序，要做测试。
  大概是读事件按addLast时的顺序执行，而写事件则按addLast时的逆序执行
            
？NettyConnectionServer里 start(Listener listener)的listener研究下
？注意epoll模式的server
？CompletableFuture此接口需要学习下，详见https://www.jianshu.com/p/6bac52527ca4

？LinkedList的poll pop remove peek等方法的比较
  linkeList.remove("a");//删除时如无该元素则返回null
  linkeList.pop();//删除顶部元素，如无该元素则抛异常 和push配合使用，实现堆栈数据结构
  linkeList.poll();//删除顶部元素，如无该元素返回null，和offer配合使用，实现队列

？tomcat是采用io多路复用的Nio吗？ 如果不是则一个客户端请求就要有对应的一个服务端线程。 
  详见https://www.oschina.net/question/1240923_2202821
      https://blog.csdn.net/fd2025/article/details/80007435
      https://www.jianshu.com/p/76ff17bc6dea

？为什么DB不能用io多路复用技术，而是使用连接池技术。详见https://www.jianshu.com/p/61079795896b

？明天过下bind()的源码过程、pipeline的结构、启动netty server demo  用shell  telnet连下、复习下传智网络编程tcp3次握手、sync()源码过程
  学习完netty后回头过去看dubbo服务发布过程的源码

？秘钥交换个人感觉只是保证了数据传输的安全性，那骑手客户端在连接推送平台之前应该是要通过业务系统注册登录并获取公钥（也可认为是token）
  此时拿到这个公钥不就意味着可以直连服务端并获取响应的数据了。

？？商家提交消息到 pushCenter，这个消息body里带的userId应该是目标骑手用户的id  ！是的
？？商家提交消息前先要连接到某台 网关服务器节点（也是连接服务器节点，也是连接管理节点），此时连接暂存map要么是互通的，要么就是直接转发到另外服务器节点。其实是响应给商家客户端端重定向
？？整个推送消息到下发消息的具体过程要理清楚，可以通过tester相关demo进行测试

？编码过程中为什么要把package.body=null;
？push-client属于服务端的sdk，主要可以用来做消息推送 ，甚至可以在Android里用这个sdk来发送消息。 但是ios就应该要做另外的sdk了
？netty的连接如果没有手动断开就应该一直保持着，属于长链接
？connection的心跳检测是判断读超时超过指定的次数就关闭连接。这样的话可以减少无用的连接，当骑手连接被关闭后，有需要再通过握手，秘钥交换等流程建立新的连接。当然连接的关闭和重建是伴随着本地路由和远程路由的更新的。
？看下ping -> pong的具体心跳逻辑

？当一台连接服务器down掉了，那它上面的连接怎么办。 有人说是补推，是不是每推送成功一条消息就写入一条日志。？具体解决方案。 找下gper社区
  是不是可以每发送成功一条消息都需要骑手客户端响应，以明确的得知消息有被成功接收。
？长链接是如何保持的，大白说用心跳，但是代码里的心跳检测只是检测是否读超时，超时则关闭连接，并没看到发送心跳包的代码。
？future.channel().eventLoop().inEventLoop()代码深究下	

*  nioEventLoopGroup.setIoRatio(100);//代表全部线程都用于操作Io的读写，而没有线程用于操作业务的执行。如果ioRatio=30则io和任务比是30：70
  !个人理解，在接收连接进来的消息后，由于业务需要，也需要另外的线程来执行任务，此时就会将这些任务放到netty的EventLoop里去，应该是共用线程的目的。
   如代码：task.getExecutor().execute(task);里其实都是获取通道对象里面的eventloop对象
* ConnectionServer#init里所有注册的命令类型都是由客户端发过来的，有点像springMVC的Dispatcher
* 6上30分钟
* lion.conf完整的配置在哪里可以查看，其实可以看CC接口类和dabai-vip\conf\reference.conf

* 几个相对重要的类：
 * Packet：原始的数据包对象，和前端的Packet的json对象。并没有包含connection信息（即channel）
 * HandshakeHandler：继承BaseMessageHandler<T>，属于一种消息处理类，
 * HandshakeMessage：是对Packet的分类性包装，将connection包装进去。并将两者隐藏（transient），将两者必要的信息暴露在字段上
 * Connection：是连接对象，主要存储了SessionContext、Channel... 规约了连接常用的操作方法，如发送消息、连接状态、是否超时...
 * SessionContext：是Connection里的一个字段，存储了连接上下文，如客户端osName、osVersion、clientVersion、deviceId...

* 几个重要的过程：
 * 连接建立过程：ping-pong（可选），握手建立安全通道，绑定用户
 * 推送消息过程：业务系统通过PushClient->gatewayClient连接到 网关服务端GatewayServer，GatewayServer再去操作本机的connection进行消息发送。
                注意PushClient就是提供给业务系统进行推送消息的SDK。GatewayServer是和ConnectionServer在同一台服务器上（同一个大服务里）。                   
 * 踢人过程：实际上只是发送了踢人的消息给骑手客户端，客户端自己关闭连接。显然这样的逻辑很别扭。
 * 路由存储逻辑：远程路由其实存储的是骑手用户所在连接服务器的网关GatewayServer的ip+port信息


* ByteBuf
 * ByteBuf用于通道读写数据时缓冲，和线程一样属于稀缺资源，因为它要占用堆内或堆外内存，因此netty采用ByteBuf池：ByteBufAllocator。
    channel.alloc();和ctx.alloc();均可以获得byteBufAllocator实例
 * heapBuf.hasArray()代码，只有在堆内内存才有数组，堆内内存归jvm管理，堆外内存归系统管理。 
 * CompositeByteBuf相当于只是视图，它并没有拷贝普通缓冲区的东西，而只是"引用"，这应该就是"零拷贝"
 * ByteBuf中以get开头的方法(getXxx)是不会改变读索引，而read开头的方法(readXxx)是会更新读索引（即不可重复读）
 ？堆外内存的零拷贝问题，详见blogs《关于零拷贝的一些理解》

* 监控模块再性能优化专题会再讲，所以暂时大概浏览了代码，没有深究

* 项目中的Profiler类是一个跟踪线程信息的工具类，本质上是使用ThreadLocal
  ThreadLocal类型共享变量存储数据，实际上是存储到当前线程相关的变量中去。详见blogs《Java中的ThreadLocal详解》


* netty源码中判断一个数是不是2的幂次（即2的n次方），采用了一个算法判断：一个数如果是2的n次方,如8，则8&(-8)==8
 这个-8在计算机中表示是8的补码，即8取反加一


* Netty中EventLoop其实是一个线程或者线程池，当我们在业务的channelHandler里处理业务时如果需要使用线程执行任务，一般就用当前的线程或线程池执行任务，如
 channel.eventLoop();eventLoop.execute(new Runnable() {...}）
 除了通过 execute 添加普通的 Runnable 任务外, 我们还可以通过调用 eventLoop.scheduleXXX 之类的方法来添加一个定时任务
 注：setIoRatio()就是用来设置io任务和这里的业务任务在这些线程池里执行的占比

*关于打包
 大白老师的项目用到一个可以将依赖打进jar包的maven插件maven-assembly-plugin，使用命令mvn assembly:assembly
 其中profiles节点是配置不同环境的打包方式，如测试环境test或这是环境release。
 这里是用名为zip的环境，自己使用命令mvn package -P zip -Dmaven.test.skip=true 进行打包 
 当然要到maven的安装目录的setting.xml更改本地仓库路径
 用命令打包：install好依赖的模块后，进到lion-boot目录执行mvn clean package -P zip -Dmaven.test.skip=true

*关于运行
 java -jar -Dlion.conf=Z:\gupaotemp\dabai-vip\lion-boot\src\main\resources\lion.conf bootstrap.jar
 java -Xms1300m -Xmx1300m -XX:PermSize=1000m -XX:MaxPermSize=1000m -XX:NewSize=200m -XX:MaxNewSize=300m -jar bootstrap.jar

*调节了linux文件句柄数、redis连接池、connection读写超时次数、线程池参数
？在lion-tools里refrence.conf 需要做下配置

* * * 总结：
   设计模式：* 模板模式，如各种Message的抽象解析
           * 类的链式编程，在setXXX方法中返回this
           * 领域驱动，缓存、服务发现、事件总线、路由管理等模块的定义，抽象，关联
           * SPI机制，每个扩展点都定义了一个工厂，而工厂又是一个扩展点。
           * 观察者模式，或事件驱动活发布订阅模式，在服务发现，用户上下线感知等方面用到了EventBus和其它发布订阅及监听
     * 装饰器模式，如Connection的心跳包装，PushRequest中PushTask的超时队列包装、对redis缓存的本地缓存RedisCacheManagerFactory	
   设计思路：* 本地路由和远程路由设计
     * 商家客户端->服务网关->连接服务->骑手客户端的设计
     * 客户端流控设计，抽象了流控的本质逻辑
           * 通过公共线程池规划达到监控整个系统性能指标的设计，？？此部分还需要后续学习
           * 客户端和服务端都用了一个上下文对象来承载它所有的启动的服务。即LionServer和lionClient	
     * CC配置将配置文件和配置类关联起来，实现真正的面向对象
  		 	   * 日志用logback将各种业务场景下的日志区分开，如Logs.PUSH、Logs.CONN等	
     * 每个业务对象都有固定的toString，配合Jsons进行序列化，加上日志系统可以很好的记录运行过程中的数据      
   三方框架：* Guva框架的应用，这个后需要学习
     * CuratorFramework/Zookepper
     * Jedis/Redis
           * Netty
     * typesafe配置工具	
  		 	   * Java8新语法

  ### ------大白老师代码研读 end------- 


？netty中一个线程有几个eventloop

？？HashedWheelTimer(ThreadFactory threadFactory, long tickDuration, TimeUnit unit, int ticksPerWheel) 中的ticksPerWheel参数有什么用？  在执行效果上，定义24个槽和  100个槽  有区别么？  

？？各类常见分布式解决方案及其问题可看公开课，找启蒙。在学习完基础课后，先对基础再复习一遍，然后找启蒙问题做demo（可简单看公开课）

？com.gupaoedu.vip.distributed.io.niodemo.channeldemo.ServerSocketChannelDemo里还有些代码疑惑，后面有空了解下
  其中为什么socketChannel.write(writeBuffer);并不一定会将writeBuffer里的内容一次性写入到socketChannel中

？nginx反向代理http服务和代理netty服务有什么区别，可以尝试做下demo。注意lion项目并未用nginx做骑手到服务的反向代理，而是通过一个负载均衡服务让骑手先调用下获取一个服务节点进行直连
  https://www.oschina.net/question/2003397_2189112?sort=time
  https://segmentfault.com/q/1010000017323588/
  https://www.cnblogs.com/zihunqingxin/p/6879317.html

？明天自己百度下Nio的服务端demo代码的一些疑惑
  自己学习下大白netty的demo代码

？下午传智集合全部练习一遍
  看一遍这个链接并做好intellij笔记  http://www.cnblogs.com/KnightKitt/p/8904001.html



## --------------------分布式 end--------------------------------

## --------------------并发编程 begin------------------------------

* 进程和线程的概念，看传智基础课再看咕泡课程，如果再看不懂购买腾讯课堂课程https://ke.qq.com/course/343174
 可参考博客园收藏《Java多线程系列——从菜鸟到入门》

* 进程和线程的概念、wait\notify\notifyAll\join方法的使用和原理看传智。
 注意这些方法的调用对象。wait\notify\notifyAll是lockObj，join是threadObj

*InterruptedException异常通常是在线程处于阻塞状态下调用了interrupt()方法才会抛出，而jvm在抛出InterruptedException之前会对interrupt标志位复位（即置为false）
 详见咕泡并发课程文档

*wait() 和 sleep()有什么区别？ 详见blogs《面试 LockSupport.park()会释放锁资源吗？》
 wait():释放资源，释放锁。是Object的方法
 sleep():释放资源，不释放锁。是Thread的方法

* notify 仅仅通知一个线程，并且我们不知道哪个线程会收到通知，然而 notifyAll 会通知所有等待中的线程。
 notify、notifyAll要在synchronized里进行使用，这样才能找到锁
 注意：lockObj.wait(timeout)重载是指当超过了指定时间，则当前线程会继续加入到lockObj锁的竞争行列，如果获取到就继续执行自己的代码
 注意：与park/unpark的区别
 注意：FutureTask的原理就是利用阻塞和唤醒实现 ，但它是通过park/unpark实现。 通过FutureTask在Controller启动多个线程来调用多个服务实现并行执行，提高效率。

* threadObj.join()原理看csdn《Java中的join方法原理详解》,threadObj.join()其实是主线程将threadObj的作为锁对象synchronize并wait，知道子线程任务结束

* Condition对象的await()\signal()\signalAll()相当于锁对象的wait()\notify()\notifyAll()。
 Condition对象是和Lock实例lock()方法绑定使用，而wait()等方法是和synchronized及锁对象绑定的。 本质上都是让这些方法找到锁。

*await和wait的区别。 详见csdn《Java并发：await/wait的区别》
 lock体系会比synchronized更灵活，例如：用多个线程用wait()阻塞等待，用notify()不能唤醒指定线程。 而如果用特定的conditionA.await()阻塞等待，则通过conditionA.signal()可以唤醒指定线程A

* JUC线程池的Future<String> future = ex.submit(...)中的Future原理详见csdn《JUC FutureTask 分析》
   与Jdk1.6版本不同，Jdk1.7的FutureTask不再基于AQS来构建,本质上还是AQS三板斧：CAS、LockSuport、自旋

* 总的说进程管理了应用所需的一些资源，如内存空间、cpu资源等，而线程则是在这些资源范围内去抢占资源。

* * 假设A为主线程任务，A中有一个耗时操作b。此时可以启用了B线程以提高性能。其中可用join或Callable去保证一些业务的有序性。
 如果A任务最后用到了B的执行结果，则采用Callable
 如果A任务里并没用到B的执行结果，但又必须等B执行完才能结束A线程，则采用join

* 阻塞队列LinkedBlockingQueue的使用。 有一个使用调用链套路详见mic-vip\2018\20180810-并发编程第一节课\Demo.java
 线程池ExecutorService的使用

* 线程的6种状态，注意调用哪些api会影响它们的状态改变。如:Thread.sleep(100)会使当前线程进入超时等待状态。
  *阻塞与中断的区别，详见csdn《线程的阻塞和中断》
  *如果被中断线程处于阻塞状态（例如线程调用了Thread.sleep、thread.join、thread.wait、1.5中的condition.await、可中断的Channel上的 I/O 操作方法后可进入阻塞状态），则在线程在检查中断标示时如果发现中断标示为true，则会在这些阻塞方法调用处抛出InterruptedException异常。

* 线程的启动和终止，常问的面试题
 方式1：threadObj.stop()是暴力终止，已过时，有点像linux里的kill命令。有些资源可能还没释放或者还有一些地方在用此线程。
 方式2：threadObj.interrupt()是告诉当前线程可以停止了，至于什么时候结束要看自己。可用threadObj.isInterrupt()判断是否停止。
 方式3：一般线程里的任务都是用循环，如while，此时使用标志位方式是属于最优雅的方式，让线程自然停止。

* threadObj.interrupt()内部原理是设置一个中断标志（假设为flage）以供线程内部判断此标志，如果在当前线程执行Thread.interrupted()则会将flage重置为false

* java中用native关键字标志的方法其实就是用java调用c写的一些api函数。C#也有类似的语法

* 进程和线程的区别 详见博客园收藏《说说进程和线程的区别》 https://www.cnblogs.com/zhehan54/p/6130030.html
 * 进程是资源分配的最小单位，线程是程序执行的最小单位。如IO、CPU、地址空间等资源。
 * 线程是共享进程中的数据的，使用相同的地址空间，因此CPU切换一个线程的花费远比进程要小很多，同时创建一个线程的开销也比进程要小很多。
 * 线程之间的通信更方便，同一进程下的线程共享全局变量、静态变量等数据，而进程之间的通信需要以通信的方式（IPC)进行。不过如何处理好同步与互斥是编写多线程程序的难点。
 * 但是多进程程序更健壮，多线程程序只要有一个线程死掉，整个进程也死掉了，而一个进程死掉并不会对另外一个进程造成影响，因为进程有自己独立的地址空间。

* 线程的可见性、原子性、有序性（详见博客园收藏《Java中Volatile关键字详解》https://www.cnblogs.com/zhengbin/p/5654805.html）
 可见性：一个公共变量在多个线程中是可见的，表现是当这个变量在一个线程中的修改对于其它线程是能"同时看到"
 原子性：一个公共的变量的修改，如count++; 是作为一个整体不可分割。（一般count=0是原子的而count+即count=count+1;是非原子的），多个线程同时计算不会造成最后结果"误差"
 有序性：对于公共变量的修改，如count1++;count2++;这段代码在多线程环境下，指令重排，可能造成先执行count2++;再执行count1++;
         有序性的经典案例就是abxy案例，详见咕泡文档或自己的练习。乱序问题也是看咕泡文档。
 * 可见性关心的是自己的变化能否立马被其它线程感知，原子性关心的是多个代码指令是否作为一个整体执行，有序性关心的是多个代码指令是否按顺序执行。

* 其实乱序问题


* 总的来说就是cpu的指令重排\高速缓存问题造成了多线程的可见性、原子性、有序性问题

* 单核CPU时代，是不会出现缓存一致性问题，多核CPU情况下就会出现真正的指令并行执行，此时共享数据的处理在并行下就会有缓存一致性、有序性问题

* JMM内存模型提供的相关api用以解决可见性、原子性、有序性问题：
 * volatile阻止了指令重排和高速缓存，保证可见性、有序性但不保证原子性，能保证count=0;安全，但不保证count++;安全。count++;是可分割的，是非原子操作。
         内存屏障，只有一个cup核心时并不需要内存屏障。指令重排时不会将指令重排到内存屏障之前的位置。
	 volatile修饰的变量与普通变量几乎相同，但性能较慢，因为他要在本地代码中差多许多内存屏障来保证执行重排造成的乱序。
 * synchronized只允许同时只有一个线程可操作，可以保证原子性和可见性、有序性，其实就是让count++;或者一些代码块在多线程下是串行执行的。 使用了同步锁机制
 * final可以保证可见性
 * juc

* JUC包是用于解决多线程编程方面的问题的，其下的体系详见博客园收藏《Java并发：多线程和java.util.concurrent并发包总结》

***JUC AQS核心三板斧：自旋、CAS、LockSuport。详见腾讯课堂图灵学院杨过老师并发编程课
   自旋：实际上算是一种重试，未获取到锁的线程会先通过LoackSuport的park()阻塞，当被unpark()后又继续重试获取锁。
   cas：怎么确认谁获取锁成功？其实就是通过CAS来对比和设置一些变量或对象（乐观锁），但这个设置对多线程是原子性的是可见的，直接用底层操作(unsafe类)内存方式保证安全。
   LockSuport：实际上就是真正的进行线程阻塞操作，part()可以使得线程让渡cpu资源，让代码执行停在那，有点像断点。
   以reentranlock为例，AQS的整体大概流程为：
    1、多个线程调用reentranlock.lock()竞争锁，原理是定义一个全局的state变量，通过CAS原子操作state成功代表获取锁成功。
    2、reentranlock用一个变量（比如叫：lockHolder）记录先获取锁的线程，用一个队列（比如叫：waiters）按顺序记录未获取线程。
    3、获取锁的线程，在业务代码执行完后会执行reentranlock.unlock()。实际上是设置lockHolder=null且state复位，再用Locksuport.unpark()唤醒waiters队首的线程。
    4、未获取锁的线程，进入自旋，实际就是循环while(true){先进行尝试获取锁，未果则用Locksuport.park()阻塞//等待持锁线程释放锁唤醒}
   参考资料《并发编程之Atomic&Unsafe魔法类详解-图灵杨过》
   ？？找下图灵学院Java架构师学习路线图
   **AQS（AbstractQueuedSynchronizer），即队列同步器，它是构建锁或者其他同步组件的基础框架，如ReentrantLock、ReentrantReadWriteLock、Semaphore，CountDownLatch等。

*ReentrantReadWriteLock：一个ReentrantReadWriteLock实例可以得到一个读锁和一个写锁，线程进入读锁或写锁遵循以下原则。因为读线程不会造成线程安全问题，所以共享读锁，从而提高读写性能
   线程进入读锁的前提条件：
         没有其他线程的写锁
         没有写请求，或者有写请求但调用线程和持有锁的线程是同一个线程
   进入写锁的前提条件：
         没有其他线程的读锁
         没有其他线程的写锁

* CPU和内存之间有一个叫高速缓存的东西。这个需要了解
 高速缓存分为L1、L2、L3。它缓存了内存的一些东西，如count=1;

 每一个CPU核心都有一组高速缓存，每组高速缓存之间的内容是相互不可见。如果把count=1;加载到每组高速缓存，当有个CPU改了count值，
 此时只有自己的高速缓存值改变了，其它CPU的高速缓存值没有改变。
 高速缓存的一致性导致了线程的可见性。

* sychronized锁的优化补充学习详见博客园收藏《Java并发编程：Synchronized底层优化（偏向锁、轻量级锁）》

* 线程锁之Lock，详见博客园收藏《Java并发编程：Lock》，此文章很好，还涉及读写锁等知识点
  * Lock只是一个接口，java中唯一的实现是ReentrantLock。
   注意Lock只有少量方法供使用，ReentrantLock提供了isFair、isLocked、isHeldByCurrentThread、hasQueuedThreads等实用方法
  * Lock接口有3个获取锁的方法，当多个线程同时（一定要保证同时）获取锁时，3者表现各不一样：
    * lock.lock() 未获取到锁的线程会选择等待
    * lock.tryLock() 未获取到锁的线程可以选择放弃或做其它操作
    * lock.lockInterruptibly() 未获取到锁的线程会等待，但该线程可用thread1.interrupt()终止等待，
                              必须在线程调用lockInterruptibly()的方法上声明异常而不是try-catch。
                              而终止等待后的操作可以在捕获上述异常的地方进行处理。
  * ReadWriteLock接口，juc中唯一实现类是ReentrantReadWriteLock
   * 注意reentrantReadWriteLock实例的readLock()和writeLock()方法获取的是单例的lock
   * 写锁是排他锁，而读锁是共享锁
  * Condition的使用 详见博客园收藏《Java多线程系列--“JUC锁”06之 Condition条件》和咕泡练习
    lock()到unlock()之间的代码用condition.await()会造成不安全。具体伪代码实例详见gupaodemo的ConditionDemo3
    condition原理：condition.await()会将当前线程t1通过park()阻塞并加入conditionWaiters队列，
                   在condition.signal()时会将t1从conditionWaiters队列移除并添加到lock的AQS的锁竞争队列中，并unpark()唤醒t1去竞争lock锁
                   所以await()\signal()和synchronized锁的wait()、notify()是一样的。
                   signal()执行后不一定是t1第一时间获取到锁，而是lock里的AQS的队列决定的，如果是公平锁lock则是等待时间最长的线程获得锁。

* CountDownLatch用于制造指定个数的线程并发
* Semaphore用于限流，限制指定个数的线程进行访问。

* AtomicXX类的使用详见简书收藏《Java中atomic包中的原子操作类总结》，注意其中描述的ABA问题

* CAS概念（Compare-and-Swap 比较和交换）与平台相关，它有三个操作数，内存位置值（V），旧的预期值（A），新值（B）。其实就是乐观锁的概念

* for(;;){}和while(true){}的区别
 两者在一般的编译器编译后会进行优化，而优化后的字节码是相同的
 但是如果有一些编译器没有优化，则会会有一些差异for的字节码会更少

* TimeUnit是juc提供的一个工具枚举类

* AQS（AbstractQueuedSynchronizer）在谈到ReentrantLock涉及到AQS概念

？学习阻塞队列LinkedBlockingQueue的使用

  复习zookeeper实现锁的demo
  协程概念的学习

* ScheduledThreadPoolExecutor、Timer+TimerTask、HashedWheelTimer的优缺点
  ScheduledThreadPoolExecutor比Timer+TimerTask误差小，支持多线程，任务执行时间超过延迟时间不会有问题，任务有异常时线程不中断
  HashedWheelTimer可以定义时间的刻度和周期等
  注意：Executors.newSingleThreadScheduledExecutor()内部也是包装了ScheduledThreadPoolExecutor
 详见csdn《定时任务ScheduledThreadPoolExecutor的使用详解》 《延迟任务的实现总结》


*ConcurrentHashMap 详见csdn收藏《ConcurrentHashMap的作用与用法》

？？几种锁：偏向锁，重入锁，重量锁。

## --------------------并发编程 end--------------------------------

## --------------------性能优化-JVM begin------------------------------

*jvm相关工具使用 具体使用可以通过https://docs.oracle.com进行search
 jps 查看java相关的进程pid  和linux的ps命令差不多。 加参数-l可显示类全名
 jinfo 打印查看整个jvm相关信息，比如运行时信息，如编译类的数量。也可以在jvm运行时动态更改相关运行参数值
    jinfo -flags 进程号
 jmap 查看内存信息，ru出现OM了就可以用jmap的dump功能、打印各个类的实例数和内存、打印堆的内存概要
    jmap -heap 10032 打印10032进程的堆内存信息
    jmap -histo:live 10032 打印10032进程jvm里的类的class实例的数目和占用空间
    jmap -dump:format=b,file=/mydump.dump  注意dump下来的文件直接打开是乱码的。可以MAT打开分析（如果导入不了可以改名为mydump.bin），详见csdn《JVM MAT使用分析详解》
 jstat查看类加载、内存、垃圾收集、jit编译信息，总的来说就是监控jvm的统计信息，详见官方文档或bologs《jstat命令查看jvm的GC情况 （以Linux为例）》
    如：jstat -gcutil 5228 1000 表查看信息如下（5228和1000分别代表pid和输出时间间隔ms），S0到M分别表堆中各区域被占用的大小的百分比，YGC和YGCT代表YongGC次数和时间，FGC和FGCT表fullGC的次数和时间，GCT是总的GC时间，CSS表？
       S0     S1     E      O      M     CCS    YGC     YGCT    FGC    FGCT     GCT
       98.44   0.00  10.89   5.06  65.67  68.65      2    0.064     0    0.000    0.064

   各个参数的意义：
     - S0C: Young Generation第一个survivor space的内存大小 (kB).
     - S1C: Young Generation第二个survivor space的内存大小 (kB).
     - S0U: Young Generation第一个Survivor space当前已使用的内存大小 (kB).
     - S1U: Young Generation第二个Survivor space当前已经使用的内存大小 (kB).
     - EC: Young Generation中eden space的内存大小 (kB).
     - EU: Young Generation中Eden space当前已使用的内存大小 (kB).
     - OC: Old Generation的内存大小 (kB).
     - OU: Old Generation当前已使用的内存大小 (kB).
     - PC: Permanent Generation的内存大小 (kB)
     - PU: Permanent Generation当前已使用的内存大小 (kB).
     - YGC: 从启动到采样时Young Generation GC的次数
     - YGCT: 从启动到采样时Young Generation GC所用的时间 (s).
     - FGC: 从启动到采样时Old Generation GC的次数.
     - FGCT: 从启动到采样时Old Generation GC所用的时间 (s).
     - GCT: 从启动到采样时GC所用的总时间 (s).
 Eclipse Memory Analyzer 简称MAT（Memory Analyzer Tool），配置 -XX:+HeapDumpOnOutOfMemoryError就可将内存信息dump到指定路径，路径在gc日志里会打印出来。
    使用详见csdn《Eclipse Memory Analyzer —— MAT查找内存泄漏工具》 18年大白老师“jvm课04上/下”有介绍 
 jstack


*常见jvm相关参数：配置经验详见《JVM参数配置大全》、《JVM启动参数大全》


 -XX:CICompilerCount=2 在jvm总共编译的类数量
 -XX:InitialHeapSize=100663296  整个堆初始化大小，和-Xms100663296 一样  也可加单位如 -Xms3550m
 -XX:MaxHeapSize=1583349760  整个堆的最大值，和-Xmx1583349760一样
 -XX:MaxNewSize=527433728 新生代最大大小
 -XX:NewSize=33554432 新生代初始化大小
 -XX:OldSize=67108864 老生代初始化大小
 -XX:MinHeapDeltaBytes=524288 
 -XX:+UseCompressedClassPointers 
 -XX:+UseCompressedOops 
 -XX:+UseFastUnorderedTimeStamps 
 -XX:-UseLargePagesIndividualAllocation 
 -XX:+UseParallelGC      //jdk1.8默认的收集器是新生代收集器：+UseParallelGC = 新生代ParallelScavenge + 老年代ParallelOld
 -verbose:gc 输出每次GC的相关情况。

*GC日志的查看
 *在com.gupao.edu.jvm.JvmTest1内存溢出单元测试中，发生了多次GC (Allocation Failure)但是内存还是不足，于是又发生了多次的Full GC，还是发现内存不足，于是就报错java.lang.OutOfMemoryError，GC日志详情打印需要添加参数-XX:+HeapDumpOnOutOfMemoryError -XX:+PrintGCDetails 
 *PSYoungGen 代表新生代使用PS收集器，即ParallelScavenge
  ParOldGen 代表老年代使用ParallelOld收集器

 

*[Times: user=0.01 sys=0.00, real=0.09 secs] 这几个耗时是什么意思
 *当前进程的实际CPU耗时= user time + sys time
 *单线程情况下 real/user/sys关系
  real time = 当前进程的实际CPU耗时 + 其它因素耗时
  当前进程的实际CPU耗时 = user time + sys time
  real time > 当前进程的实际CPU耗时
 *多线程情况下 real/user/sys关系
  此时，不同线程可以并行执行，导致user+sys的时间可能大于real的时间
  当前进程的实际CPU耗时 = user time + sys time
  real time < 当前进程的实际CPU耗时

*大对象直接到老年代，而空间担保会使对象先到eden区再到老年代，这是两者的区别。


*逃逸分析和栈上分配 
 详见：blogs《JVM的逃逸分析》 、demo详见csdn《JVM的栈上分配》
 注意：未逃逸对象是可能栈上分配，并不是一定的
 理解：一般在方法内的局部变量指向的对象和return出去的对象都是在堆中分配，因为return出去的对象可能被当前方法外的其他方法所引用（可以称作该对象“逃逸”），所以是否回收要看jvm通过GCRoot可达性分析后才能知道，因此return出的对象是应该会在堆中分配。  为了减少对象在堆中分配，通过逃逸分析，如果分析后判定某个对象仅在当前方法中，没有“逃逸”出这个方法的作用域范围，jvm可能会将对象分配在栈上，随着当前线程的结束而销毁，这样就减少了jvm堆的占用，也减少了GC回收处理。

*对象的hash值是存储在对象的Mark Word中的，所以Object#hashCode是native方法，相当于是访问底层

*优化目标标准：减少fullGC次数，跑满服务器瓶颈指标（如CPU或带宽，一般内存不是瓶颈）
 大白jvm生产消费实例场景：500线程生产者，5个消费者进行生产消费。
 调优要点：由于产量过大，太多的产物堆积在LinkedBlockQueue里，造成老年代内存占用过大，fullGC次数频繁。
           此时可选方案有：*增大老年代内存或整个堆的内存，内存一般也不是瓶颈，所以此方式最low
                           *增加消费线程比例，但是可能增加太多会造成生产线程和消费线程相互切换造成多余开销，但这个因素影响应该比较小
                           *可通过阻塞或睡眠等方式让生产线程放缓速度，给LinkedBlockQueue设置capacity原理也是让生产线程阻塞。
           在597采集数据的案例中,通过张阳测试，带宽是主要瓶颈。可以测试当单个产物的生产和消费需要占用多少带宽，一次来指定生产和消费的线程数和LinkedBlockQueue的capacity


*XShell可以用安装一个软件【lrzsz】，然后用【rz】命令下载服务器文件

*log4j日志是一个规范，他自己也有一套实现，另外logback、log-commons等也是它的实现
 logback中包含相关概念
   appender是输出到哪里，可以配置输出格式，方式，目的地。同时可以通过配置<filter>来实现只输出响应级别的日志比如info	
   logger是具体的日志记录器，可以包含多个appender。  
         注意<root>节点也是一个logger，而LoggerFactory.getLogger(this.getClass())用的就是默认的root这个记录器
   



？Hotspot虚拟机中对象投 Mark Word中的无锁态、轻量锁、重量锁、偏向锁的原理或关系

？minorGC、majorGC、fullGC的过程
 minorGC时会进行复制回收算法，没被回收的对象且不超过年龄限制的（如15）则放到s1中，一旦s1中的对象熬过了15次minorGC则会晋升至老年代。否则还在s1区待着。详见《为什么JVM中的新生代要有两个Survivor区？》

？明天实践Dump内存溢出的dump文件，并用MAT进行分析





* 2017课程内容，课前准备：http://git.gupaoedu.com/java-vip/nice/issues/6
 * 性能监控时常用linux命令（具体学习看17年教案）：
  * 看内存：free -m ，显示内存和虚拟内存使用情况，-m代表兆，还可以-g，-b等。 执行命令后的结果中，mem是物理内存，swap是虚拟内存。教程详见blog 《linux free 命令》
      	  free -m -h -s 3 ，常用的命令组合， -h会显示单位（人性化），【-s 3】是间隔3s打印一次。
          注意buff/cache维度的含义，它是linux内存优化手段，对于程序buff/cache的内存是可用的，而对于操作系统（即mem维度）是已用的。
  * 看cpu：top命令是Linux下常用的性能分析工具，能够实时显示系统中各个进程的资源占用状况，类似于Windows的任务管理器。
          top命令关注点在于%CPU、%MEM，此命令是性能优化常用的命令
         详见blog《Linux top命令的用法详细详解》
  * 看io： iostat 1，常用参数-d -x,可用合写为-dx，？可写demo，测试循环读写文件，然后看io状态
	 	  iostat 1 -dx 实时输出io情况
         注意在此命令执行结果中的%util维度，是查看io占用cpu时间的占比，经验值一般不超过5%
         如果没有此命令则运行下 “yum install sysstat”，详见blogs 《iostat命令详解》
  * 看network:nicstat -l
         如果没有此命令则安装详见https://my.oschina.net/u/2328100/blog/3001211
  * 看文件大小：df，加上-h 参数可人性化的显示数据
               df -h 指定目录名/  此命令可以显示当前目录下制定目录的大小
  * 看性能问题出现后的堆信息：jstack 进程号 > aa.txt ，将对应进程的堆信息输出到文件，以查看进程为何cpu飙高或内存满等性能问题，属于jvm的工具
  * 看cpu的负载：vmstat命令可以每秒输出一次信息

 * 机器的性能监控，行业内常用开源监控应用有zabbix、nagios，zipkin，cat
 * 常用性能优化手段：
   * 点播改为广播，减少为每个业务的计算量，提高cache命中率，改get为push
   * 同步改为异步，减少即时处理带来的阻塞，通过队列形式防止系统崩溃。如lion项目里延迟流控的做法
   * 遵守规范，尽量使用符合框架规范的处理机制
   * 实时计算改为预计算，减少动态请求，可预计算的先计算，削减峰值
 * 性能优化案例
   * “Tomcat最大连接数默认200时，300个请求还好，但是调大Tomcat最大连接数为1000，在200个请求下系统就卡死，为什么？”
     答：虽然配置参数调高，但是业务系统架构各不相同，要根据业务分析
   * “当cpu飙高，我们如何通过top命令和其它命令来查找定位问题所在线程及其代码行？”
     答：1.用top命令查看cpu飙高的进程A，然后用jstack将进程的堆信息打印文件中（如a.txt），这个简称“线程dump”;
	 2.在top命令下按H，进入到线程显示模式，然后A进程对应的线程中cpu飙高的线程号（如：69235）
	 3.用命令printf "%x \n" 69235 将线程号转化为16进制数
         4.在堆信息文件a.txt中查找16进制的线程号，查看该线程的堆信息即可定位到出问题的代码。
     注意：在dump下来的堆信息文件中a.txt中，进程号或线程号都是以16进制写入，而top中显示的进程和线程号都是10进制的。
   * “秒杀案例中如何控制并发？”
     答：有种方式是：先js写相关规则过滤掉一大部分请求，在后端Nginx等再设置过滤掉一部分请求。
           在网关添加过滤器合并多个请求为一个请求（gateway里用spring-cloud-starter-aggregator过滤器，详见chatGPT问答）
           将秒杀商品库存数提前写入到redis，一个请求进入则用redis的decr减一，如果小于0则返回秒杀失败。 
           其实如果是单机的情况下直接用AtomicInteger存库存即可，但是秒杀可能是服务集群，所以只能用redis或zookeeper之类的中间件。
           所以回答秒杀方案时，要切合实际，是集群服务还是单机服务。
           前后端：随机过滤，限流，整形，异步，防重复提交
   * “12306以前自己玩死自己：同步购票和即时退票”
     答：分时，分段售票，异步购票退票
   * “系统平均响应时间变慢了” 
     答：一般都
   * “com.gupao.jvm.HelloWorldDemo#error中当请求此方法报内存溢出错误后，再做一个另外的请求比如/hello,为什么还能正常响应”
     答：个人认为因为在访问hello时，并没有再创建新的对象，所以可以响应。如果hello控制器里又有创建新的对象应该会响应错误
   * “使用jvisualvm检测到程序线程发生死锁”
     答：打开jvisualvm并连接本地货远程vm可以自动检测程序运行过程中的死锁。或者可以dump线程文件。 详见大白 jvm-lock的demo
         在线程dump文件中查找“DeadLock”或“block”文本，即可找到死锁或阻塞相关信息。
   * “如何使用dump文件查找相关问题”
     答：详见blog《Jvm dump介绍与使用（内存与线程）》
   * “常见的jvm故障分析” 
     答：* * * 这个文章很好，详见 https://www.javatang.com/archives/2017/10/25/36441958.html  此文章的相关系列文章都可以阅读
   * “如何通过MAT来发现内存泄漏的所在代码” 
     答：1.先通过查看GC日志，看GC回收前后，内存是不是没有变化，或者还增长了，如果是则说明有内存泄漏问题，或可能要内存泄漏了。 
         2.通过jmap等工具将内存dump文件下载后导入MAT分析工具内
           在MAT里的histogram里找到内存占用最大的对象，然后右键找到它的GCRoot对象。即内存溢出的故障对象
           因为只有GCRoot对象一直被引用不能释放，才会出现内存溢出。
   *抢单功能在上线后，发现我们在访问高峰期，响应速度明显变慢（并发在1千人）。
     答：当初设计就是通过redis来做资源列表暂存以防止高并发给数据库直接带来压力。 后来发现tomcat和redis的连接数还是默认500和1000，在此处已经被超时掉了。
         于是调整了tomcat和redis相关的参数


* 相关jvm工具：
  jvisualvm
  jconsole
  MAT  当发生内存问题，通过jmap等工具导出内存dump文件，然后用MAT导入dump文件，就可以进行分析了。比如可以发现内存溢出故障的所在类
       

* 如果应用出现死锁，对于应用的影响也只是：当前死锁相关的线程不会被释放，结果就是这个线程资源被占用，如果这些代码被运行多次就都会处于死锁状态。
 而cpu所能处理的线程是有限的，假设最大100个线程的话，那随着这些死锁线程的不断增加，最终会导致崩溃。 

* 性能测试
  * 基础的性能测试工具fiddler等，专业的有loadrunner、jmater等
  * 系统资源监控工具：
      jvm监控：jrock、jmap、jprofile
      zabbix
      elk
      普罗米修斯
      linux命令 top
  * Jmater基本测试demo步骤：
   1.新建线程组元件，这个线程组就是要模拟用户和负载的
   2.新建http请求元件，填写相关请求参数，？是不是可以在此元件添加前置处理器
   3.在新建的http请求元件上添加监听器（或者后置处理器等等...），
   ....添加一些相关元件实现相关测试需求
  
  * 性能测试-理发师模型 需要去理解推导，详见咕泡2017年vip课程-性能测试
  * mysql执行性能分析可以看profile或执行计划  
  * spotlight监控linux服务器资源

* Jvm充当的角色： 
  1.软件层面机器码翻译
  2.内存管理

* Jvm学习的6部分（* * * 运行时数据区这部分的结构图很重要* * * ）（详解简书《深入理解JVM-内存模型（jmm）和GC》、《一文讲透JVM内存结构，还不懂的赶紧看过来》）
  * 运行时数据区（代码最后变成指令和数据被分配到运行时数据区去做处理）
    * 程序计数器：指向当前线程正在指向的字节码指令的地址行号。？为何是指向当前呢，因为线程会切换，所以要保存休眠线程的当前状态
    * 虚拟机栈：存储当前线程运行方法所需数据、指令、返回地址。虚拟机栈里有栈针（局部变量表、操作数栈...），每个栈针对应一个方法。
    * 本地方法栈：和虚拟机栈一样存储的是方法的东西，不同的是它存的是本地方法，即native修饰的方法的东西
    * 方法区：存储类信息（即class的信息）、常量、静态变量、JIT。存储的是共享信息
    * heap：堆区，栈区里存储引用变量指向的变量值
  * 对象回收的时机
    * 是否能被回收判断算法：
	* 引用计数法,个人理解应该是如果某对象a有被其它对象的每次引用都记一次数，如果引用次数为0则可被回收
	* 可达性性分析，个人理解就是如果找不到某一条引用链能够到达目标对象，则可回收，但不一定会被回收。这个链路是从GCRoot节点开始，？那些可以作为GCRoot要注意
	 当GC要回收对象前，会调用对象的finalize()方法，所以我们可重写finalize，在里面让当前对象重新被引用，就不会被回收了。注意每个finalize只会被调用一次
	* 引用
         强引用：Object obj=new Object();
         软引用：？？SoftReference去了解下。可以用做全局缓存场景应用（建议使用guva框架做缓存）
         弱引用：弱引用对象会与一个队列相关联，它被回收后从从这个队列里获取到结果是空的。有点监控的感觉
	 虚引用：用的少，可以用来监控jvmGC活动
  * 垃圾回收算法
    * 标记-清除算法，标记哪些可回收。效率低，空间碎片。
    * 复制-回收算法，复制存活对象到指定区域，然后GC清除掉其余对象。实现简单，空间利用率高。新生代的eden、s0、s1就是用复制回收算法
    * 标记-整理算法，比标记-清除算法改进了一点，会在GC时进行整理并放到指定空间，使得空间连续，利用率高。 这里用了多个回收器
  * 垃圾回收器 
    新生代和老年代有各种相关的收集器，各种收集器相互配合使用。
  * Minor GC 、Major GC、FullGC
   * 在新生代的eden、s0、s1区发生MinorGC和MajorGC，在老年代进行FullGC，FullGC=MinorGC+MajorGC
   * 经过3个GC后，会使得大部分的对象会被回收掉，而存活的对象则放在老年代  
  * GC日志
   * tomcat设置gc日志及其它jvm启动参数的方法
   * 查看GC日志方式：
     * 详见blog《【GC分析】Java GC日志查看》，注意区分YongGC、FullGC等各种不同GC日志的格式含义
     * 在idea的启动参数配置-XX:+PrintGCDetails
     * jconsole工具 
     * jstat命令
     * tail -100f gc.log

  *JVM内存设置多大合适？详见blogs《JVM内存设置多大合适？Xmx和Xmn如何设置？》
  
* jvm有些参数的潜规则
  * 有带-X或-XX 是非官方的参数，有可能一些jvm是不支持的
  * 布尔类型的通常都是+或-开头，如-XX:+MaxFDLimit
  * 如果有=号的，则是定值，是固定数值或字符串
  * 带-X的一般不用等号，而-XX有的是需要。 如-Xms20M和-XX:PreBlockSpin=10  
* 常用jvm参数
 -Xms20M  起始大小，start
 -Xmx     最大大小，Max
 -Xmn     新生代大小，new

* Jvm内存模型（详解简书《深入理解JVM-内存模型（jmm）和GC》） 
 jdk1.8-，分新生代、老年代、永久代，新生和老年代在堆区内，永久代在方法区
 jdk1.8+，分新生代、老年代、MetaSpace，新生和老年代在堆区内，MetaSpace是直接内存分配的
          MetaSpace不属于堆区（设计MetaSpace目的是为解决老年代溢出问题），可用无限动态扩容，但是堆外内存越大会使得可用堆内内存变小

 *垃圾回收不会发生在永久代，如果永久代满了或超出了临界值，会触发jvm的完全垃圾回收（full gc）对其进行回收，正确的永久代大小会避免调用full gc
   其实永久代可以是被回收的，只是条件比较苛刻。条件是：1.该类的实例都被回收。 2.加载该类的classLoader已经被回收 3.该类不能通过反射访问到其方法，而且该类的java.lang.class没有被引用 当满足这3个条件时，是可以回收，但回不回收还得看jvm。


* javap是jdk自带的反解析工具。可将class字节码文件反解析出当前类对应的code区（汇编指令），看汇编指令就查找对应文档看就行了

* jvm启动的时候回把jvm相关信息附加到GarbageCollectorMXBean上，我们在代码里可以使用这个类实例 来打印jvm信息

* 大白JVM课程中主要讲jdk8的，但是安装的是jdk9，因为两者差不多 

* Jdk11中的GC回收机制，最大的停顿时间只有10ms
  
* Jvm分为两种模式：client和server模式，jvm会根据操作系统环境进行判断

* Jvm即支持编译型模式和解析型模式，两种模型去执行代码。运行java -version 看见的mixed mode文本就代表着这两种模式共有的混合模式

* java -version 命令中的HotSpot是指一种早期的虚拟机，后来被sun公司收购并融入到正统jdk中

* 如果用kill -9杀死java进程的话  jvm的hook是不会被调用，就是钩子不会被调用

* 相关命令 
 jps 类似于linux的ps命令，只是jps显示的是java的进程，而ps是显示linux所有的相关进程。
 jinfo -flags 18136  要去了解执行该命令输出结果里的参数的意思  运行时的参数
 jmap -heap 18136  看内存的相关信息，18136是应用的进程号。注意要看8:1:1的内存分布情况不用此命令。
 jstack 18136 查看dump下的堆栈信息，详见blogs《jstack命令详解》

* 很多情况下，都会出现dump这个字眼，java虚拟机jvm中也不例外，其中主要包括内存dump、线程dump。
 输出内存dump用jmap，输出线程dump用jstack。或者用jvusalvm工具。  dump文件应该叫快照文件，待证实。

* 学会上Oracle官方去查找相关工具或应用的文档（https://docs.oracle.com/javase/8/doc）

* 为什么java中可以直接使用Obeject类实例，因为BootstrapClassLoader在jvm启动时会加载rt.jar里的类，而Object类就在rt.jar里
 从Object.getClassLoader()==null,可以看出它的classLoader是BootstraptClassLoader，因为BootstraptClassLoader是c写的，所以java加载不出来就为null
//cny_note 地区对应此模板 此处修改了bodyTpl

* java中的类加载器，从低到高依次为SystemClassLoader，ExtenssionClassLoader，BootstrapClassLoader，他们的父子关系不是java对象中的继承关系。

* 双亲委派机制：所有的类加载时候首先会依次委派给父加载器去加载，也就是从BootstrapClassLoader开始加载，如果依次加载不到就报错，所以叫双亲委派
 这样的话，像java.lang.String这种类就会在BootstrapClassLoader就被加载到，并且是到rt.jar里去加载的，而不是到开发者指定的classpath去加载。所以
 即使开发者在指定的classpath里写了一个自己定义的String类，也不会被加载，就保证了String类不被乱改，这就是沙箱安全机制。

* jvm沙箱安全机制，当开发者自己定义一个java.lang.String类时，jvm会阻止这样的行为，这就是沙箱机制。 双亲委派机制是沙箱机制的一种实现

*老年代控件分配担保：
      参考csdn《JVM 彻底搞懂什么是老年代空间分配担保机制》，此文的流程图有误
      参考csdn《什么时候对象进入老年代？什么时候触发Full GC？如何减少长时间的 GC 停顿？》
      整体理解： 如果老年代中最大可用的连续看空间大于新生代所有对象的总空间，那么 Minor GC 是安全的。如果老年代中最大可用的连续空间大于历代晋升到老年代的对象的平均大小，就进行一次有风险的 Minor GC，如果小于平均值，就进行 Full GC 来让老年代腾出更多的空间。因为新生代使用的是复制算法，为了内存利用率，只使用其中一个 Survivor 空间来做轮换备份，因此如果大量对象在 Minor GC 后仍然存活，导致 Survivor 空间不够用，就会通过分配担保机制，将多出来的对象提前转到老年代，但老年代要进行担保的前提是自己本身还有容纳这些对象的剩余空间，由于无法提前知道会有多少对象存活下来，所以取之前每次晋升到老年代的对象的平均大小作为经验值，与老年代的剩余空间做比较。
      两个逻辑的理解：
           老年代连续可用空间是否大于新生代所有对象总和：如果是则意味着新生代如果进行minorGC时，如果全部新生代对象都未死进入老年代是够的（minorGC是安全的）。否则不够则会进行“是否开启空间担保”和“是否开启冒险”逻辑判断。
           历代晋升入老年代的对象平均大小是否大于老年代连续可用空间：
              说法1：如果是则进行minorGC，否则进行fullGC。（？这个不好理解  ）
              说法2：如果老年代中最大可用的连续空间大于历代晋升到老年代的对象的平均大小，就进行一次有风险的 Minor GC，如果小于平均值，就进行 Full GC 来让老年代腾出更多的空间。（应该是这个说法才好理解）
    


* native修饰的方法是c或c++实现的方法，因为java不能操作底层一些东西。 也就是所谓的本地方法（详见JVM体系结构概览图）

* 方法区存储类的相关信息，包括静态变量、静态常量、方法、继承关系等的定义

**应用的分类：
  CPU密集型（高并发单任务执行时间短、并发不高但任务执行时间都花在计算），这种情况就减少线程切换，核心线程数越小越好
  IO密集型（高并发或低并发下任务执行时间都花在IO操作上，我的数据采集系统就是这种），这种情况就多开核心线程数
  混合型（既高并发而且任务执行时间又长），这种情况就靠整体架构，做分布式架构或缓存

？？永久代，元空间
    ASM


？？当发生Tomcat下，请求的控制器方法中出现堆内存溢出时，此时，当前方法在栈中的信息是不是会发生出栈？ 
？？此时堆内存溢出后，如果方法信息出栈了，那应该会释放内存。 但是实际top查看好像内存还是没有下降，因为测试时list是全局变量。
    此时通过实际测试，当前线程是没有死亡的，应该是因为Tomcat使用的是线程池

* 栈：先进后出
 堆：先进先出

* * * * * * * * 看到 1下 48分* * * * * * 



****性能优化经验体会
  *所有性能优化都是基于现有业务和框架去做分析的，需要有一些统计数据来做参考支撑。总之那块业务量大就做拆分或做压力转嫁
   如：当用户量大，对数据库的访问并发量增多，此时就需要统计在大并发或平时数据库读和写的并发量各多少，了解后可以做redis缓存
   如：统计数据显示图片访问量大，可以讲图片单独出来做服务，服务器做拆分
   如：我们的搜索引擎访问量大，对于某些关键词访问量大，我们就可以做缓存，也算是做压力的转嫁。

****jvm优化一定要看csdn《什么时候对象进入老年代？什么时候触发Full GC？如何减少长时间的 GC 停顿？》

## --------------------性能优化-JVM end--------------------------------

## ---------------性能优化-tomcat begin--------------------------------

* * * 2017小马哥的课程笔记在 http://git.gupaoedu.com/java-vip/xiaomage-space/tree/master/VIP%E8%AF%BE/tomcat

* 学习要点
 * 学习小马哥关于tomcat的架构图（注意与server.xml的节点相对应），Tomcat官网对于架构描述比较抽象
 * Tomcat目录及相关文件的作用
   catalina.policy 控制jvm相关的权限配置，比如说shutdownhook的权限等。比如访问Tomcat下webapps的应用时，可以通过../../可访问上层资源，如果没有权限限制就会被黑客利用攻击
   logging.properties 日志的配置，和log4j差不多
   tomcat-users.xml 使用Tomcat自带的manger应用时，配置用户密码角色用的。这个文件其实是相当于一个本地的xml数据库
   server.xml 最为重要的配置文件，主要是服务相关的配置，特别注意该配置下各层次节点的意义。网上查找
   
 * tomcat部署应用
  * 直接部署在webapps下是属于不专业的方式，懒人做法。
  * 做法有4种，第二种部署是直接改conf/server.xml配置，这种方式不支持热部署，但性能好，所以生产环境用这种方式（官方不建议这么做）。 
 * JMX和JNDI概念及应用。
  * JNDI个人理解JNDI大概就是讲所有类型的东西再做一层抽象，当成一种资源。 比如jdbc之上再做一层抽象。在server.xml里的GlobalNamingResources节点就是JNDI的标准

* 响应报文的时候有一个属性叫etags，相当于一个hashcode。 另外lastModify最后的更新时间

* springSecurity和apcheShiro差不多，都是权限框架，shiro会相对简单点。
 Tomcat的server.xml的Realm节点的权限配置，其实就是通过JNDI的方式指定到tomcat-users.xml，具体的角色-用户-权限配置就在tomcat-users.xml

* 不建议用tomcat做静态资源服务器，因为它如果又做动态服务器，则性能会占用端口，性能下降

* 在java代码中的getContextPath()就是 在tomcat中部署时设置的context的path属性

* tomcat优化点：
 禁用热部署，热加载
 连接器 connector
 连接方式：阻塞/非阻塞，这里要注意：tomcat8后的非阻塞时，只有在接收请求时才有非阻塞，在但响应时都是阻塞的

* 用jmater模拟100个线程，而tomcat设置最大线程数99，此时利用jconsole查看应用进程的线程数量，应该是99个，另一个请求线程在等待中。

* tomcat7-maven-plugin插件原理（个人认为）：利用tomcat的编程api和servlet规范，将maven项目编译并启动起来。 包含了maven的编译和tomcat的web容器作用。

* 有100个线程请求，tomcat最大线程池数也在100+，在jconsole里看到正在执行的线程并不是100个，可能是30个，因为如果单个请求处理快，30个线程是足够应付100请求了。

* 实践：
  ？设置多少线程数量最优（此问题看小马哥笔记）。  
   答：可以用jconsole查看在某一场景下的吞吐量。
       首先，评估整体的情况量，假设100W QPS，有机器数量100台，每台支撑1w QPS。
       第二，进行压力测试，需要一些测试样本，JMeter来实现，假设一次请求需要RT 10ms，1秒可以同时完成100个请求.10000 / 100 = 100线程。
             确保，加载太高。减少Full GC，GC取决于JVM堆的大小。执行一次操作需要5 MB内存，50 GB。20 GB内存，必然执行GC。要不调优程序，最好对象存储外化，比如Redis，同时又需要评估Redis网络开销。又要评估网卡的接受能力。
       第三，常规性压测，由于业务变更，会导致底层性能变化。 


* maven插件开发详见简书《Maven插件开发》

* tomcat编程式api的实践详见简书《tomcat嵌入式启动》

* springboot用的是嵌入式的web容器（tomcat）


* war和jar都是zip文件，一般war里没有main启动，jar有 

* nio的性能不一定比bio好， 在rpc中，由于rpc通信的数据都是量大，单个数据少的场景，所以用nio效率高。
## --------------------性能优化-tomcat end----------------------------------


## --------------------分布式事务解决方案 begin----------------------------------

*分布式事务种类：
 单个应用服务操作多个不同数据库
 多个应用服务操作单个数据库
 多个应用服务操作多个数据库

*分布式事务的解决方案：
 全局事务管理器（降低分布式事务出错概率）
 基于消息机制实现弱一致性
 最大努力通知
 补偿型处理（如：TCC）

*ACID 即原子性、一致性、隔离性及持久性，是传统事务特性，一个事务要满足这四个特性
 CAP 一致性、可用性、分区容错性，是分布式事务下只能这三者中的两个。并且这里的一致性属于强一致性。
     详见bilibli收藏《【IT老齐010】5分钟大白话什么是CAP定理》
     一致性(Consistency)：所有节点在同一时间具有相同的数据；
     可用性(Availability) ：保证系统能再“正常响应时间”内返回预期的结果；很多时候我们为了满足“正常响应时间”返回给用户，只能牺牲一致性“C”
     分区容忍(Partition tolerance) ：系统中任意网络丢包或延迟，不会影响系统的继续运作，系统不能崩溃，系统能容忍这些。注意：只有分布式才有所谓的分区，才有所谓的P
     场景：X服务调用Y服务
         CP：首先要保证一致性，XY系统为了保证最终一致性C，在网络出错时，X需要不断重试，来保证XY系统可以容忍这些错误（即P）。
                此时对于用户来说，XY系统一直在重试，就没办法保证一定在正常响应时间内返回预期的结果（即A）
         AP：比如X服务调用Y服务的方式变成通过MQ，则X服务将任务推送至MQ则往下执行，并不等待Y服务响应。
                此时一致性不能得到保证（即C），对于整个XY系统在正常时间内返回了结果（即A），并且系统不崩溃（即P）
         AC：只能是在单体应用中，因为单体不涉及多个分区就没有网络原因，所以他能保持一致性和可用性。即AC
     注：一般nosql数据库更注重可用性，所以nosql数据库一般是AP系统。而关系型数据库则通常是CP系统

 BASE 基本可用（Basically Available）、 软状态（ Soft State）、最终一致性（ Eventual Consistency），是eBay大牛提出系统的保证基本可用，并允许中间态，而且通过最终一致性来规避解决分布式事务（弱一致性）。
        基本可用：只保证核心业务可用，如积分这类附加的功能再大流量大并发可用暂时停用
        软状态：订单下完之后，并不返回扣款成功状态，而是一个中间状态
        最终一致性：通过其它方式保证最终给到用户的是一致的。 比如：人工补积分，补礼品。
* XA规范不是java的规范，而是一种通用的规范，目前各种数据库、以及很多消息中间件都支持XA规范。只有这些资源管理器实现XA接口。应用服务才能调用XA接口
 JTA(Java Transaction API)，是J2EE的编程接口规范，它是XA协议的JAVA实现。基于JTA规范的第三方分布式事务框架有Jtom和Atomikos


* 分布式事务中提到的资源管理器RM，包括数据库、消息中间件等
* 本地事务，和分布式事务相对的，就是在同一个资源内执行的事务，如同一个数据库。


* * 2pc 和 3pc在实际中间件应用其实很少，不能保证完全的一致性。
  形象的理解详见bilibili收藏马士兵《seata简介》中提到：“男女AA吃饭，老板收钱出餐”场景。
  数据最终一致性一般通过消息中间件（事件驱动、消息）或推送通知来实现最终的一致性。 像微信支付宝支付功能都要一个结果回调url
  这种回调一般会不定时执行多次，知道应用给予应答。 此时要保证应用处理结果过程中的幂等（就是处理一次和重复的多次处理的结果要保持一致）
  幂等实现方式：数据库的唯一约束，最好不要查询，因为查询要枷锁防止并发情况下的竞争问题
               token机制，其实这里也需要枷锁防止竞争问题。token也可放redis来保证竞争过程中的一致性
  如果通过数据最终一致性方案后还出现数据不一致问题，这时候只能人工介入，进行人工数据处理。
  一致性分强一致性和弱一致性，强一致性会产生一定的性能问题。如果不是非常必要，不建议强一致性。
  如果消息丢失怎么办？mic说用事件表
  如果消息需要有顺序性怎么吧？！时间戳
  总结：一般分布式事务解决方案：先使用常规分布式事务框架保证大多数业务正常运作，再用可靠消息中间件对数据一致性进行补偿处理，最后再有一致性出错则人工介入。

*2pc中准备阶段会有在本地记录undolog和redolog，分别记录修改前和修改后的数据。

* 注意XA和TCC的区别，一个是在资源层面上（如数据库提供了回滚机制），TCC是在应用层面上（如实现try、comfirm、cancel方法）
        而seata的AT模式则是存储了执行sql的快照，然后通过快照回滚。
        从侵入程度来看，XA<AT<TCC。即XA其实是侵入最少的。
        XA模式中，如果一个服务数据库失联了，则可能产生死锁，久久不能释放。

* 分布式事务解决方案
 * 基于JTA（XA）标准的框架，如JOTM、Atomikos。主流是是用Atomikos。 网上可找ssm+Atomikos的使用案例。
 * tcc-transaction  详见简书《TCC-Transaction 解析系列（1）：dubbo-sample》 、《tcc-transaction源码分析与思考》
    tcc-transaction的comfirm和cancel方法还可以配置失败重试的次数。 并且好像是通过固定数据库表来记录信息
 * seata框架，阿里的分布式框架seata后期可以了解下，19年1月开始开源的项目，还不稳定，待研究。
   详见blibli的收藏的马士兵的课程、具体详见官网http://seata.io/zh-cn/index.html
   seata 将为用户提供了 AT、TCC、SAGA 和 XA 事务模式。主流的是用AT模式
   AT模式的总体逻辑：两个独立的局部事务tx1、tx2注册到一个全局事务，会有保留全局事务编号XID和局部事务BranchID
             tx1、tx2提交时会有UNDO LOG记录（保存在各个分布式事务所对应的数据库undo_log表里）。而且tx1、tx2都会去通过全局分布式锁来控制读写隔离（如：防止tx1执行，tx2未执行情况下tx1里的数据被读取）
             当提交tx1、tx2都没有问题则全局事务提交（释放锁等资源，删除UNDOLOG等），如果其中一个局部事务出错，则会通过XID和BrancID找到UNDO LOG记录来回滚补偿。
             注意：AT模式的具体调用逻辑详见csdn《seata的AT模式调用流程分析》！！！ 一定要看
   TCC模式：和TCC-Transaction框架一样就是浸入式的try-comfirm-cancel逻辑
   Saga：过程比较复杂，做了解。对于一些老的系统或者异构系统（不同语言构建的多个微服务）、其实也是通过补偿机制，比如在原有的服务接口之外，新定义补偿接口。
             这些提交或补偿由状态机来决定，状态机决定这些调用流程。
   概念：
         TC：事务协调者，seata的服务端
         TM：事务管理器，全局的事务的发起者。 TM和RM可以是同一个，比如下单扣库存，订单和库存服务都是RM，而发起全局事务的是在订单服务，所以订单服务也是TM
         RM：资源管理器，具体的事务执行器
 * * 注意：以上方案都是基于二阶或三阶提交理论，不能100%保证一致性。所以衍生了最终一致性方案：可靠消息和最大努力通知两个最终一致性方案。

*！seata整体执行原理，详见csdn《阿里分布式事务框架Seata,AT模式原理解析》和简书《Seata in AT mode的工作原理》
 注意：数据表undo_log、branch_table、global_table、lock_table的相关作用。在seata中，无论你使用哪种事务模式，都会将全局事务状态和分支事务状态存储下来。
      AT和XA的区别在于第一阶段本地事务提交后前者释放本地事务锁定的本地记录，而后者是在第二阶段才完全释放。
 seata AT模式相关数据表作用：
    global_table：全局事务表，在整个全局事务执行期间，由seataServer操作，记录全局事务相关信息。全局事务结束则删除记录
    branch_table：分支事务表，在分支事务开始时会向seataServer发起注册分支事务请求，seataServer将分支事务相关信息保存至该表。
    lock_table：（？需考证）记录着被全局事务锁xid锁定的数据主键（即pk字段），各分支事务提交的时候先校验是否有被全局锁住的数据，如果冲突则分支事务无法进行提交，防止了脏写（都是被seata管理的事务）。
    undo_log：业务事务快照表，在本地事务执行期间，有RM操作，本地动态代理数据源会将涉及数据前后镜像快照和业务sql一起提交事务。
 seata AT模式事务相关状态：详见51CTO《seata源码解析：事务状态及全局锁的存储》
**Seata AT全局事务的执行步骤（以jeecg订单、库存、账户demo为场景）
    参考文档：简书《Seata in AT mode的工作原理》、csdn《Seata入门系列(7)-undo_log、global_table、branch_table、lock_table字段及作用详解》、《阿里分布式事务框架Seata,AT模式原理解析》
    1、用户发起订单请求，orderServer发起全局事务(TM)，在seataServer（TC）注册全局事务生成xid返回orderServer。 
       此时seataServer将全局事务相关信息存储到global_table表中
    2、创建订单（此时orderServer是RM角色），具体过程如下：
       2.1、拦截解析sql（通过动态代理实现），查找当前数据，生成前镜像。执行sql，生成后镜像。
       2.2、根据1步中拿到的xid向seataServer注册分支事务，信息存储到branch_table。申请涉及的数据库数据记录的全局锁（即将涉及的数据锁定），避免其它事务干扰。
       2.3、提交本地事务，包括业务sql和前后镜像快照到数据库（前后镜像保存到业务库的undo_log表中）。
       2.4、向seataServer报告本地事务结果，变更分支事务状态。此时会释放掉本地事务锁定的本地记录和连接（如果XA模式在此阶段并不会释放锁定，而是全部结束才会释放）。
            AT模式之所以能够在此阶段（第一阶段）释放被锁定的记录，是因为在每个业务库都有undo_log表记录了前后镜像快照，
    3、扣减库存，扣减账户（productServer和accountServer都是RM），具体过程和第2步创建订单是一样的。
    4、orderServer执行完整个调用链后获取seataServer上的各分支事务执行情况（此时orderServer是TM角色）。根据执行请求发起全局提交或回滚：
       提交：seataServer决定全局提交，将分支提交的消息发送给各分支事务，各分支事务收到分支提交消息后，将消息放入一个缓冲队列，然后直接向Seata返回提交成功。
            之后每个本地事务会慢慢处理分支提交消息，具体过程：删除相应分支事务的undo_log记录。之所以只需删除分支事务的undo_log记录，而不需要再做其他提交操作，是因为提交操作已经在第一阶段完成了（这也是AT和XA不同的地方）。
       回滚：seataServer决定全局回滚，将分支事务回滚消息发送给各分支事务，由于在第一阶段各个服务的数据库上记录了undo_log记录，分支事务回滚操作只需根据undo_log记录进行补偿即可。
            具体过程如下：开启本地事务，查询当前分支事务的undo_log记录，对比修改前后的记录镜像，生成undo sql，执行undo sql，删除相应的undo_log，提交上述操作的本地事务。
            注意：根据undo_log表进行数据回滚前，会对比现有数据和undo_log的after_image是否一致来防止脏写。如果有其它事务修改过数据（脏写），则回滚失败，只能人工介入。
    特别注意：阶段划分：1、2、3步属于第一阶段，4步属于第二阶段。
            写隔离：第一阶段提交本地事务前需要申请全局锁（比如涉及行记录的行锁），获取成功则提交，获取不成功则重试，重再不成功则失败回滚事务。其它全局事务要操作涉及的行记录则也是要去申请竞争全局锁。
            读隔离：数据库设置了不同的本地事务隔离级别，包括：读未提交、读已提交、可重复读、串行化。在数据库本地事务的隔离级别为读已提交、可重复读、串行化时（读未提交一般不使用）， Seata AT全局事务模型产生的隔离级别是读未提交。
                  从上述的第一阶段和第二阶段的流程图中也可以看出这一点。也就是说一个全局事务会看到另一个全局事务未全局提交的数据，产生脏读，这在最终一致性的分布式事务模型中是可以接受的。
    考察问题：XA和AT有什么区别？：主要区别是在第一阶段提交本地事务后，会释放分支事务占用的全局锁锁定的数据。
            AT模式下事务隔离级别是什么？：是读未提交，因为在AT模式第一阶段提交本地事务后，已经释放了全局锁锁定的行数据，所以此时其它全局事务是可以来访问的。
            使用seata过程有没有出现什么问题？：有，出现了局部事务未回滚的情况。 ....待考察
 *seata实践：
   *通过jeecg官网demo进行实践 
   *实践中相关问题：
       相关问题可以参考简书《seata集群部署与踩坑集合之秃头篇-持续优化》
       *配置了seata服务端file.conf的数据库连接后启动失败，报错“errorCode 0, state 08001”。将驱动添加上“cj”即可，即driverClassName = "com.mysql.cj.jdbc.Driver"
       *报错corsFilter重名问题。 可以根据提示配置spring.main.allow-bean-definition-overriding=true即可
       *order项目启动时报“Failed to determine a suitable driver class”错误，是因为order项目继承了父pom，打包类型是pom，此时需要改为jar类型
       *报数据源类型错误，原因是由于使用的dynamic-datasource，但jeecg-boot公共依赖druid-spring-boot-starter导致配置类进行相关bean注册时相关yml配置缺失导致报错。排除DruidDataSourceAutoConfigure的bean注册即可
        如果从整体架构优化角度，更好的方式是在特定组件对应的配置类里加上@Conditional(onMyConditional.class),在onMyConditional实现里去判断配置文件是否有特定的组件配置
       *上述问题处理完后，发现访问knikfe4j文档时，业务接口文档并没有显示（大概率路径问题）。最后单独做knikfe4j测试demo也有问题（报错），通过报错网上查找到解决方案。
        详见csdn《解决springmvc因版本造成的路径通配问题》、《Spring Boot 2.6.x整合Swagger启动失败报错问题解决（治标还治本）》
       *seata demo中/test2中，account服务余额不足时，account本地事务失败（抛出异常），order服务事务回滚了，但product的事务却提交了（库存变了），也就是没有全局事务回滚。
        ？奇怪的是/test1中product库存不足事务回滚了，全局事务是正常回滚的。！！其实是库存不足则product服务抛异常，所以account服务未执行扣款。其实和account服务余额不足情况是一样的。
        ？各个微服务启动后，在seataServer服务端控制台日志可以看到，order、product、account都注册TM和RM角色。但个人认为是只有order注册TM才是符合理论的（全局事务的发起者）
        ？通过断点调试，在branch_table只添加order分支事务的数据，并且seataServer服务端控制台日志显示也只有order分支事务注册成功，也就是只有orderServer注册了分支事务，product和account并未注册分支事务。
        思路：在service分支事务代码中用RootContext.getXID()可以获取到xid，可以打印出各个分支事务下的xid，看是否是一致的或者xid为null
             是否service事务代码被ctry-catch掉或者全局异常处理。
        解决：根本原因在于orderServer用feign客户端请求微服务未进行xid携带，productServer和accountServer获取不到xid。
             jeecgdemo里用的是seata-spring-boot-starter并没有xid携带功能。而spring-cloud-starter-alibaba-seata是集成xid携带功能(放在请求header的tx_xid)
             详见csdn《SpringCloud-Alibaba之Seata入门以及踩坑》
   
 *seata的基本使用步骤，详见jeecg的demo
  注意：由于jeecg-boot架构问题，seata的demo引用了公共依赖，需要相应的一些配置。因此需先在启动引导类里将自动配置类和相关类的bean排除。
        排除了WebMvcConfiguration.class,确实默认页面路径配置，需要用直接地址访问http://127.0.0.1:5001/doc.html#/home
  注意：在TM上的service的方法上要用@GlobalTransactional


* mic的vip-project-space项目里各个dubbo服务都是通过自己模块的Bootstrap#main运行的，是dubbo编程式的启动方式。不依赖于tomcat


* 通常把一个数据库内部的事务处理看作本地事务，而分布式事务处理的对象是全局事务


*mycat适用于哪些场景？相对于海量存储的Nosql的适用场景又如何？
数据量大到单机hold不住，而又不希望调整架构切换为NoSQL数据库，这个场景下可以考虑适用mycat。当然，使用前也应该做规划，哪些表需要分片等等。另外mycat对跨库join的支持不是很好，在使用mycat的时候要注意规避这种场景。

？如果数据库分库分表，并且用mycat聚合，此时如果一个service调用mycat进行操作是不是会有分布式事务问题。或者说mycat是如何解决多库的分布式事务的
  如果是一个service调用多个分布式的service，此时分布式事务如何落地实践。

？找一个主流的分布式事务框架进行实践：atomikos和tcc-transaction
？部署vip-project-space项目以学习部署，可以了解dubbo编程式启动，打包部署

？你们分布式事务解决。
               我将分布式事务分为应用层、数据库层和强一致性和弱一致性。最终一致性（避免分布式事务）
               强一致性（如资金账户加款、积分账户增加积分等金额处理）：
               资源层面，如数据库分布式事务主要通过Mycat整合数据库集群，利用XA协议保证解决分布式事务问题。对于分表分库，实际在事务、排序、查询等都是相对会耗时，所以能不分表分库尽量不要。
               应用层面的分布式事务主要通过Tcc框架解决非数据库类型事务，其原理是二阶提交，有点try-catch的意思。虽然侵入性抢但性能较高优势大，因为他没有预提交过程，就是一种补偿机制，可以做支付宝接口。而Atomikos更多用于单体应用，分布式下会有并发性能问题，因为会占数据库锁。而我们知道应用层面比数据库好扩展。
               弱一致性（记账、发货通知）：
               人工对账、或者最终一致性，用ActiveMQ消息订阅，类似于支付接口的结果回调监听。
               幂等性的实现（全局唯一ID，数据库主键、版本戳）。
               尽量将dao层面请求写在一个service，如果不行就用Tcc。包含单service多库事务、多service单库事务
               *分布式事务场景类型
                同service服务跨库强一致性，用mycat的XA协议进行。
                跨service服务强一致性，用Tcc补偿型或Atomikos等支持XA的框架。如：扣余额、扣库存
                跨service服务弱一致性，可用MQ或任务等做异步。如：同步索引库、扣积分
                跨service服务最终一致性。可用MQ或任务等做异步。如：支付接口回调、
               *事实上分布式事务，由于锁是在最终提交时才释放，所以占用资源和时间，因此并发下容易造成事务积压甚至死锁。详见csdn《XA 分布式事务研究》
                因此尽量避免使用分布式事务，将需要调用的东西都放在同一个资源内，如将订单表和库存表放在同一个数据库内。


## --------------------分布式事务解决方案 end----------------------------------

## --------------------限流策略 begin----------------------------------

* 应对高并发手段：限流、降级、缓存

* 降级方式
 自动降级，dubbo配置的mock、熔断其实也是属于降级的一种。 在限流机制下一单阀值达到就会触发降级策略
 人工降级，如用配置中心达到人工降级

* 配置中心
 diamond
 百度disconfig
 apollo 、nacos

* 限流原理（注意各种原理的具体代码落地实现,详见mic课堂demo，另外还有信号灯）
 滑动窗口：TCP层面限流就是利用“滑动窗口”原理实现。窗口滑动时，每次都会计算窗口内的量是否超出限制。
 计数器：大白的lion项目自己实现的限流原理应该是利用计数器。
 漏桶：如利用固定大小队列来限制，其实相当于消息队列，然后跑一个服务订阅消息队列用固定速度处理。  guava里有实现漏桶 RateLimiter.create(100,10,TimeUnit.MILLISECONDS)
 令牌桶：类似银行取号办业务，但是令牌生成是有固定的速率的。但是会有问题：当业务消费速率大于令牌生成速率则会出现等待生成令牌或直接报错。guava里有实现漏桶和令牌桶的策略RateLimiter.create(100)
 注意：漏桶和令牌桶的区别

* 大白的lion项目自己实现的限流原理应该是利用计数器原理


* 限流解决方案：
 * 接入层层面：通常使用nginx自带的连接数限流模块和请求限流模块。Nginx的openResty扩展模块也有提供限流功能。缺点：不能对内部服务调用进行限流
 * 应用层面：
    * 单机：AtomicInteger、Guava的RateLimiter、JUC的信号灯Semaphore等
    * 分布式：Redis+Lua+拦截器+注解（常用方案）、mysql存储

？实战：Redis+Lua+拦截器+注解做分布式限流

 

## --------------------限流策略 end----------------------------------

--------------------任务调度 begin----------------------------------
*背景：
   单机任务：用线程、ScheduledExecutorService等做定时任务或Quartz框架
   分布式任务：
         ①使用zookeeper实现分布式锁 缺点(需要创建临时节点、和事件通知不易于扩展)
         ②使用配置文件做一个开关  缺点发布后，需要重启
         ③数据库唯一约束，缺点效率低
         ④使用分布式任务调度平台XXLJOB、Elastric-Job、TBSchedule
*xxl-job
 概念：
     执行器：具体执行任务的服务机器。可以手动或自动注册登记，存储到DB里面
     调度中心：用来负责调度任务的机器。
     触发器：什么时间，什么情况下去触发执行任务。
     路由：即调度器选择哪个具体的执行器的链路。关注点是路由策略，就是调度器决定以什么方式选择执行器。 其实就是一个“负载均衡策略”，比如最少调用策略或轮询策略。
     DB：用于负责存储执行器数据、触发器数据、任务数据等相关信息
 总的原理过程：
    1、根据文档配置启动admin服务（应该是调度中心）， 在springboot里集成xxl-job（作为执行器，并注册信息到DB）
    2、在admin后台配置相关任务后，按照规则（路由策略、运行模式等），调度中心会从DB获取相关任务信息交给执行器执行。
    3、如果运行模式是Bean方式，则这个Bean实例应该是在执行器所在的服务里定义。 

     
--------------------任务调度 end------------------------------------

* 类图中的关系连接符
 —> 关联关系 一对多的关联
 --> 依赖关系 一对一的关联
 —▷ 继承关系
 --▷ 实现关系
 —◇聚合关系
 —◆复合关系

* 源码阅读技巧：
 * 用intellij的Structure面板可以分类查看属性、构造函数、继承的东西
 * 看该类名称、接口规定“技能”，抽象父类规定“实现流程”。
 * 职责单一，公共的逻辑放父类
 * 利用装饰器模式、工厂等模式可以对对象的行为进行监控、拦截扩展等操作。

* 调试技巧：
 debug时候，console输出的错误信息从上到下是对应最底层到最上层的代码。此时可在throw异常的地方前断点查看引发异常的原因。
 对于第三方框架来说，如果不了解底层的一些逻辑原理的话，很难判断是上层应用的什么错误代码导致了底层异常。所以需要学习底层框架原理。

* @FunctionalInterface表明这个接口将是一个函数式接口，里面只能有一个抽象方法
 注意jdk8提供的Function、Predicate、Consumer、Supplier接口都带有@FunctionalInterface注解
 注意：以下方法参数handlerSupplier是可以传递一个MessageHandler对象或者Supplier<MessageHandler>接口实例
       即可以传MessageHandler实例又可以传递一个返回MessageHandler类型实例的方法或lamda
    public void register(Supplier<MessageHandler> handlerSupplier) { //do sth }

* 【597简历的求职意向-->搜索简历 】 功能的解决方案：
 需求：每份简历可以添加3个求职意向，而且每个求职意向有：城市、职位、...等5个条件
       比如A简历有3个求职意向：北京+PHP...、杭州+Java...、厦门+DotNet...
           B简历有3个求职意向：北京+DotNet...、杭州+PHP...、厦门+Java...       
       此时搜索引擎搜索就必须满足搜索"北京" 能匹配到AB，搜索"北京PHP"只能匹配到A，等等等等多种情况。
 ?要问下张阳，这些搜索关键词是通过 选择控件选择出来还是 输入关键词

* 现在有代码转流程图工具，可以用这种工具进行画流程图 如：https://code2flow.com/app

* 大多数框架都是支持spring和api两种调用方式，而常用spring方式，为了更好了理解spring方式的相关配置，可以学习使用api方式。

* java经常用接口来规定调用，而用Abstract类来规定该接口实现的一些模板，具体实现类负责其中的一些实现

* 在研究源码的时候可以最好调试，通过断点去查看接口接收的实例到底是什么，再去具体实例的实现类或其父类中去查看对应的方法。

* Mockito是java单元测试中，最常用的mck工具之一，提供了诸多打桩方法和注解。

* oom异常,内存溢出

* TPS 即每秒处理的事务数，很关键的指标，脚本定义什么事务，就按什么事务来计算。

* 幂等函数，或幂等方法，是指可以使用相同参数重复执行，并能获得相同结果的函数。这些函数不会影响系统状态，也不用担心重复执行会对系统造成改变。例如，“getUsername()
* 幂等，简单来说：重复调用多次产生的业务结果与调用一次产生的业务结果相同。分布式事务解决方案课中有描述

* mycat对这个mysql8支持不太好，可能会出现连接慢的问题

* MySQL 每秒 570000 的写入，如何实现？https://mp.weixin.qq.com/s?__biz=MzUzMTA2NTU2Ng==&mid=2247486295&idx=1&sn=418312cb5429d21d09c7a6e23910832e&chksm=fa4974e6cd3efdf00fdc897af55c6a2c71ae651faab5509be918b9c27d703d1c18841d30a433&mpshare=1&scene=23&srcid=0217rMrBREycCz4GGv7F4AkS#rd

* mysql据库在公网，mysql有固定的ip白名单。客户端在笔记本上会经常变换网络,怎么办
为了安全，给几个建议参考
1，服务端设置成非3306端口，尽量10000以上
2，禁用root用户的远程访问权限
3，新建一个普通用户，开通远程访问权限，同时普通用户限制一下权限

* MongoDB管理工具Studio T3可以了解下

* ETL，是英文Extract-Transform-Load的缩写，用来描述将数据从来源端经过萃取（extract）、转置（transform）、加载（load）至目的端的过程。ETL一词较常用在数据仓库，但其对象并不限于数据仓库。

* slf4j和log4j的关系详见博客园收藏。 实际线上项目一般slf4j，它主要提供了日志的接口api，而不是具体的日志实现，相当于是一套规范。
 slf4j-log4j12.jar是slf4j 转接到log4j的桥接包,所以这个包不能和log4j-over-slf4j.jar同时用，否则会死循环！！

* 通过异步化写入日志可以使得服务器性能在应用有充分的利用。

* java中子类继承父类时，若父类没有无参构造函数，则子类构造函数内必须首句调用父类指定的构造函数。


* intellJ中，在匿名内部类或者Lamda表达式方法体里使用外部的变量总是会显示为紫色并且带下滑线，应该是表示此变量是不可变的，final的，如果在方法体内部或外部对该变量进行更改的话会编译报错。


* 到时候准备面试时，是否考虑到福州进行练手面试，缺乏大型互联网项目实战是一个很大的坎。


* 有时间的话，到后面可以按章节刷刷咕泡的问题论坛和qq群。

* 整合淘淘和jeesite形成自己的框架。

* 后期如果有需要用大量的数据做压力测试，可以找郭总或者找咕泡老师

* 职业方向：把业务功能做熟悉，再研究分布式重构。

？在数据库做报表的时候，有时候一些统计汇总的数据计算量非常大，怎么解决处理
  可以将数据分批统计汇总，或者一部分相对少变化的数据统计汇总结果做缓存。这样只做部分有变化数据的汇总，再和其它汇总结果相加即可

？Objects、Collections、Arrays的常规使用

？怎么使用jstack查看线程阻塞情况

？？白老师的项目有用过guava啊，用来做缓存和事件监听 可以蛮了解下guava
？？spring security蛮去了解下

？？JVM最多支持多少个线程，网上找找可以有一个量级概念。详见CSDN《JVM能够开启多少线程》

？？分布式环境下的事务处理、服务调用链出错等问题。这些必须进行系统深入的学习
？？字节码重组，动态编译技术是否要深入的学习
？？底层通信、多线程和并发要进行系统学习
？org.projectlombok的使用

？学习使用JDK自带的VisualVM进行Java程序的性能分析 jdk1.8.0_11\bin\jvisualvm.exe 

？sharding-jdbc做读写分离，有待了解，和mycat做对比

？GTS是一款分布式事务中间件，由阿里巴巴中间件部门研发，可以为微服务架构中的分布式事务提供一站式解决方案。
  它是收费的，但是有开源的社区版本fescar

？面试题：给你50台机子，用MySQL存储，怎么解决
  如果说qps,可以加缓存，可以加收索引擎，如果是tps，那么就放消息队列，限流

？面试题：Spring 项目启动非常慢的解决思路  还有 线上环境 cpu负载不高 load很高 怎么定位和解决问题 

？面试题：线程池就问有几种 你用过哪些 哪些用的比较多 说说怎么实现的

？面试题：谈谈你对spring的理解

？面试题：擅长什么，遇到什么困难，怎么解决的，用的什么分布式，写过什么并发，大数据量怎么处理的，平时看书吗？看的什么书

？面试题：一个数据库字段只有1,2两个值，那查询时用 =1和!=2有什么区别。 好像和索引问题有关，如果这个字段是主键，无论 =1 和 ！=1 都会走索引，非主键 字段，!= 是不会走索引的 。答案不确定需要深究

？面试题：现在面试好难啊，，不知道为什么，，？他们根本就不问你学的东西，，都是，如果网络闪断怎么样？你用zk，他说服务还是好的，，心跳不跳了，，分布式锁怎么搞？  你说限流吧，，他说不能限流，，量就是很大，你说扩展服务器吧，，他说假如一台量就是很大不能给限了，限了影响客户体验。。。哎，，，吐血了，，，你说你读了源码，人家根本不吊你，，，现在面了好几个都这样。。。。

？咕泡学员问题：我现在有个问题，就是要判断某个字符串是不是被加载了，我用个stringbuilder.indexOf的方式去判断。要83秒，然后我用list.contain判断，也要80秒。。有什么办法可以优化呢，才15W条数据，15M的数据量
  可以用hashSet试下

？面试题：csdn《面试集锦|狮桥资本技术一面》

？廖师兄那个微信点餐系统是个什么项目  了解下
  es搜房的项目

？soapUI测试工具了解下

？咕泡学员分享面试题：
 1.面向对象的特点
 2.equals和==的区别
 3.hashMap与hashtable以及currenthashmap的区别
 4.线程池的几种实现方式
 5.threadloacl原理分析。 详见blogs《Java中的ThreadLocal详解》
 6.volatile实现原理
 7.CAS乐观锁
 8.谈谈ABA及解决方案
 9.Spring ioc的实现原理及优点
 10.说说Netty线程模型
 11.说说RPC的实现原理
 12.说说CAP定理，BASE理论
 13.说说最终一致性的解决方案
 14.集群与负载均衡的算法与实现
 15.数据库性能优化有哪些
 16.描述设计一个秒杀系统

？咕泡学员哈罗出现面试题：
 1.线程池参数
 2. hashmap
 3. zk服务怎么动态获取
 4.redis的数据结构
 5.spring得理解
 6.spring的扩展点
 重点还是spring额，问的不难，关键要回答的面试官

* 神州优车
 一般13薪，有kpi，框架集成，如果只是普通业务开发，是否考虑。
 不同级别能看到的框架源码不一样

* 面试宝典https://www.docin.com/p-2122232700.html、
 https://blog.csdn.net/weixin_42248137/article/details/80395227、
 https://www.cnblogs.com/xueSpring/p/8026875.html
 阿里面试题：https://gper.gupaoedu.com/answers/712  https://gper.gupaoedu.com/articles/766
 美团校招面试经验 https://mp.weixin.qq.com/s?__biz=MzI3ODcxMzQzMw==&mid=2247488625&idx=2&sn=7482d2a59ea40e6d89f2ced75ea2368c&chksm=eb539147dc2418518e3f9676c021649a4137f863607f71d40344af5b09e08e60fa37add704e7&mpshare=1&scene=23&srcid=0301ccTa3nM0lqKPP3LX5RRB#rd
 github上面有个5万star的项目 专门收集一些面试题  https://github.com/CyC2018/CS-Notes
 【社招】阿里巴巴内推Java和前端开发（长期有效） https://zhuanlan.zhihu.com/p/64743162
 网友收集面试题：https://github.com/Airxia/leetcode
 大厂面试题：https://gper.club/answers/7e7e7f7ff3g5bgc6g6a

* 面试之前将一些知识文档全部打印进行复习。当做一次考试。    
* 今天面试碰到面试官问秒杀 我说用redis list结构push方法解决秒杀 他说10000个人进来会导致连接超时或者连接满拒绝吗？ 

* 整理实战项目：
 海晟相关系统
 质量检测系统，主要是设计模式应用
 MytotalWorld电商平台，结合淘淘系统
 大白抢单中间件，伪销售抢单

* 北京java 三四年左右 26k左右
 北京上海java 四五年左右  28k左右

* 厦门4年工作经验，进趣店18K 18薪




* * * 走工资流水记录  一个月走7000 找坤斌帮忙    

* * * * * * * * * * * * 新阶段的实战计划* * * * * * * * * * * * 

* 抄袭jeesite，复习基础

* 实践各种中间件

* 实践互联网常见解决方案


*文杰数据库服务器
 IP/端口：106.55.38.133:3306
 用户名/密码：root/7Bx=*xou|fkowj$e#Q"9
*文杰redis库服务器
 IP/端口：139.199.156.53:16379
 密码：smart2020
 

  


